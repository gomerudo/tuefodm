{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Cldva427KD_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Foundations of Data Mining: Assignment 4\n",
        "\n",
        "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as).\n",
        "\n",
        "**Deadline:** Thursday, April 12, 2018"
      ]
    },
    {
      "metadata": {
        "id": "Q_m_H-ZmKD_n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Please fill in your names here\n",
        "NAME_STUDENT_1 = \"A. Siganos\"\n",
        "NAME_STUDENT_2 = \"J. GÃ³mez Robles\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nZ5SygS2KD_q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from preamble import *\n",
        "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
        "# Comment out and restart notebook if you only want the last output of each cell.\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8RvIAZG6KD_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Backpropagation (6 points)\n",
        "\n",
        "Figure 1 illustrates a simple neural network model.\n",
        "\n",
        "![Figure 1](images/a4_network.png)\n",
        "\n",
        "It has single input $x$, and three layers with respectively one, two, and one neurons. The activation function of the neurons is ReLU. \n",
        "\n",
        "The parameters $w_1$, $w_2$, $w_3$, $w_4$, and $w_5$ (no biases) are initialized to the following values $w_1 = 2, w_2 = 1$, $w_3 = 2$, $w_4 = 4$, and $w_5 = 1$. Implement a single update step of the gradient descent algorithm by hand. Run the update state for the data point $(x=2, y=3)$:\n",
        "\n",
        "The goal is to model the relationship between two continuous variables. The learning rate is set to $0.1$\n",
        "\n",
        "Provide the solution in the following format:\n",
        "\n",
        "- A choice for a loss function \n",
        "- Compute graph for training the neural network\n",
        "- Partial derivative expression for each of the parameters in the model\n",
        "- The update expression for each of the parameters for each of the data-points\n",
        "- The final value of all four parameters after the single step in the gradient descent algorithm\n",
        "\n",
        "The Python code for simple computational graph nodes, as seen in the tutorial session, is provided in the cell below (run the cell to load the code, and again to run the code). Extend the nodes so they can be used to implement the network described above. Implement the network with the same initial weights and the correct learning rate, and verify your hand-made calculations. Add comments to your code or provide a separate description to explain the changes you have made."
      ]
    },
    {
      "metadata": {
        "id": "pY5kkrQCKD_t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ]
    },
    {
      "metadata": {
        "id": "y3Qbp5osuu9Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loss function**\n",
        "\n",
        "For this problem, we have choosen the Mean Squared Error defined as follow:\n",
        "\n",
        "$$\n",
        "L = \\frac{\\left(\\hat{o} - y\\right)^2}{2}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\hat{o}$: The prediction\n",
        "\n",
        "- $y$: The true value\n",
        "\n",
        "**Compute graph**\n",
        "\n",
        "![Figure 1](https://lh3.googleusercontent.com/bTxjSuuYeaWaQNyFXoDDG3C8NaOfwPvjHHiLDSj_r4Zu5_dSmY62FfqQzf_JZowhj4-c-IbvuboziHMcRq4HeSE7Ey-1D3lK4YUj0bopLmFC2youIOXFOLGngHbKj1MB_bHPrgPrp5smrguoTNhOwCmJao24c-NtvsEhlNWv63TzJ9I50cvMxd4dozDB5qGe_fVed3E2-Ug0MOu0xyPe6-rosu0wFjeKOk5aUJ1gRTKumMDf_thYC8xEf93ei_YNxr6OGJrFHfpYpPK6qOoqeWqQO_vMMYIMVUn5GzN1iGVqpgdMmGpvRqohjhW31UpnTPfIWUPcZ10r5tk6LuCAEIjTmFnSvn0DMSOIyGS7Xk-o4B0CoU9p2T7Wi5O_UwzRd5WPgYpNrQQ4o7L8PNK9OVo5oc7-5IWr4y4EHyBjaUk72uiAV3LTefZk8iCFsK8tJ8MTdSdKMDrtOMvAVAUCvPmrTBtrBBcqEKT9A0VXEIUYWLDv2Cd8AnLk_e7wBWoBBhFvwLTKjPUxDQf9lZzoZYjXtGlp-a0EAs5pVeS2xYuqz2FT2hnlhKfjBAu-dxBRa-yNT38MtHiblzZc-ZAnornYFlddFQh0jSEbP1epj6aLFgVrT7xytnqu8LsGoGqABo78kGET5ZcPkvbdCWHAPgDniNDpyoj-fQ=w860-h395-no)\n",
        "\n",
        "\n",
        "where:\n",
        "\n",
        "$$\n",
        "o_1 = w_1 . x \\\\\n",
        "o_2 = w_2 . o_1 \\\\\n",
        "o_3 = w_3 . o_1 \\\\\n",
        "o_4 = w_4 . o_2 \\\\\n",
        "o_5 = w_5 . o_3 \\\\\n",
        "o_6 = o_4 + o_5\n",
        "$$\n",
        "\n",
        "Specifcally, for this problem our loss is defined as:\n",
        "\n",
        "$$\n",
        "L = \\frac{(o_6 - y)^2}{2}\n",
        "$$\n",
        "\n",
        "**Partial derivative expressions**\n",
        "\n",
        "First, we show the derivative expressions for loss and outputs $o_i$. Note that for $o_1$ we obtain two expressions because of the split of this output in the first multiplication node.\n",
        "\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial L} = 1 \\\\\n",
        "\\frac{\\partial L}{\\partial o_6} = \\frac{\\partial}{\\partial o_6} \\frac{(o_6 - y)^2}{2} = o_6 - y = 24 - 3 = 21 \\\\\n",
        "\\frac{\\partial L}{\\partial o_5} = \\frac{\\partial o_6}{\\partial o_5} \\frac{\\partial L}{\\partial o_6} = \\frac{\\partial (o_4 + o_5)}{\\partial o_5} \\frac{\\partial L}{\\partial o_6} = 1  (o_6 - y ) = 1 \\cdot 21 = 21 \\\\\n",
        "\\frac{\\partial L}{\\partial o_4} = \\frac{\\partial o_6}{\\partial o_4} \\frac{\\partial L}{\\partial o_6} = \\frac{\\partial (o_4 + o_5)}{\\partial o_4} \\frac{\\partial L}{\\partial o_6} = 1 (o_6 - y ) = 1 \\cdot 21 = 21 \\\\\n",
        "\\frac{\\partial L}{\\partial o_3}\n",
        "= \\frac{\\partial o_5}{\\partial o_3} \\frac{\\partial L}{\\partial o_5}\n",
        "= \\frac{\\partial (o_3 \\cdot w_5)}{\\partial o_3} (o_6 - y )\n",
        "= w_5 \\cdot (o_6 - y ) = 1 \\cdot 21 = 21\\\\\n",
        "\\frac{\\partial L}{\\partial o_2}\n",
        "= \\frac{\\partial o_4}{\\partial o_2} \\frac{\\partial L}{\\partial o_4}\n",
        "= \\frac{\\partial (o_2 \\cdot w_4)}{\\partial o_2} (o_6 - y )\n",
        "= w_4 \\cdot (o_6 - y ) = 4\\cdot 21 = 84 \\\\\n",
        "\\frac{\\partial L}{\\partial o_1}\n",
        "= \\frac{\\partial o_2}{\\partial o_1} \\frac{\\partial L}{\\partial o_2}\n",
        "= \\frac{\\partial (w_2 \\cdot o_1)}{\\partial o_1} (o_6 - y )\n",
        "= w_2 \\cdot (o_6 - y ) = 1 \\cdot 21 = 21\\\\\n",
        "\\frac{\\partial L}{\\partial o_1}\n",
        "= \\frac{\\partial o_3}{\\partial o_1} \\frac{\\partial L}{\\partial o_3}\n",
        "= \\frac{\\partial (w_3 . o_1)}{\\partial o_1} (o_6 - y )\n",
        "= w_3 \\cdot (o_6 - y ) = 2 \\cdot 21 = 42\n",
        "$$\n",
        "\n",
        "\n",
        "On the other hand, for the weights (note that $w_1$ is now updated twice because of the split in the first multiplication node), we obtain:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial w_5} = \\frac{\\partial o_5}{\\partial w_5} \\frac{\\partial L}{\\partial o_5} = \\frac{\\partial (o_3 w_5)}{\\partial w_5} (o_6 - y) = o_3(o_6 - y) = 8 \\cdot 21 = 168 \\\\\n",
        "\\frac{\\partial L}{\\partial w_4} = \\frac{\\partial o_4}{\\partial w_4} \\frac{\\partial L}{\\partial o_4} = \\frac{\\partial (o_2 w_4)}{\\partial w_4} (o_6 - y) = o_2(o_6 - y) = 4 \\cdot 21 = 84 \\\\\n",
        "\\frac{\\partial L}{\\partial w_3} = \\frac{\\partial o_3}{\\partial w_3} \\frac{\\partial L}{\\partial o_3} = \\frac{\\partial (o_1 w_3)}{\\partial w_3} w_5 (o_6 - y) = o_1 \\cdot w_5 (o_6 - y) = 4 \\cdot 1 \\cdot 21 = 84 \\\\\n",
        "\\frac{\\partial L}{\\partial w_2} = \\frac{\\partial o_2}{\\partial w_2} \\frac{\\partial L}{\\partial o_2} = \\frac{\\partial (o_1 w_2)}{\\partial w_2} w_4(o_6 - y) = o_1 \\cdot w_4(o_6 - y) = 4 \\cdot 4 \\cdot 21 = 336 \\\\\n",
        "\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial o_1}{\\partial w_1} \\frac{\\partial L}{\\partial o_1} = \\frac{\\partial (x w_1)}{\\partial w_1}  w_2 (o_6 - y) = x \\cdot w_2 (o_6 - y) = 2 \\cdot 21 = 42 \\\\\n",
        "\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial o_1}{\\partial w_1} \\frac{\\partial L}{\\partial o_1} = \\frac{\\partial (x w_1)}{\\partial w_1}  w_3 (o_6 - y) = x \\cdot w_3 (o_6 - y) = = 2 \\cdot 42 = 84\n",
        "$$\n",
        "\n",
        "**Update expressions**\n",
        "\n",
        "The learning rule is defined as:\n",
        "\n",
        "$$\n",
        "w = w - \\alpha \\frac{\\partial L}{\\partial w} \n",
        "$$\n",
        "\n",
        "For our weights, the results are:\n",
        "\n",
        "$$\n",
        "w_5 = w_5 - \\alpha \\frac{\\partial L}{\\partial w_5} = w_5 - \\alpha \\cdot o_3(o_6 - y) \\\\\n",
        "w_4 = w_4 - \\alpha \\frac{\\partial L}{\\partial w_4} = w_4 - \\alpha \\cdot o_2(o_6 - y) \\\\\n",
        "w_3 = w_3 - \\alpha \\frac{\\partial L}{\\partial w_3} = w_3 - \\alpha \\cdot o_1 \\cdot w_5(o_6 - y) \\\\\n",
        "w_2 = w_2 - \\alpha \\frac{\\partial L}{\\partial w_2} = w_2 - \\alpha \\cdot o_1 \\cdot w_4(o_6 - y) \\\\\n",
        "w_1' = w_1 - \\alpha \\frac{\\partial L}{\\partial w_1} = w_1 - \\alpha \\cdot x \\cdot w_2(o_6 - y) \\\\\n",
        "w_1 = w_1' - \\alpha \\frac{\\partial L}{\\partial w_1} = w_1' - \\alpha \\cdot x \\cdot w_3(o_6 - y)\n",
        "$$\n",
        "\n",
        "**Final value for all parameters**\n",
        "\n",
        "The final values of our paremeters (weights) are:\n",
        "\n",
        "- $w_5 = 1 - (0.1)(168) = - 15.8$\n",
        "- $w_4 = 4 - (0.1)(84) = -4.4$\n",
        "- $w_3 = 2 - (0.1)(84) = -6.4$\n",
        "- $w_2 = 1 - (0.1)(336) = -32.6$\n",
        "- $w_1' = 2 - (0.1)(84) = -6.4$\n",
        "- $w_1 = -6.4 - (0.1)(168) = -23.2$\n",
        "\n",
        "Our initial loss is $L = 220.5$\n",
        "\n",
        "And our final loss is $L = 4.5$\n"
      ]
    },
    {
      "metadata": {
        "id": "46evxwvv8CbC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Code explanation\n",
        "\n",
        "To ease the analysis of solution, we have removed the unused code from the original version. The code itself contains the comments to understand the modifications performed.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FVczYK9eKD_t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c992aac6-8cc8-4f1c-9559-6d9966603949",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523226107170,
          "user_tz": -120,
          "elapsed": 1047,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# %load basic_graph.py\n",
        "'''\n",
        "Implementations of nodes for a computation graph. Each node\n",
        "has a forward pass and a backward pass function, allowing\n",
        "for the evaluation and backpropagation of data.\n",
        "'''\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "import math\n",
        "import time\n",
        "\n",
        "# We still preserve the abstract class Node \n",
        "class Node(object):\n",
        "\n",
        "    def __init__(self, inputs):\n",
        "        self.inputs = inputs\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self):\n",
        "        ''' Feed-forward the result '''\n",
        "        raise NotImplementedError(\"Missing forward-propagation method.\")\n",
        "\n",
        "    @abstractmethod\n",
        "    def backward(self, d):\n",
        "        ''' Back-propagate the error\n",
        "            d is the delta of the subsequent node in the network '''\n",
        "        raise NotImplementedError(\"Missing back-propagation method.\")\n",
        "\n",
        "# ConstantNode is never affected. Its initial value is always preserved. Hence,\n",
        "# forward is just the replication of the value and backward does nothing, which\n",
        "# can be interpreted as the end of the backpropagation.\n",
        "# This node is used to represent the input x and the target y.\n",
        "class ConstantNode(Node):\n",
        "\n",
        "    def __init__(self, value):\n",
        "        self.output = value\n",
        "\n",
        "    def forward(self):\n",
        "        logging.debug(\"[ConstantNode] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    # Input never changes\n",
        "    def backward(self, d):\n",
        "        logging.debug(\"[ConstantNode] Nothing to backward. Value: {}\".format(\n",
        "            self.output))\n",
        "        pass\n",
        "\n",
        "# VariableNode is a value that can modify its value. For forward(), we only\n",
        "# replicate the output. For backward() we apply the learning rule with the\n",
        "# requested learning_rate. This is 1 of the ending nodes of the backpropagation\n",
        "class VariableNode(Node):\n",
        "\n",
        "    def __init__(self, value):\n",
        "        self.output = value\n",
        "\n",
        "    def forward(self):\n",
        "        logging.debug(\"[VariableNode] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    # Update the variable node according the learning rule\n",
        "    def backward(self, d, learning_rate = 0.1):\n",
        "        logging.debug(\"[VariableNode] Updated weight from {} to {}\".format(\n",
        "            self.output, self.output - learning_rate * d))\n",
        "        self.output -= learning_rate * d # Gradient Descent\n",
        "\n",
        "\n",
        "# Recall that Node has \"inputs\". AdditionNode just sums the forward values \n",
        "# of each input. For backward() it just backwards the parent nodes.\n",
        "class AdditionNode(Node):\n",
        "\n",
        "    def forward(self):\n",
        "        self.output = sum([i.forward() for i in self.inputs])\n",
        "        logging.debug(\"[AdditionNode] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d):\n",
        "        # Go backwards for each neuron connected (they should be mult.)\n",
        "        for i in self.inputs:\n",
        "            logging.debug(\"[AdditionNode] Backwarding parent node of class {} with value {} \".format(type(i), i.output))\n",
        "            i.backward(d)\n",
        "\n",
        "# Recall that Node has \"inputs\". MultiplicationNode just multiplies\n",
        "# two forwarded inputs. For backpropagation, the gradient is d * x\n",
        "class MultiplicationNode(Node):\n",
        "\n",
        "    def forward(self):\n",
        "        self.output = self.inputs[0].forward() * self.inputs[1].forward()\n",
        "        logging.debug(\"[MultiplicationNode] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d):\n",
        "          # Backwards to xi and wi, which are constant and variable, respectively\n",
        "          logging.debug(\"[MultiplicationNode] Backwarding parent node with value {}\".format(self.inputs[0].output))\n",
        "          self.inputs[0].backward(d * self.inputs[1].output)\n",
        "          logging.debug(\"[MultiplicationNode] Backwarding parent node with value {}\".format(self.inputs[1].output))\n",
        "          self.inputs[1].backward(d * self.inputs[0].output) \n",
        "\n",
        "# This is the MeanSquaredError node. It assumes that the second input is\n",
        "# the correct value. The first input is the prediction. Forward is the MSE error\n",
        "# presented in the formulas and backward is the gradient as presented in the\n",
        "# formulas\n",
        "class MSENode(Node):\n",
        "\n",
        "    def forward(self):\n",
        "        self.output = 0.5 * (\n",
        "            self.inputs[0].forward() - self.inputs[1].forward())**2\n",
        "        logging.debug(\"[MSENode] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d):\n",
        "          # Prediction\n",
        "          logging.debug(\"[MSENode] Backwarding prediction node with value {}\".format(self.inputs[0].output))\n",
        "          self.inputs[0].backward(d * (self.inputs[0].output - self.inputs[1].output))\n",
        "          # Real target\n",
        "          logging.debug(\"[MSENode] Backwarding target node with value {}\".format(self.inputs[1].output))\n",
        "          self.inputs[1].backward(d * (self.inputs[1].output - self.inputs[0].output))\n",
        "    \n",
        "\n",
        "# Relu function.\n",
        "# Forward is defined as max(0, x). Backward is given by the next equations:\n",
        "# f'(x) = 0 if x <=0 ; f'(x) = 1 if x > 0\n",
        "class ReLUNode(Node):\n",
        "\n",
        "    def forward(self):\n",
        "        self.output = max(0, self.inputs[0].forward())\n",
        "        logging.debug(\"[ReLUNode] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d):\n",
        "        logging.debug(\"[ReLUNode] Backwarding parent node with value {}\".format(self.inputs[0].output))\n",
        "        argument = 1 if self.output > 0 else 0\n",
        "        self.inputs[0].backward(d * argument)\n",
        "\n",
        "# The neuron has no significant changes\n",
        "class Neuron(Node):\n",
        "\n",
        "    def __init__(self, inputs, weights, activation):\n",
        "        ''' weights: list of initial weights, same length as inputs '''\n",
        "        self.inputs = inputs # Inputs are nodes also. Can be constant, variable, etc\n",
        "\n",
        "        # Initialize a weight for each input\n",
        "        self.weights = [VariableNode(weight) for weight in weights]\n",
        "\n",
        "        # Multiplication node for each pair of inputs and weights\n",
        "        mults = [MultiplicationNode([i, w]) for i, w, in zip(self.inputs, self.weights)]\n",
        "\n",
        "        # Sum all multiplication results\n",
        "        added = AdditionNode(mults)\n",
        "\n",
        "        # Apply activation function\n",
        "        if activation.lower() == 'sigmoid':\n",
        "            self.graph = SigmoidNode([added])\n",
        "        elif activation.lower() == 'relu':\n",
        "            self.graph = ReLUNode([added])\n",
        "        elif activation.lower() == 'tanh':\n",
        "            self.graph = TanhNode([added])\n",
        "        else:\n",
        "            raise ValueError(\"Unknown activation function.\")\n",
        "\n",
        "    def forward(self):\n",
        "        # Evaluates the activation function\n",
        "        self.output = self.graph.forward()\n",
        "        logging.debug(\"[Neuron] Fordwarding value = {}\".format(self.output))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d):\n",
        "        logging.debug(\"[Neuron] Backwarding with d = {}\".format(d))\n",
        "        # Go back from the activation function\n",
        "        self.graph.backward(d)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [weight.output for weight in self.weights]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"Loaded simple graph nodes\")\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nImplementations of nodes for a computation graph. Each node\\nhas a forward pass and a backward pass function, allowing\\nfor the evaluation and backpropagation of data.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded simple graph nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mn-lvP2TKD_z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "## The input layer contains only constant nodes, this is, the x variables. We ##\n",
        "## implement the backward of each node, but since the backward of constant is ##\n",
        "## skipped, it does not affect. ################################################\n",
        "################################################################################\n",
        "class InputLayer(Node):\n",
        "    \n",
        "    def __init__(self, x, name = None):\n",
        "        self.nodes = [ConstantNode(xi) for xi in x]\n",
        "        self.name = name\n",
        "        \n",
        "    def forward(self):\n",
        "        pass # No need to compute forward of constant nodes\n",
        "    \n",
        "    def backward(self, i):\n",
        "          for node in self.nodes:\n",
        "              node.backward(None)\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"Input Layer '{}' with {} inputs\".format(self.name, len(self.nodes)))\n",
        "        for i in range(len(self.nodes)):\n",
        "            print(\"\\tx{}: {}\".format(i, self.nodes[i].output))\n",
        "\n",
        "\n",
        "################################################################################\n",
        "## The hidden layer receives an input layer or another hidden layer, then we  ##\n",
        "## have to handle both cases. If it is an input layer, then we call the nodes ##\n",
        "## otherwise, we call the neurons. This could be also be fixed by calling the ##\n",
        "## neurons nodes, but we prefer making the distinction for clarity.           ##\n",
        "## Additionally, for forward we just forward the values of the neurons. For   ##\n",
        "## backward() we do nothing since everything should be backpropagated from    ##\n",
        "## the output layer. ###########################################################\n",
        "################################################################################\n",
        "class HiddenLayer(Node):\n",
        "    \n",
        "    def __init__(self, parentLayer, num_neurons, weights = None, activation ='sigmoid', name = None):\n",
        "        \n",
        "        # Random weights if we do not specify\n",
        "        if weights == None:\n",
        "            weights = []\n",
        "            for c in range(len(num_neurons)):\n",
        "                weights.add(np.random.uniform(0,5, len(inputLayer.nodes)))\n",
        "            \n",
        "        # If an InputLayer, my inputs are the parentLayer.nodes\n",
        "        if isinstance(parentLayer, InputLayer): \n",
        "            self.neurons = [Neuron(parentLayer.nodes, weights = weights[i], activation = activation)\n",
        "                for i in range(num_neurons)] # As many identical neurons as requested\n",
        "        \n",
        "        # If another HiddenLayer, then my inputs are the neurons\n",
        "        if isinstance(parentLayer, HiddenLayer):\n",
        "            self.neurons = [Neuron(parentLayer.neurons, weights = weights[i], activation = activation)\n",
        "                for i in range(num_neurons)] # As many identical neurons as requested\n",
        "\n",
        "        self.name = name\n",
        "        \n",
        "    def forward(self):\n",
        "        for neuron in self.neurons:\n",
        "            neuron.forward()\n",
        "\n",
        "    def backward(self, i):\n",
        "        pass\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"Hidden Layer '{}' with {} neuron(s)\".format(self.name, len(self.neurons)))\n",
        "        for i in range(len(self.neurons)):\n",
        "            print(\"\\tn{} with input weights : {}\".format(i, self.neurons[i].get_weights()))\n",
        "    \n",
        "\n",
        "################################################################################\n",
        "## The output layer receives a hidden layer for us, but we could receive also ##\n",
        "## an input layer, hence we make the distinction again for clarity.           ##\n",
        "## The output layer has only the MSE node. Even if have a for loop, in our    ##\n",
        "## problem we only have one MSE node. Forwarding and backwarding is just the  ##\n",
        "## backward of the activation function which will trigger the other values.   ##\n",
        "################################################################################\n",
        "class OutputLayer(Node):\n",
        "    \n",
        "    # TODO: is it realy just one target?\n",
        "    def __init__(self, parentLayer, target, activation = 'mse', name = None):\n",
        "        self.name = name\n",
        "        \n",
        "        if isinstance(parentLayer, HiddenLayer): \n",
        "            self.nodes = [] # MSE nodes\n",
        "            for neuron in parentLayer.neurons:\n",
        "                self.nodes.append(MSENode([neuron, ConstantNode(target)]))\n",
        "            self.graph = AdditionNode(self.nodes)\n",
        "\n",
        "    def forward(self):\n",
        "        self.output = self.graph.forward()\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, i):\n",
        "        self.graph.backward(i)\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"Output Layer '{}' (MSE) with {} neuron(s)\".format(self.name, len(self.nodes)))\n",
        "        for i in range(len(self.nodes)):\n",
        "            print(\"\\tExpected value for n{} : {}\".format(i, self.nodes[i].inputs[1].output))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NZbopUECKD_1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4905bc89-b4eb-476e-ff11-502509fcfd81",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523226129463,
          "user_tz": -120,
          "elapsed": 1885,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "## Final model. This can be also understood as the compute graph. It is a set ##\n",
        "## of layers, starting from the input layer. neural_network has the final     ##\n",
        "## graph and then we forward from it to recursively obtain the answers. We    ##\n",
        "## print the result and then we backpropagate. We show the final weights and  ##\n",
        "## finally we print the new MSE. One can observe that we reduced the error    ##\n",
        "## significantly with just one passing, but obtained negative weights.        ##\n",
        "################################################################################\n",
        "\n",
        "inputLayer = InputLayer(x = [2], name = \"Input\")\n",
        "inputLayer.summary()\n",
        "\n",
        "# # First hidden layer\n",
        "hL1 = HiddenLayer(parentLayer = inputLayer, num_neurons = 1, weights = [[2]], activation = \"relu\", name = \"HL1\")\n",
        "hL1.summary()\n",
        "\n",
        "hL2 = HiddenLayer(parentLayer = hL1, num_neurons = 2, weights = [[1], [2]], activation = \"relu\", name = \"HL2\")\n",
        "hL2.summary()\n",
        "\n",
        "hL3 = HiddenLayer(parentLayer = hL2, num_neurons = 1, weights = [[4, 1]], activation = \"relu\", name = \"HL3\")\n",
        "hL3.summary()\n",
        "\n",
        "neural_network = OutputLayer(parentLayer = hL3, target = 3, activation = \"mse\", name = \"Output\")\n",
        "neural_network.summary()\n",
        "\n",
        "res = neural_network.forward()\n",
        "\n",
        "print(\"\\nLoss: {}\".format(res))\n",
        "\n",
        "print(\"\\nBack-propagating...\")\n",
        "neural_network.backward(1.0)\n",
        "\n",
        "print(\"Showing layers after back-propagation...\\n\")\n",
        "inputLayer.summary()\n",
        "hL1.summary()\n",
        "hL2.summary()\n",
        "hL3.summary()\n",
        "neural_network.summary()\n",
        "\n",
        "res = neural_network.forward()\n",
        "print(\"\\nLoss : {}\".format(res))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Layer 'Input' with 1 inputs\n",
            "\tx0: 2\n",
            "Hidden Layer 'HL1' with 1 neuron(s)\n",
            "\tn0 with input weights : [2]\n",
            "Hidden Layer 'HL2' with 2 neuron(s)\n",
            "\tn0 with input weights : [1]\n",
            "\tn1 with input weights : [2]\n",
            "Hidden Layer 'HL3' with 1 neuron(s)\n",
            "\tn0 with input weights : [4, 1]\n",
            "Output Layer 'Output' (MSE) with 1 neuron(s)\n",
            "\tExpected value for n0 : 3\n",
            "\n",
            "Loss: 220.5\n",
            "\n",
            "Back-propagating...\n",
            "Showing layers after back-propagation...\n",
            "\n",
            "Input Layer 'Input' with 1 inputs\n",
            "\tx0: 2\n",
            "Hidden Layer 'HL1' with 1 neuron(s)\n",
            "\tn0 with input weights : [-23.200000000000003]\n",
            "Hidden Layer 'HL2' with 2 neuron(s)\n",
            "\tn0 with input weights : [-32.6]\n",
            "\tn1 with input weights : [-6.4]\n",
            "Hidden Layer 'HL3' with 1 neuron(s)\n",
            "\tn0 with input weights : [-4.4, -15.8]\n",
            "Output Layer 'Output' (MSE) with 1 neuron(s)\n",
            "\tExpected value for n0 : 3\n",
            "\n",
            "Loss : 4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WtWXWzL8KD_5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Deep Models (3 points)\n",
        "\n",
        "The model in the example code below performs poorly as its depth increases. Train this model on the MNIST digit detection task. \n",
        "\n",
        "Examine its training performance by gradually increasing its depth:\n",
        "- Set the depth to 1 hidden layer\n",
        "- Set the depth to 2 hidden layers\n",
        "- Set the depth to 3 hidden layers\n",
        "\n",
        "Modify the model such that you improve its performance when its depth increases. Train the new model again for the different depths:\n",
        "- Set the depth to 1 hidden layer\n",
        "- Set the depth to 2 hidden layers\n",
        "- Set the depth to 3 hidden layers\n",
        "\n",
        "Submit an explanation for the limitation of the original model. Explain your modification. \n",
        "Submit your code and 6 plots (can be overlaid) for the training performance of both models with different depths. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pl05iNzwKD_5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aec17c6-502f-49f5-89e2-d35ec1768442",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523460767742,
          "user_tz": -120,
          "elapsed": 7845,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# (You don't need to change this part of the code)\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 10\n",
        "nb_epoch = 10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zcfCO79LKD_8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3480df74-ef6e-437c-c110-3526dd34c7ca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523460770991,
          "user_tz": -120,
          "elapsed": 1567,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# (You don't need to change this part of the code)\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOi_mvTVy7b1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we run all 3 possible models with the original parameters. For ease we show all 3 possible model accuracies overlaid. "
      ]
    },
    {
      "metadata": {
        "id": "SmEFncbWeFox",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2861
        },
        "outputId": "3a5ca580-8ece-494b-8dd8-7f63ef0af99a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523460990022,
          "user_tz": -120,
          "elapsed": 100329,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#------------------------ Original Models-----------------------\n",
        "trainlegend = ['train1','train2','train3']\n",
        "testlegend = ['test1','test2','test3']\n",
        "myColors = ['r', 'g', 'b', 'y']\n",
        "plt.figure(figsize = (10, 8))\n",
        "for i in range(3):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_shape=(784,), activation='sigmoid'))\n",
        "  model.add(Dropout(0.2))\n",
        "  number_hidden_layers=i\n",
        "  while number_hidden_layers >= 1:\n",
        "      model.add(Dense(512))\n",
        "      model.add(Activation('sigmoid'))\n",
        "      model.add(Dropout(0.2))\n",
        "      number_hidden_layers -= 1\n",
        "  number_hidden_layers = number_hidden_layers+1\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(),\n",
        "                metrics=['accuracy'])\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
        "                    verbose=1, validation_data=(X_test, Y_test))\n",
        "  score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  # list all data in history\n",
        "  print(history.history.keys())\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'], c = myColors[i], label = \"Train \" + str(i)) #change style and color\n",
        "  plt.plot(history.history['val_acc'], c = myColors[i], label = \"Test\" + str(i), linestyle = \"--\")\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  #plt.legend([trainlegend[i], testlegend[i]], loc='upper left')\n",
        "plt.legend()\n",
        "#plt.gca().set_color_cycle(['red', 'green', 'blue', 'yellow'])\n",
        "plt.show()\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 2.0278 - acc: 0.3393 - val_loss: 1.6435 - val_acc: 0.7408\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.4812 - acc: 0.6264 - val_loss: 1.1954 - val_acc: 0.8072\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.1348 - acc: 0.7234 - val_loss: 0.9244 - val_acc: 0.8332\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.9259 - acc: 0.7673 - val_loss: 0.7665 - val_acc: 0.8470\n",
            "Epoch 5/10\n",
            "48896/60000 [=======================>......] - ETA: 0s - loss: 0.8061 - acc: 0.7916"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.7981 - acc: 0.7915 - val_loss: 0.6666 - val_acc: 0.8532\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.7176 - acc: 0.8092 - val_loss: 0.6002 - val_acc: 0.8653\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.6592 - acc: 0.8207 - val_loss: 0.5517 - val_acc: 0.8715\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.6117 - acc: 0.8323 - val_loss: 0.5160 - val_acc: 0.8739\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.5821 - acc: 0.8369 - val_loss: 0.4885 - val_acc: 0.8784\n",
            "Epoch 10/10\n",
            "17408/60000 [=======>......................] - ETA: 1s - loss: 0.5671 - acc: 0.8398"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.5553 - acc: 0.8428 - val_loss: 0.4666 - val_acc: 0.8818\n",
            "Test score: 0.46660534963607786\n",
            "Test accuracy: 0.8818\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "57856/60000 [===========================>..] - ETA: 0s - loss: 2.3321 - acc: 0.1193"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 58us/step - loss: 2.3304 - acc: 0.1203 - val_loss: 2.2318 - val_acc: 0.2801\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.2487 - acc: 0.1684 - val_loss: 2.1447 - val_acc: 0.5262\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.1533 - acc: 0.2452 - val_loss: 2.0311 - val_acc: 0.6075\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.0268 - acc: 0.3362 - val_loss: 1.8739 - val_acc: 0.6258\n",
            "Epoch 5/10\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 1.8527 - acc: 0.4294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 54us/step - loss: 1.8521 - acc: 0.4297 - val_loss: 1.6636 - val_acc: 0.6888\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 1.6426 - acc: 0.5089 - val_loss: 1.4361 - val_acc: 0.7007\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 1.4364 - acc: 0.5732 - val_loss: 1.2320 - val_acc: 0.7693\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 1.2568 - acc: 0.6248 - val_loss: 1.0677 - val_acc: 0.7790\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 1.1196 - acc: 0.6605 - val_loss: 0.9460 - val_acc: 0.7879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 1.0140 - acc: 0.6918 - val_loss: 0.8538 - val_acc: 0.7968\n",
            "Test score: 0.8538445023536683\n",
            "Test accuracy: 0.7968\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40704/60000 [===================>..........] - ETA: 1s - loss: 2.3655 - acc: 0.1028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 64us/step - loss: 2.3610 - acc: 0.1045 - val_loss: 2.2966 - val_acc: 0.1136\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.3491 - acc: 0.1043 - val_loss: 2.2947 - val_acc: 0.1028\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.3364 - acc: 0.1101 - val_loss: 2.2890 - val_acc: 0.1010\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.3315 - acc: 0.1100 - val_loss: 2.2841 - val_acc: 0.2117\n",
            "Epoch 5/10\n",
            "41856/60000 [===================>..........] - ETA: 1s - loss: 2.3204 - acc: 0.1162"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 59us/step - loss: 2.3190 - acc: 0.1161 - val_loss: 2.2775 - val_acc: 0.1169\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.3098 - acc: 0.1212 - val_loss: 2.2707 - val_acc: 0.1660\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 2.3021 - acc: 0.1245 - val_loss: 2.2641 - val_acc: 0.3015\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.2927 - acc: 0.1353 - val_loss: 2.2555 - val_acc: 0.2144\n",
            "Epoch 9/10\n",
            "41856/60000 [===================>..........] - ETA: 1s - loss: 2.2859 - acc: 0.1392"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.2829 - acc: 0.1418 - val_loss: 2.2469 - val_acc: 0.2633\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 2.2707 - acc: 0.1556 - val_loss: 2.2314 - val_acc: 0.2658\n",
            "Test score: 2.2314223358154295\n",
            "Test accuracy: 0.2658\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHvCAYAAABqnbr1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd8U/X+x/HXyWraJi100UWBMmXv\nqaJsZLoQFMGJG/U6wetEwXnVn+NerxMFFQdXwQGKIIoiyAZlSYECbaG7TbNzzu+PpGlrGY62aenn\n+Xj00SY5Ofmkh5Z3v1PRNE1DCCGEEELUCV2oCxBCCCGEaEwkfAkhhBBC1CEJX0IIIYQQdUjClxBC\nCCFEHZLwJYQQQghRhyR8CSGEEELUIQlfQogG47777uOFF1446TGLFy/miiuuqJuChBDiL5DwJYQQ\nQghRhyR8CSFqxeHDhznzzDN59dVXGTlyJCNHjmTLli3MmDGDs846i1mzZgWP/fLLLxk7diyjRo1i\n2rRpZGZmAlBYWMhVV13FkCFDmDFjBqWlpcHn/Pbbb0ydOpWRI0cybtw4tm/ffsqaXnrpJUaOHMmw\nYcO47rrrKCkpAcDpdHL33XczZMgQRo8ezaeffnrS+++9915efvnl4Hkr3x4yZAgvvvgiI0eOJCsr\ni4yMDKZMmcLo0aMZPnw4n332WfB53333HWPGjGHkyJFcd911FBUVMXPmTF5//fXgMXv27KF///54\nvd4/fQ2EEPWThC8hRK0pLCwkPj6e5cuX0759e26//XYef/xxlixZwmeffUZmZiZZWVncf//9vPTS\nSyxbtoxzzjmHBx54AIBXX32Vpk2bsnLlSh544AHWrFkDgKqq3HTTTUyYMIHly5fz0EMPceONN540\noOzYsYOFCxfy8ccf89VXX+F2u1mwYAEAb7zxBh6Ph5UrV/Lmm28yZ84cjh49esL7T+Xo0aMsX76c\n5ORknnzySc4991y+/PJL5s6dy3333YfH48Fut3PXXXfx7LPPsnz5ctLS0nj++ecZO3ZslYD29ddf\nM2LECAwGw9+5FEKIekR+moUQtcbr9TJq1CgA2rVrB0BMTAwA8fHxHDt2jP3799OvXz9atGgBwMUX\nX8xTTz2F1+tlw4YNzJgxA4DU1FT69u0LQEZGBvn5+Vx00UUA9OrVi5iYGDZv3nzCWjp37sy3336L\nyWQCoEePHhw6dAjwt0Bdc801ACQmJrJ69WoiIyNPeP+pnHPOOcGvX375Zcp3cevVqxcul4vc3Fwy\nMjJITEwMfl/uuusuADRNY9asWWRkZJCens6KFSu45557TvmaQoiGQ8KXEKLW6PV6zGYzADqdjoiI\niCqP+Xw+CgsLiYqKCt5vtVrRNI3CwkKKi4uxWq3Bx8qPKykpwel0Mnr06OBjNpuNoqKiE9bicDiY\nN28e69atA6C4uDgYkgoLC6u8TnnAOtH9pxIdHR38+vvvv+ff//43hYWFKIqCpmmoqlrtfZeHQiDY\nPXnRRReRm5sbDJ1CiNODhC8hREjFxsZWabEqLi5Gp9PRtGlToqKiqozzKigooHnz5iQkJBAZGcmy\nZcuqnW/x4sXHfZ358+dz4MABFi9eTGRkJM8++2ywC7Fp06YUFhYGj83JySE6OvqE9+t0OlRVrVLz\n8Xg8Hm677Taee+45Bg8ejNvtpmvXrsd9TYfDQXFxMYmJiYwZM4Z58+ZhtVoZOXIkOp2MEBHidCI/\n0UKIkBo0aBAbNmwIdgG+//77DBo0CIPBQPfu3VmxYgUAmZmZbNy4EYCUlBQSExOD4augoIB//OMf\n2O32E75Ofn4+6enpREZGcuTIEVavXh08fsiQIXzyySdomkZubi4TJ06ksLDwhPfHx8eza9cuAA4d\nOsSmTZuO+5oOhwO73U7nzp0BfwA0Go3Y7XZ69epFbm4u27ZtA/zdky+99BIAAwcOpKioiHfeeadK\n654Q4vQgLV9CiJBKTEzk0Ucf5cYbb8Tj8ZCamsqcOXMAuO6667j99tsZMmQIrVu3ZsSIEQAoisK/\n/vUvHnroIZ577jl0Oh1XXnlllW7N35s8eTIzZ85k5MiRtG/fnnvvvZdbbrmFt956iyuuuIKDBw9y\n7rnnYjabueeee0hOTj7h/ZMmTeLmm29mxIgRdOzYkZEjRx73NaOiorjmmmuYOHEisbGx3HDDDQwb\nNozrr7+ezz77jBdeeCE41qtFixY8/vjjgL9LdtSoUXzzzTf06tWrJr/dQoh6QNHKR4IKIYSoN159\n9VUKCwu5++67Q12KEKKGSbejEELUMwUFBXzwwQdMmTIl1KUIIWqBhC8hhKhH3n//fS688EKuvfZa\nmjdvHupyhBC1QLodhRBCCCHqkLR8CSGEEELUIQlfQgghhBB1qMEsNZGbW3rqg2pA06YRFBaeeK0g\nUb/J9Wv45Bo2fHINGza5fjUjPt56wsek5et3DAZ9qEsQf4Ncv4ZPrmHDJ9ewYZPrV/skfAkhhBBC\n1CEJX0IIIYQQdUjClxBCCCFEHZLwJYQQQghRhyR8CSGEEELUoVoNX3PnzuWSSy5h8uTJbNu2rcpj\nK1as4MILL2TKlCksWLCgNssQQgghhKg3ai18rV+/noMHD7Jo0SIee+wxHnvsseBjqqoyZ84cXn31\nVRYuXMiqVavIycmprVKEEEIIIeqNWgtfa9euZdiwYQC0bt2a4uJibDYbAIWFhURFRRETE4NOp6N/\n//78+OOPtVWKEEIIIUS9UWsr3Ofl5dGpU6fg7ZiYGHJzc7FYLMTExFBWVsaBAwdISUlh3bp19O3b\n96Tna9o0os4WfjvZqrSi/pPr1/DJNWz45Bo2bHL9aledbS+kaVrwa0VRePzxx5k9ezZWq5XU1NRT\nPr+utjqIj7fW2VZGoubJ9Wv45Bo2fHINGza5fjXjZAG21sJXQkICeXl5wdvHjh0jPj4+eLtv3768\n++67ADzzzDOkpKTUVilCCCGEEPVGrY35GjRoEMuXLwfgl19+ISEhAYvFEnz8mmuuIT8/H7vdzqpV\nqxgwYEBtlSKEEEIIUW/UWstXz5496dSpE5MnT0ZRFB588EEWL16M1Wpl+PDhTJo0iauuugpFUZgx\nYwYxMTG1VYoQQgghRL2haJUHY9VjddX/LH3dDZtcv4ZPrmHDJ9ewYZPrVzNONuZLVrgXQgghhKhD\nEr6EEEIIIepQnS01IYQQQghRZzQN3G4UlxOcLjSLBSIiQl0VIOFLCCGEELVIyctDcTn9IchVEYbU\nZs1QW6UDYPxxDfr9GeB0orhcgWNdaLGxOK69wX/M96sxv/1m4FwuCBynOF0UffI5WnQTdIcP0fSc\ngShuF4rTWaWOkv+8juuCi+v8/R+PhC8hhBDidKZp/g+df6SR7vAhlMJCFIcDxV7m/+ywo8bE4jln\nCADGH77HtHIFBMKN4nb5v3Z7KHlzAQD6XTux3jQjGIAIBCzF5aL4nUV4zj4HgJj+PdCVFFcry37j\nTMoeehQA81uvYf5kcbVjvGd0CoYv3ZHDmD+teowWFoYWZganC6JBCzOjpjZHMwfuDwtDM5vRTGGo\nSck18/2sARK+hBBCiFDyeoMhCLs9GIbw+vD26w/4A5Np+ZfVApNit1N2z32oKang8dBk/EgUu/9+\nHA7/1w47Zf98GMdNMwGw3nI9ph++r1aG+6xzKA6EL8PGDUS88OwJ68VgAJ/P31plDkMzhaFFRKDF\nxPgDkTk8eLhr7HgUlwvNHAhDJn8g8vSvWN/TOf1q3ENHgNmMFmZGCwsDsxnVGlVxnnETyRsyPPh6\nmEzBQFlOi4+n8Nv6v1e0hC8hhBCiMq8XxekAjwfcHhSvxz92yOvF17IVGI3gcmH6/lt/wCkrD0P+\nYOQeMQpv1+4ARD70T/T79qLYK8ISDjueIcOwzXvaf8wjDxDxnxerlaE2aUL+nkwA9Hv3YJ1153HL\ndVx5jT98GQwYdv6KZjKhRUSiWa2ozRIhPBy10g4z7vPG4u3UGcIj0MLD/aEpPAJf8+bBY1wXTcIz\ncJA/LFUKQ5rJBHr/Psu+Tp3Jzzhyym+n7bmXTnmMZ9BZpzyGyEi0yMhTH9cASPgSQghRO8rH7ni8\nKB43eDwoHjea0YTaPA0AXXYW+ox9gXBTNey4LrgY9HqU/HzMH77nfyx4Hg94PDinTMV3RkcALPfe\ngZKfj+J2g9cT+OzFPeo8HNfdBEDkow9hWvoJitdb5TXVtBYUrvoBgLBPPibqxmuP+5byN+5AbZ6G\nYrMRfenxxw+p8QnB8GX84XuMWzcDoBkM/lAUHg4eb/B4b8dOuEaO9geh8AgIhCEtqqLVx9upC8Wv\nzYfw8OA5tPAItIgI1MQk/0GKQt6BnFNelvJuvJNRk1NQk2Xbv9oi4UsIIUQFlwtdTjZKaSk6WylK\naQlKSQlKaSmuMePR4uNB07Decj1KaSmKrTTweAm60lLsN98GD8wCIHraZEyrvqn2Eu7+AylesgyA\nsE8XY3lg9nFLyR0zHiIi0OXlnvAYT78BwfBlWvYF+qzqLTG+tu0qvT+nv/XJZEKLjEQzGquEQQA1\nJRXX8JFgMPpbeoxGNKMRjCZ/OAI0qxXbPx9GiwiH34UhX7v2wXMVv78YDHq0iEh/i9nxvuWTL8M1\n+bLjPlZOS0jAPf78kx4jGg4JX0IIcRpQiotQiov9oanUH4aU0lLU2Dg8g88FwPTl54R9sdQflsqD\nVWkpqCqF67YAYNywnibnjznua3g7dMQbHw+KQtjST/xjlMDf+mKxokZH+8NKgKdXH/9tgxHNFAgv\nRiO+9DZVjim74x5/GDIYweQPQxiN/nFFgJqSQvH898Bo8D9mMqEZDGAy+bsBA4qWr0JTdGA0BAJT\n4DyVxgWVzXmcsjmPn/R76RkwCM+AQSf/hptMOGbefvJjAC029pTHiMZHwpcQQoSKz1elZcnf2uT/\n2j10OFpUNLhcRD78T3SBx/0f/pBln/kPXFOmAhA95SKMG9ZXewn3kGEUB8KXYecvmBe9G3xMCw9H\nC4QmNA0UBV9yCs5JU1CjotCsVjRLFFrga1/ritBU8ONGf8uRxRoMSeXKN1Wx33381qrKvH364e3T\n76THaBYr7tHHD4SVqc0ST3mMEPWBhC8hhKgFugP7Mez8FV3WEfTZWeiyjqDLzgKfL9jlZvrmK6Kn\nXnLc5xd8swZfl65gMBDx2itVHisPTeUtT+APWb701v5B1tYoNGsgMFVqGXJMvxrnhZP8ocoaddxu\nMLVVOqUvvlLt/mrHpaT+oe+DEKI6CV9CCPEnGbZvRbc/A33WEXTZ2eiyj6DPysLTrTtljz0JQPg7\nbx13qr6v0tgiX0pzXKPGBMKQPxCpgdAUHESt11Ow8gc0i8XfAmWx+qfY/479zntPWbcWGyvdYELU\nAxK+hBCinKpi/OnHQCtVRajSZR/BccU1wS6+yH/ei2ntD1Wequl0qHGVpvMPH4kaG4eanIwvMRk1\nOdkfqCoFJ1+nzpS8/d4py/J17lJDb1AIUR9I+BJCNAqKrRTDxg3+pQ2ys9AFQpUuKwvb8y/h7dIN\nFIXoSRP9SxRUoplM6I9WTOF3TrsS99jx+JJS/KEqKRk1PqHK2CdP/4F4+g+ss/cnhGg4JHwJIRo8\nXU42hh3b/IEq6wi6nGx/l+DRoxSuXAN6PfqMfTS5eEK152oRkSi5uf4bikLZvfejRUYG1jlKxpeU\n4u+qU5Tgc1wXTqqrtyaEOA1J+BJC1Gv63/ai37un6sD1nGzU+HhKX3kTANMXn2G9945qz1WbNEEp\nLESLi8PXoiVld81CTU7Bl5QcDFeaNapKsHLcfGudvTchROMk4UsIUXu83uBaUuUfvtZt/At1AuY3\nX0OXkxVYm8r/OMUFhJ8zDMet/jAV8a8nMX+0qNqpPd16VHzdbwC2+x5ETUyqaLFKTIZKW5Fo0U2w\n3zWrlt+wEEKcmoQvIUR1Xm9gEc5AINI0fJ06A6D/9RdMK1egBNaj0pWWBtepKp7/Llgs6A4eIGZw\nf/9K4r9T8sobuM6/CIDwV17CkLGv6gF6PfrWFSuEuyZegLdz11MOXHcE6hNCiPpOwpcQpxOfr9J2\nL6Woqan+hTqBsPcXosvPD7RElQRbmtzDRuC8bBoAln/cgnnxh9VCk7djZwq//REAw9bNWB65/7gv\nryspRrVY0CxWvG3bB5dGKF9KQY2KwtumYquX8g13VYs1uJBnXOtUbAUVr+8eMRpG1Ny3SAghQk3C\nlxD1mc2G/sB+9Icy0R86iO7wYZTiInSlpZS8+pa/lWjPbqIvHOcPU/ayKk8vXrDIH16AyMcerjJj\nr5waHw+B8KXGxftDk9XqD03lK5unVqxN5Tn7HIoXLKqyJlX58eWtUVpsLEVfrz7l2zvubEC9/o9+\nd4QQokGS8CVEqGgaSlEh+kOZ6A4d8oerQ5loFgv2WQ8AEL5wPpb7jz9OSbGVokU38a92HhGBt1li\ntZYmX1JK8Hjb08+Dgj80WSoW9dSiooLH2Gc/gH32AyctW01JxS2rmwshxF8m4UuI2qJpKAUFwVCl\nP3QIX+s2uEf6W6Kst1yP+YPqC2z60loGw5enVx8cV16Dr3kLfGlpqKnNUZvGoEVF+2fpAWrztOCm\nyCdT/rpCCHFac7urjFnV2Uqr3FbKynCPGImvdduQlSjhS4i/StNQcnPRH85EfygTT5duqOmtAYie\nNBHj+nXVugGdF1wUDEHert1wFRfha56Gmprm/5yWVqWLz9u7L7befevuPQkhRCioKkqZDcVmC4Sk\nSrOky2zoKt+22fyP2ypu6yrfdrlO+XKOPbuwPftiHbyx45PwJcSJaBrKsWPoDx3E26kLhIej2EqJ\numa6vyXr8KEqGxuXznsKZyB8aWFh+Fql42ue5m+xau4PVb72HYLHO2bciGPGjXX+toQQokZoGrhc\nwbCkK7NVWlampCJIVZ4Z/bv7ym/rbKV/uYzyYRRq0xi0tBZoloqxqKrFEhiTGrjPYkGzRuEZOKgG\nvxF/noQv0XipKkp+fnDNKf1vewn/9wuBMViZ6I8cRnE6ASj86lu83XuiRURiXPMdWmQk3rbtUVOb\nB1usPAPPCp665J3q61IJIUTIaJq/O85ehuJwoNjtKA47lPk/l99W7HbQ+YjIyQuEo4ogpQu2PFUK\nVx7PXysnLCw4UccXF483GJICY1HLb1ut/ok9Fmul+yoFqUgL6HQ1/M2qfRK+xOlL04Irlxu2bcH0\nzdf+UJWZie6wv+UKTSPvUC7odChlNsLfeQsANTYWb4czUJu3wJfaHDW6if+cOh15uw9WWbxTCCH+\nNlUFp7NKCAp+tpeBw4FSVjU4BQNUldsOf8Cy24MfOBz+x32+P1zO8X7DaTpdMBipzRLRWlfMdFYr\nzXquPOnH3/pUNUxVnhndWEn4Eg2fz4f+118wrl8Le3cSvXcf+syD+NJaUvzxEgAMP68jct6c4FPU\nuHi8nbvga94CxV7mX5eq/RkUfL8eX2rzk4crCV5CNE6a5m/xyc+vCDm/C0M47CjHaU1SHA4oD0W/\nD0qBc9RYmSYTWkQEWngEalQUWmISBGZFa+ER/s/lH+EREBERmDUdiRYRQVRiLEWqoVJLlBXVYoWI\niCpbcYm/TsKXaHjKytAVF6Em+5dRsN50LebFHwUfNgG+ZoloVmvwPvfwURS1Sve3ZKWk+n+J/J7Z\nXGVMlhCiEXG70R3NQZedje5otn8f0exsdDmBj+ws9Dk51SbR/BVapSCkxsZVCUWER1QNScFQFA6B\ncFTtscBnIsL9YcrwN/9rj7fiyf3rY7DEqUn4EvWecuwYxvU/YVy3FuP6tRi2b8M9fBQl898FwD1k\nOFp4BJ5+A4gaNphcSxyYzVXOoaa1QE1rEYryhRChFFjyRZedhf5otj9QZWehy8lBl+MPWPqcbHR5\nuSc9jRoXjze9NWpSElp5YKoUfIKBKiLQklTtMf9nwsMb5BglUbMkfIn6RdOgrAwsFgCsN19XZS0s\nzWDA26073m7dg/e5Jk3BNWmK/0a8FeQvNiEaB4cDXU4gPP2upUpfHrCOZp906QEtIgJfYhLe9h38\nG7MnJqEmJeFLSq643Syx0Y9REjVLwpcILbcbw7YtGNcFWrZ+/gn3sJGUvvAfALxndMI9ZBiefgP8\nH917Hr/LUAhx+vD5UPLy0AdapnTZWegCrVb67KxA92AWuqKiE55C0+lQE5rh7dgJNTEZNTERNSkZ\nX2ISanmwSkryL1Ys45hEHZPwJepWpRmIlrtux7xoYXA5BwBfSipqTGzwtuOmmThumlnnZQohaodi\nK63U9VeplSow1sr/OeekM/PUqGjUpCS83XqgJv6ulSopEK7iE2SfUFFvSfgStUp3+JC/RWvdWozr\n1+E+8yzKHn0C8A869aW3wdOvv79Vq29/1NTmIa5YCPGXeDzojh1Fl50FjmLMu/ehD7Za5VR0C5bZ\nTngKzWhETUzC26OXv5UqKalKq5WalISvWZLMOBYNnoQvUSsiH76fsE8+Rn/kcPA+zWxG6dUneLvs\n4ccok+Z+Ieo3Va0+YD0nu2LAek4O+pxslLxcFE0LPs36+9PExKC2aImnvGWqWaVAlehvudJiY2Uw\numgUJHyJv85ux7h5Y3AmonvQ2ThuuQ0ApSAfxenANXpsYLxWf7xdulUdtCrBS4iQUkpL/CEq2AXo\nD1T6nJyKJRaO5px0FXMtPNw/jqptO38LVbMkItq2osQag69ZoBuwWWK1GchCNGYSvsSfFvHc05iW\nf4Fh6xYUrzd4f+WxWrbHnsT23EsSsIQIBZerIkwdrTTzL6fSulU5OSfvAjQYUJsl4u3aDTUQonyB\nmX+nGrAeEW/FJbOOhTghCV/i+DQN/f59GNavw7huLZ5+A3BNvgwAw9YtGLZuwdu1G56+/rFanr79\n0RISKp4fWCpCCFGDfD50ebmBRT+zq4QpfeWuwIKCk55GjYtDbdnK3wVYJVAl+gewJyajxcVJF6AQ\ntUTCl6jC/NbrmFavwrhubZVFBxWbLRi+bHOfRH3xFRn0KkRN0TSU4qKKLsCjOYHWqqpjq3THjp58\nFqDFipqYiLdTlyqBylc+EzAxCTWhGYSF1eGbE0L8noSvRkopLcGw4WeM69bi7d0H97CRAIR9tgTT\nd6vwJSXjnHhBYBbiAHwdOwWfqyYlh6psIRomrxd95gH0e/ag358RGGNVMVhddzTHv/ffCWgmk38W\nYM/egWUVEoNdgcFQlZjo37BYCFHvSfhqLDQN47crCfvqSwzrfsLw6w4UVQXAOWlKMHzZHpnr30Q1\ntbmM1xLizyorw5DxG/o9u9Hv3YNh7x70e3ejz9iH4nZXO1xTFNT4BLxt2wcGpidVLKuQmFgxCzAm\nRn4ehTiN1Gr4mjt3Llu3bkVRFGbPnk3Xrl2Djy1cuJAlS5ag0+no3Lkz9913X22WIrxeLLPvwrDv\nN7SwMDx9++MNzEL09O4bPKxyC5cQ4viUvDwMv+0JhKzdgZC1B/2hzGrHqpEWvJ0642vTDm+79vjS\n26CmpFR0Af7dTZCFEA1Orf3Ur1+/noMHD7Jo0SL27dvH7NmzWbRoEQA2m43XX3+dr776CoPBwFVX\nXcWWLVvo3r37Kc4q/pSyMozbtuAZMAiMRkpffAXF48HTo5eM+RDiVFQV3aFMDHt3o9+71x+y9uxG\n/9ue4w5o9yU0w33m2fjatPWHrLbt8bVt5++ml1YrIUQltRa+1q5dy7BhwwBo3bo1xcXF2Gw2LBYL\nRqMRo9GI3W4nIiICh8NBdHR0bZXS+Ggaps+WYHlgFrrCQgp+3ICanIK30gKnQogApxN9xj5/yAqE\nK8OePej37a2y9RX49wv0tWiJp08/fG3b423bDl/gQ4tuEqI3IIRoaGotfOXl5dGpU0UXVkxMDLm5\nuVgsFsLCwrjpppsYNmwYYWFhjBkzhlatWtVWKY2Kfu8eLLPvwrR6FZrRiOPGmajyn4IQKEWFFeOw\ngiFrN7rMg8Hxj+W08HC8bdvja9u2Ushqjy+9tbQaCyH+tjobbKBV2nbCZrPxyiuvsGzZMiwWC9On\nT2fXrl106NDhhM9v2jQCg6FuNkmNj2+AM4Z8Ppg9G559FjweGDUK5fnniWjXjohQ11bHGuT1E1X8\n5WuoaXD4MOzcCbt2+T+Xf330aPXj4+Jg0CA44wzo0CH4WUlLw6jTYfx7b6NRk5/Dhk2uX+2qtfCV\nkJBAXl5e8PaxY8eIj48HYN++fTRv3pyYmBgAevfuzY4dO04avgoL7bVVahXx8VZyG+jKzFHbfsGQ\nmIRtzuO4R4/xjzNpoO/lr2rI10/4/aFr6HajP7Af/Z7dgTFZe4KtWoq9rMqhmqKgNm+Bd+jw4Dgs\nb+CzFht7/PPnlx3/fvGHyM9hw9ZQrp9X9VLgLKDAmU+LqJaEG8Lx+Dz83+Z/ke/Io8CZT74jn3xn\nPgWOfGb2+gdXdb62zuo7WYCttfA1aNAgXnjhBSZPnswvv/xCQkIClsCq5ykpKezbtw+n04nZbGbH\njh0MHjy4tko5bel3/orp62U4Zv4DgNJn/g8tMhIiGltblzhdKaUlVYKVvnzphgP7q2xtBaCFheFL\nb1MxDqtde7xt2uFr3UZ+JoSo5zRNo8xjIy8Qmgqc+eQ58rB77cHAtPXYZmavuTsYrIpcRcHnL7tw\nJT2b9cagM/DMhifwqhW/HyKNFmLD41CoPxNfai189ezZk06dOjF58mQUReHBBx9k8eLFWK1Whg8f\nztVXX820adPQ6/X06NGD3r1711Yppx2lpJiIpx4n/LX/oPh8uM8dhq9LV7RAy6IQDY7Ph373Lowb\nf4b9e4jeugP9b3vQZ2dVO1SNboK3e0//jMI27fC1a4e3TTvUFi1BXzdDE4QQf9yWY5s4VJpZEawc\n+eQ782jdpC139ZkFwJM/z+WZDU9Ue65e0XNlp2tQFAVVU9l0dANNzTEkRibRMbYzseFxxJhjiQ7z\nT9pTFIUPx31KlCkq+JjZUP82dVe0yoOx6rG6agKt182tmkbYh+9jefh+dLnH8LVoie2xJ3CPGB3q\nyuqNen39RJBy7BjGTRswbvwZw8afMWzeVG2TZ19KasWyDW0CLVlt2/v/yJClG+o1+Tls2H5//X7f\nKtUupgMWowWf6mPuukcC3Xs7azBOAAAgAElEQVR5/u69wNe39ryTm3rMBODCJeP5/vC31V6nX9IA\nlp6/HIBP9n7MB7vfIyY8llhzHLGBzzHhsYxoMQq9To+q+SfG6JSGsedoSLodRQ3TNKIvnojpu1Vo\nZjNl99yH/aZbwVz/Er0QVbhcGLZv9QetTRswbtyAPvNglUO87drj6tUHb68+WAcPJC82WbbKEaKW\neFVvcBxUvjOPAkc+ec48bG4bM3veDsD23K3MXHljsAvQ5XMFn7/k/OX0TxqAXqfnte3/weH1b42l\nV/TEmGNJjEwi0lix9++0jlcwuuV5wWAVEx5LnDmOpuaY4DET217IxLYXnrTuhhK6/ggJXw2FouDp\n3QfNYsH2yFzUtBahrkiI6jQNXebBYIuWcdMGDNu3VdlaR42JwTV8JN6evfH06oO3R88qa2RZ461o\n0moixB+iaRo+zYdB5//vfF32T+wv3keBs6DSoHN/F9+DA+cA8PymZ3hi/WPHPd+N3W8BQFF0HCjZ\nT2x4HB1jOwVDU6w5jvjwuODxn0z4gqiwKGLNcUSFRR83IE1oc0FNv+0GT8JXfaWqhH3wHuaPPqD4\n/Y/BYMB+92zQnT7JXzR8SmkJhs2b/CFr488YN/6MrtIsZ81gwNu5C95effD06oOnZ2/UVunSbSjE\nCXh8HgpcBcFWqS5xXYkOa4KmadwXGGyeXylYFTjzuaP3PdzW604Ant34JCszV1Q7b+9mFdvIdYrt\nwrjWE4k1xwZbocqDVbnOcV3Yf231MZe/16NZrxp4142PhK96yLBtC5Z77sC48We0iAgMv2zH262H\nBC8RWj4f+j27K3Uf/ox+106USsNGfanNcY4/Pxi2vF26Qnh4CIsWIrTsHjvH7EeD3Xv5geUPStxF\nzOr3AODv4rv2qyvId+ZTXGkGH8DiCZ9xZsrZKIrCot3vUeouAcBitBIbHkunwKDzcld1vpZx6ROD\ng83jwmMDA9IrWpdHtTqPUa3Oq4N3L05Ewlc9ohQWEDl3Dua330DRNJwTLqDsoUdRU1JDXZpohJTc\n3CotWobNm9DZKg3CjYjAM2CQP2j17I23V2/UxKQQVixE7fKpPjyqJzh7bs2R79hTuPt3Y6fySY9u\nzVODnwXgte2v8OhPDx73fLf3uhuzwUyY3kypu5SkyCQ6x3YJtEL5W6WSI5ODx395wTdYTVZiwmMJ\n0x9/p4URLWUCVkMg4au+CAyoN27bgrdde2xzn8Jz9jmhrko0Fi4Xhh3bKsLWhg3oMw9UOcTbrj3u\nwDgtT68++DqcAQb5FSIatjJPGbn2Y+Q5cmnbtF2wi++BH2ZxzH6UXEcueYGPfIe/i+/uvrMB+O/W\nl1l24Itq53R5K/YE7RLXlUvaXxpsiYo1xwa/Lh+n1S6mPb9c+dspa20X076G3rUINfnNGWJKUSFa\nk6agKNjvvBf9vt9wXHs9mEyhLk2crjQN3aHMikHxGzdg2L616qD4pk1xDRtR0arVs5dsHC0aBJ/q\no8BZQJ4jl1zHsUBoyuOaLtejKAp7C/cwc+X15Nr9gcrurdg9ZdHY/3Fu2lAUReGjPYvId+YD0CSs\nCXHh8bRt2p4kS0VL1DVdr+f8thdVCVa/b5U6N20o56YNrbtvgGgQJHyFiJKfT+RjDxH2+RIKftiI\nFheHe5T0wYuap9hKMWzZHOw+NG7cgC73WPDx4KD4Sq1aMihe1Dc5ZdkcsR0mz5EXbKnKc+QSY47l\nH73vBuCNHa8y+/u7gutBVTalw1QsJisGnYFtuVuJD0+gTdN2xIfHExf4SLakBI//dOIyosKiiDHH\nYtIf/4/hs1PPqZX3Kk5/Er7qms+Hef4bRD4+B11REd4zOqLLy8UXF3fq5wpxKqpadVD8hp/R796J\nolb8Z+RLSfUPii9f6qFrNxkUL+qUqqlomoZe59+RYOm+T8gpyw62RpW3Wo1vfQE3dL8ZgNnf381n\nGZ9WO1eHmDOC4Ss5MoW+if2JC48nPqIiVMWFx2PQ+bdJbxnVisPX5aGc4o8L6eITtUnCVx0yrF+H\n5d47MO7YhmqNwvbo4ziuvBaMxlCXJhooJS8P46by7sONGDZvRFdaEnxci4jA029AxexDGRQvatm+\nor3ExnUH4Kj9KC9uejYwbqqixarAmc/80e8GB4fft+Yecsqyq5zHoDPQJ7F/8PaIlqNIi2oRCFNx\nJEQkEBceT0JEs+Axf2QW36lClxB1QcJXHYp8ci7GHdtwTpqC7f5H0Jo1O/WThCinaRi2b8Ww/ieM\nG/xdiPqDB6oc4m3bDveYcXgCrVq+MzrKoHhRJ/Id+cxZ+wDv7nqH/LvzASMen5tXtr0cPCbKFE1c\neBytotMxGypaWx8ZOBe9Th9spYoPjyc6rEmVoDS5w2V1+XaEqFXyW7k2eb0Yf1wTnLVoe/xplPx8\nvP36n/x5QlSi5Odj/vA9zAvmY9izO3i/2rQprqHDK1q1evT0T94Qog6pmsqiXe/y8Np/UuAsoGNs\nZ8q3DE6MTOLri1YTFx5PbHjcCTc4PtW2MkKcbiR81RLj2h+w3HsH+l07KVq2Em+PXvjatIU2bUNd\nmmgIVBXjmu8wL3iLsC8+Q3G70UwmnBMvwD1sJN7effC1ai2D4kVI7cz/lbu/u5112WuJMETyyKC5\nXNPlemIjmpJbVopBZ6BbQo9QlylEvSPhq4bpcrKJfOifmBd/CIDjsmn4mss+jOKP0R3NIez9hYQv\nfBv9gf2Af30t59TpOC+eghYbG+IKhagwb90jrMtey5j08Tw66HFSrLIgtBB/hISvGhT+35eJmPco\nujIbnu49sD3+DN6evUNdlqjvfD5Mq1Zgfmc+pq++RPH50MLDcV5yKY6pV+Dt209auES9sT1vG13i\nugIw58zHubzjFQxvOSrEVQnRsEj4qkG6Q4fAZKT04edxXjYN9PpQlyTqMd3hQ5gXvo35vQXos44A\n4OnSDefU6bguuEgWNRX1yuHSQ9y35h6+3P8Zn0z4goEpZ9IiqiUtolqGujQhGhwJX3+DLusI5rff\nwH73faDTYb9nNvbb70SLka4hcQIeD6blXxK+4C2Mq75B0TRUixXHtKtwXj7dv4G6EPWIx+fhv9v+\nzVM/z8PuLWNA8iDiwuNDXZYQDZqEr7/C7Sb8Py8R+a8nUexleDt3wz12PJrFGurKRD2ly9hH+MK3\nMb+/MLi6vKdXH5yXX4Fz/PlgsYS4QiGqW5+9jrtW38bOgl+INcfy+NlPc0n7S2WtLCH+Jglff5Jx\n1TdYZt+FYd9vqHFxlM57Cvd5Y0NdlqiPnE7CPl+CeeHbmNZ8B4DapAn2GTfgvGy6fw0uIeqxFQeX\ns7PgF6aeMZ1/DniIGLO06gtREyR8/QmWu24nfP7raDodjqtnUHbPfbKukqhGv2sn5gVvYf7wfXSF\nhQC4B53lH8s1ZjyYj7/WkRChpmkan2csZXSrMeh1em7rdSfDW46kT2K/UJcmxGlFwtef4OnVG8PO\nXyid9zS+Ll1DXY6oT8rKCFvyP8LfeQvjhvUAqHHx2G++DefUafjS24S4QCFObk/Bbu7+7nZ+zFrD\n3DOf5Jqu1xNhjJDgJUQtkPB1EqavlxHx3DMUv/shWnQTXJdciuuSS2XavwgybN2MecHbhC3+EF1p\nCZqi4D53KI6pV+AeORpMplCXKMRJ2T12ntv4NC9teR6P6mFUqzGMajUm1GUJcVqT8HUcugP7sdx/\nL2HLv0TT6zGu+R73mHESugQASkkxYR9/iHnBfIzbtwLgS06hbMYNOKdMRU2TRXVFw7D60CruWH0r\nmSUHSLU0Z+5ZT51yY2ohxN8n4asyhwMefJqYJ55AcblwDzwT29yn8HXsFOrKRKhpGoaf1xO+4C3C\nlvwPxW5H0+txjRqD8/LpuIcMl3XdRINT7Coiy3aYm3vcxh297yHSGBnqkoRoFCR8VWKdeQN8uhg1\nMYmyhx7Fdf5F0trVyCkF+Zg/fN+/qfXuXQD40lrinDoN5+TLUBOTQlyhEH+cV/Xy1o7XuKDdxcSY\nYxnXeiJd47vTMrpVqEsTolGR8FWJ4+ZbMbdNp/DG22XNrsZMVTH+8D3mhfMJ+2yJf1NroxHnhAtw\nTp2O56zBoNOFukoh/pSNR3/mzm9v45f87ewr/o15Zz2NoigSvIQIAQlflXi79YBhZ6Plloa6FBEC\nytGjmBctJHzB/IpNrdu2w3nZdJyTpqDFxYW4QiH+vCJnIY+te4S3f3kDDY1LO1zOnb1nhbosIRo1\nCV+icfP5MH37TcWm1l4vmtmMc9IU/6bW/fpL17NosFZlfsNN38wgz5FLh5gzePLsZ+mfPDDUZQnR\n6En4Eo2S7vAhzO8t8G9qffgQAN5OXXBMnY7rokmyqbU4LSRGJuH2ufln/4e5vttNmPSy9IkQ9YGE\nL9F4eDyYvlqGecFbmFau8G9qHWnBcfkVOKdOx9u9p7RyiQbN4XXw/KZnOK/VWLrGd+eM2I5smfYr\nFpOMYRWiPpHwJU57uv0ZhC98m7D3F6I/dhTw71bgvGw6zokXyqbW4rSwMnMF93z3Dw6WHGBn/q/M\nH/0ugAQvIeohCV/i9ORyEfbFUswL5mP6fjUAanQT7Ndc59/UulPnEBcoRM3IKcvm/jWz+HTfYvSK\nnhu63cJdfWVAvRD1mYQvcXr59Vci/+8lzB+8V7Gp9YBB/k2tx06A8PAQFyhEzfnhyPdc/sVkbJ5S\nejfry1ODn6NTnPxhIUR9J+FLnB48Hiz33gnvvEkEoMbFYb9xJs6p0/G1aRvq6oSoFV3iupJiSWFG\ntxu57Ixp6BRZf06IhkDCl2jwlNISoq6ZjmnVN9C1K8W33ol75HmyqbU47RS7ipi77hF6NevDpPZT\niAqLZvXknyR0CdHASPgSDZou6wjRl16M4dcduIaPJGzxR7gdWqjLEqJGaZrG/377iPvXzCLXcYyd\n+b9ycbvJKIoiwUuIBkh+akWDpf9lB01GD8Xw6w4c06+mZP57MnNRnHYyin7j4qUTuf7rqyl1lzC7\n3wN8NH4JiiyLIkSDJS1fokEyrvqGqKunobOVYrv/ERw33yprdInTzrbcLZz38TDcqpuhacOZd9bT\nshejEKcBCV+iwTG/+w6WO28FnY6S/76Ja+KFoS5JiBqlaio6RUfnuK6MajWGCW0uYGz6eGntEuI0\nIeFLNByaRsQTjxL5r6dQmzaleP77ePsPCHVVQtSYo/ajPPjDLOIjmjFn0Dx0io7XRs4PdVlCiBom\n4Us0DG431ttvxvzh+/hatKT4vY9lCQlx2vCpPt765XXmrnuEUncJfRL74VW9GHTyK1qI05H8ZIt6\nTykuIurKqZjWfIenV2+K316EFh8f6rKEqBFbj23mrtW3sSV3M1GmaJ48+1ku73gFep0+1KUJIWpJ\nrYavuXPnsnXrVhRFYfbs2XTt2hWAo0ePcueddwaPO3ToEHfccQfjxo2rzXJEA6Q7lEn0pRdh2L0L\n13njKHn5VYiICHVZQtSII6WHGb14KF7Vy4VtJ/HwoLkkRCSEuiwhRC2rtfC1fv16Dh48yKJFi9i3\nbx+zZ89m0aJFADRr1ox33nkHAK/Xy+WXX86QIUNqqxTRQBm2bibqsknojx3FPuMGyh6eC3ppDRAN\nm6ZplHlsWExWUqyp3NPnPno068XZqeeEujQhRB2ptfC1du1ahg0bBkDr1q0pLi7GZrNh+d06TP/7\n3/8YOXIkkZGRtVWKaIBMXy8j6torwWHH9ujjOGbcGOqShPjTNE0j35lPtu0I2WVZZNmy+HL/Z3hU\nDx+PX4qiKNza645QlymEqGO1Fr7y8vLo1KlT8HZMTAy5ubnVwteHH37IG2+8UVtliAbI/OZrWGbd\nCSYTJW8swD1GuqNF/eP2uTlqzyHLlkVOWVYwXCVENOPmHrcC8OzGp3h8/aPVnntO8yHYPKVYTVF1\nXbYQoh6oswH3mlZ9y5fNmzeTnp5eLZAdT9OmERgMddPlFB9vrZPXEb+jqjBrFjz5JMTHw9KlRPfr\n96dPI9ev4Qv1NSxxlXCk5AiHSw5zpPRI8Ouh6UO5qONFAIx5dwxf7P2i2nN7JPbg4RH/BGBQ636c\nX3I+qVGppFhTSIlKoU1MG/ql9Dvt1+wK9TUUf49cv9pVa+ErISGBvLy84O1jx44R/7sZat9++y0D\nBvyxdZoKC+01Wt+JxMdbyc0trZPXEpU4nVhnXo/5k8V4W7eh+N2PUFulw5+8FnL9Gr7avIaqppLn\nyCMn0EqVXZYV/HpGtxvpEuefFNTu9RYUuYqqPd/l8jI4fiQAfeMHEY6FJEsyyZHJJEYmk2xJJsWS\nGqy/X9PB9BsyuNp58vJstfL+6gv5OWzY5PrVjJMF2FoLX4MGDeKFF15g8uTJ/PLLLyQkJFRr4dq+\nfTvnnXdebZUgGgilIJ/o6ZdiXLcWT78BFM9/Fy0mNtRliQbG7XOTXZZFdll2YIxVtv+2LYsXhv6H\ncEM4GUX7GPher+M+/6zUwcHwNaHNhaiaj8TIJJICoSoxMplUS2rw+Bu731In70sIcfqptfDVs2dP\nOnXqxOTJk1EUhQcffJDFixdjtVoZPnw4ALm5ucTGyn+yjZluf4Z/KYl9v+GccAGlL/wHzOZQlyXq\nGZu7lCO2I2TZjpBTlk1W2RGybdkY9QbmnfU0AIv3fsjMlTcc9/mz+z9AenRrkizJjE2fEAxTSZFJ\nJFtSSAx8LvfU4Gfr5H0JIepGviOf1YdXsirzG37MWsO0jleGdLKLoh1vMFY9VFdNoNLcWncMG38m\n+vJL0OXlYb/5Nsr++RDodH/rnHL9Gi5N01iZ+TVbizawL/cA3eK7M6Obf5brnd/extu/Vp+YE2OO\nYddVBwD/YqWvbHuZ5MgUkixJ/m7AyGSSLMkkRDRDp/y9f1vij5Ofw4btdLh+XtXLpqMbWXVoBasy\nV7D52CY0/HEnPjyBOWfO44K2F9dqDSHpdhTiZEyfLyXqxmvA5aL0yWdxXnF1qEsSIbQ9bxsP/jCb\nNUe+C95X5CoMhq8zU84CIMni7wYsb6lKikwKHt8toQcvD3u1bgsXQtQb2bYsVh36hpWZK1h9eBXF\ngXGbBp2BAcmDGJI2jHPThtEptnPI/xiT8CXqXPgrLxH5wGwIj6DknfdxDx8V6pJECP1n64s8+MN9\naGgMSxvBvYPvJlpLILFSsJrY9kImtr0whFUKIeobl8/Fuuy1rMz0t27tLPg1+FhzaxoTWl/AkLRh\nnJV6dr1b1kXCl6g7Ph+RD84m4r//xpfQjJKFH+Dt1iPUVYkQ8Km+4N6FA5PPpENMRx4a+Cjnpg09\nLbo8hBC1I6N4H6syv2FV5grWHPkOu9e/EoJZb2ZI2jCGNB/GkLThtG7Spl4v5yLhS9QNu52oG68l\n7IuleNt38C8l0Twt1FWJOqZpGv/77SPmrpvD26Pfo2NsJ7rGd+fbS36s178ohRChYfPY+PHI96zM\nXMHKzBUcKNkffKxd0/acmzaMc5sPZUDyIMIN4SGs9M+R8CVqnZKbS/S0SzBu3ID7zLMpeXMBWnST\nUJcl6tiGnPXc/8MsNh79GZPOxNZjm+kY698FQ4KXEAL8f6DtLPjV35V46BvWZf2IW3UDYDVFcV6r\ncYGxW0Npbm24f8BL+BK1Sv/bXqKnXIj+4AGcF0+m9NkXwWQKdVmiDh0uPcSjPz3I4r0fATCu9UTu\n7/8wLaNbhbgyIUR9UOgs4LvD37Iq8xtWHlpBTll28LGu8d0DXYnD6NWsD0a9MYSV1hwJX6LWGH5a\nS/T0yegKCyn7x93Y77kPpIWj0Xlpy/Ms3vsR3eJ7MGfQPPonDwx1SUKIEPKpPrbmbg52JW46tgFV\nUwGINcdyYdtJnJs2lHOaDyUhIiHE1dYOCV+iVoR98jHWW64Hn4/S517CeenloS5J1BGf6mP5gS8Z\n3WoMiqJwR+976R7fk4vbTw759G4hRGgctR9lVWBW4urDqyhwFgCgU3T0btbXP1g+bRhd47s3it8T\nEr5EzdI0wl94DsujD6JarJS8/Taec4eGuipRR9Yc+Y4HfpjNjrxtvDZiPuPbnE9ceByXdLg01KUJ\nIeqQ2+dmQ856f+vWoRXsyNsWfCw5MoWpZ0zn3LRhnJ06mOiwxjcGWMKXqDleL5ZZdxE+/3V8SckU\nv/sRvk6dQ12VqAMZRb/x0Nr7Wbb/cwAmtZ9C78S+Ia5KCFGXDpYcCI7b+v7waso8/g3kTToTZ6ee\nG2zdat+0Q6OfZCPhS9QMm42o664k7OvleDt2pvjdD1GTU079PNHg/WvDkzyz4Qk8qod+SQOYM2ge\n3RN6hrosIUQts3vsrM1aE2zd2lf0W/Cx9OjWDEm7jCFpwxiQfCaRxsgQVlr/SPgSf5vuaA5Rl03C\nuG0L7nOGUPL622jW+rWasKg9Tc0xJFlSeHDAHMamj2/0f9EKcbrSNI09hbtZdcg/UH5t1g+4fC4A\nIgyRjGp5XnDdLZnNfHISvsTfot+1k+hLL0J/+BCOy6Zhe/JZMJ4eU4FFdZqm8U3mV/x7y4vMP+89\nLEYLl3e8gkvPuJwwfVioyxNC1LASVzHfHV4dDFxHbIeDj3WM7RzsSuyb2B+TXpYR+qMkfIm/zLjm\nO6KuuAxdSTFls+7HftudspTEaWxn/q888MMsVh9ehU7Rsebwd4xqdR4GnQGD/CoR4rSgaRobszby\n8dZPWXloBRty1uPTfAA0CWvCxDYXMCRtOOc0H1Jl/1Xx58hvTPGXhH3wHtbbbwag5OVXcV10SYgr\nErUl157LE+sfY8HOt1A1lXOaD+HhgXM5I7ZjqEsTQtQAn+pjXfZaPs9YwucZS8kqOwKAgkLPZr39\nK8o3H0qPhF7BPVnF3yPhS/w5mkbEv54k8onHUKObUPLWQjyDzgp1VaIWXff1law58h1tm7Tj4UGP\nMTRthIzrEqKBc/vcfH/4Wz7PWMqyA5+T58gDIDqsCZd3vZyzmg3h7ObnEGOODXGlpycJX+KP83iw\n3HUb4e++g695mn8pifYdQl2VqGHle6uV77t4T99/MiZvK9M6XnXabO0hRGNU5iljVeY3fJ6xhK8O\nLqPUXQJAXHg80zpexZj0cZyZcjbJiTHk5paGuNrTm4Qv8YcopSVEXXU5ptWr8HTrQfGCD9CaNQt1\nWaKGbTm2iQd+mM3Goz/z/ZT1pEe3pl9Sf/ol9Q91aUKIv6DYVcTXB5fzecZSVmZ+jcPrACDV0pxL\nO0xlTOsJ9GnWV7oT65iEL3FKuqwjRF96MYZfd+AaMYqS/7wBFkuoyxI1KMt2hLnrHuGD3e8BMKrV\nGAyK/HoQoiHKteey7MDnfJ6xhO8Pr8ajegBo06QtY9MnMCZ9HF3ju8vwgRCS367ipPQ7thN92cXo\ns7NwXHkNtseeBIP8szldaJrGMxue4IXNz+LwOugU24U5Z87jzJSzQ12aEOJPOFJ6mC/2L+XzjKX8\nlP1jcKPqLnHdGJM+jjHp42kfI8NE6gv5X1SckHHlCqKumY7OVortwUdx3HiLLCVxmlEUhf3FGVhN\nUcw762kuaX+pdD8I0UBkFP3GZxlL+SJjCZuObQze3yexH2PSxzMmfRwtolqGrkBxQhK+xHGZF76N\n5c5bwWCg5NW3cE24INQliRryU9aPfL5/KY8MnIuiKDwyaB5hehMWkzXUpQkhTkLTNH7N/yWwJMQS\ndhb8CoBe0XN26rmMSR/H6FZjZP2tBkDCl6hK04h4fA6Rzz6NGhND8fz38faTwdangwPF+5nz04Ms\n3fcJAJPaTaZLfDdiw2UquRD1laqpbDq6gc8zlvJ5xhIOlOwHIEwfxsiWoxmTPp4RLUfJkhANjIQv\nUcHlwnrbTZg//gBfi5YUv/8xvtZtQ12V+JtKXMU8t+kZ/rv1Zdyqm17N+jBn0Dy6xHcLdWlCiOPw\nql5+yv6RzzOW8EXGZ2SXZQH+/RMntL6Asa3HMzRtuLRWN2ASvgQASlEhUVdOxfTD93h69aH4nUVo\ncXGhLkv8TT7Vx/CPBrO/OINUS3PuH/AwE9tcKLOchKhnXD5XxaKn+z8n35kP+Lf0mdzhMsakj2dw\n6rmYDeYQVypqgoQvgS7zINGXXoRhz25cY8ZT8vKrEB4e6rLE31DgzCfGHItep2dG1xsodZdyXbeb\nCDfIdRWivijzlLEycwWfZ3zKVweWY/P4FzZNiGjGFZ2uZkz6eAYmnymLG5+GJHw1coYtm4i+bBK6\n3GPYr7uJsoceBb3Mdmuo9hTs5qEf72NP0R5+mPIzYfowru5yXajLEkIEFDkL+ergMj7PWMqqzBU4\nfU4A0qwtmNpxOmPTJ9A7sQ86RRfiSkVtkvDViJm++pKoGVeCw4HtsSdwXHtDqEsSf1G+I5+nN8zj\nrR2v49N8nJlyNoXOApn1JEQ9cMx+jGX7A4ueHlmNV/UC0K5pe8amj2dM+ng6x3WV4QCNiISvRsr8\nxqtYZt8FYWGUvLkQ93ljQ12S+As8Pg+vbX+Ff218kmJXEenRrXlo4GOMbDlafpELEUKHSw/xRcZS\nPstYwrrstWhoAHSL78GY9HGc12oc7WLah7hKESoSvhobVSXykQeIePn/UOPiKV6wCG/P3qGuSvxF\niqKwcOd8AOYMmseVna/FpDeFuCohGqffCvcG1+DakrsZAAWFvkn9g4ErLapFiKsU9YGEr8bE6cR6\n83WYl/wPb5u2FL/7EWrLVqGuSvxJ23O3sqtgJxe3n4xBZ+C/I94iMTJR1vkRoo5pmsaO/O2BJSGW\nsqtgJwAGnYHBqecytvUERrUaQ7OIZiGuVNQ3Er4aC00jetpkTN+uxN1/ICXz30VrGhPqqsQfUOQs\nZE/hHvYU7uKHI9+zeO+HmA1mhqQNJzY8lo6xnUJdohCNhqqpbDz6c3DR04MlBwAw682MajWGMa3G\nMaLlKJqa5ferODEJX42EYcsmTN+uxH3m2RS/+xGYZa2Y+qbAmc+egt0ctecwoY1/O6el+z7l6uWX\nVznujJiOPDxorqxML0QaGNMAACAASURBVEQdcnqdfLD7PV7e8n9kFO8DINJo4fw2FzImfTxDWgzH\nYrSEuErRUEj4aiTMC94GwH7zrRK86okfj6zh032L2VOwm92Fu8hz5AL+bUPGpk9Ar9PTvmkHhqYN\np13TDrSP6UC7pu3pkdBLNr8Woo4Uu4p4a8fr/Hfbv8l1HMOkM3Fxu8lMaHM+Z8uip+IvkvDVGJSV\nEfa/j/ClpOIZPCTU1TQKmqZx1J7D7oJd7Cncxe6C3ewp3EVseBxvjloAwM6CX3lzx2soKKRFtaBn\nQi/aBQKWT/OhR0+7mPa8N/bjEL8bIRqfbFsW/9n6Em//+iZlHhtWUxS39Lida7teL0u4iL9Nwlcj\nELb0E3S2Uspm3CALqNYwTdM4YjvMnsJdWIxR9E3qB8DMlTewaPe7VY7VKTp6NesTvD229QT6Jvaj\ndZO2RBgj6rRuIcTx7SnYzYtbnuPjPR/gUT00i0jkjv9n774Dqqr/P44/74ULlw0KuPdM0RQtV25x\npubeOzeusqENR4ZZmZZKbk0FxUGWuXem5iQk90TLBSJD4MLl3vP7w/KX31IvcC+XC+/HP3nlfD7n\nRYcr7/s5n/P51H6P/lUG4u7oYe14Io+Q4isf0IauRlGp0PXu9+KDxQutPreSE3ePcSnuAhcfXiRZ\n/wiAdmU7PCm+ahd+lWR9MhULVKKSV2UqelWmnGf5p25RFHIuJE9BCZFLHLvzKwsi5rLjxjYAyntW\nILDmeLpU7I6jnaOV04m8RoqvPM7uymUcfj1CeqOmGEvK+jIvYjAaiE68zsWHF/8qri5w6eFF+rzU\nn0F+bwLw45XvOfjHfjRqDeU9K/w1F6vyU6NaA6oOZkDVwdb6NoQQJjAqRnbd2MH8iLkcv/srALUK\nvcKYmhNoXaatbPEjLEaKrzxOG7oaAF0fGfX6J71Bz43E61yMu4B/oVoUdS2GoihUXVmOOF3cU8dq\n7bRPJsMDTGsQhIPagdIeZbBXy1tICFuTbkhn06X1LPjtay49vAhAy1KtCaw5njpF6snuEMLi5DdH\nXqbXow0LxejpSVqb/L19UEJaPIsig7n08PHE96vxV9Ab9QDMa7aQHpV7o1KpaF6yJSqV6qmnC0u6\nlXrq6UJZV0sI25SUnsiqsytZfCaYO8m3sVfb06NSb0bVGMtLBatYO57IR6T4ysMcdu9EHXOflKEj\n8sXyEknpieyJ+okT0aefPF0Y2m4jpT3KoFE7MPvkLBQUXDVuVPd5mYp/zcWq6VvrSR8LWiy24ncg\nhLCEeyn3WHpmISt+X0piegIuGldGvBzI8OqjKOZW3NrxRD4kxVcepg19vLaXrnd/KyexvBN3jzFi\n9xBuJd188ncejp7cTblLaY8yOGucCe/4E2U8ylLEpajcVhAiH7gWf4UFv81j/cVQ0gxpeDv5MLnO\nxwysOgRPrZe144l8zKLFV1BQEJGRkahUKiZPnkz16tWffO3OnTu89dZb6PV6qlSpwvTp0y0ZJd9R\n372Dw55d6GvUxFDVz9pxLCpe95DuWzqRmpHCO/Xfoa53IyoWqIyvk+9TRVaDYg2tmFIIkVNO3zvJ\n/Iiv2XrtRxQUSruXYXTNcXSv1AsneydrxxPCcsXX8ePHiY6OJiwsjKtXrzJ58mTCwsKefP2zzz5j\n8ODBBAQEMG3aNG7fvk3RokUtFSffcQwLRWU0ouszwNpRLM5T68WsRrMp7lqCjjXaEBOTZO1IQogc\npigK+27uZn7E1xy+fQiAl31qMqbmeNqV7SC7QohcxWLF19GjR2nRogUA5cqVIyEhgUePHuHq6orR\naOTUqVN89dVXAEyZMsVSMfInoxGnkFUoTk6kdepi7TQWsTd6F8GR81nTNgwneye6V+pl7UhCCCvQ\nG/T8cDWc+RFfc+7B7wA0LdGcwJrjea1YI5liIHIlixVfsbGxVK36/0+FFShQgJiYGFxdXYmLi8PF\nxYWZM2dy9uxZateuzdtvv/3c/ry8nLG3z5lPLj4+bjlyHos5cABuXIf+/fEul7cmk6ZlpDFp7yTm\n/DoHBzsHrqWdo0mRJk8dY/PXT8g1zAMsfQ2T05NZFrGM2UdnczPhJnYqO3pX68079d+hRuEaFj13\nfiDvQcvKsQn3iqI89ed79+7Rv39/ihUrxrBhwzhw4ABNmjR5ZvuHD1NyIOXjHzhbv23ltmAhWiC+\nSy/0Nv69/NO1+CsM2z2YMzG/Ud6zAotarqCqS/WnrldeuH75nVxD22fJaxibGsuyqEUsj1rMw7SH\nONk7MaTaMEa8HEgp99IA8vOTTfIeNI/nFbAWK758fX2JjY198vr+/fv4+PgA4OXlRdGiRSlZsiQA\n9erV4/Lly88tvoRpVAnxOP70Axlly6GvW9/accxmy9XNjN03imT9I3pX7senDT/HReNi7VhCiBwS\nnXiDb3+bx9oLa0jNSKWAtgATa7/PkGrDKehU0NrxhMgUixVfDRo0YN68efTs2ZOzZ8/i6+uLq6vr\n45Pa21OiRAlu3LhB6dKlOXv2LO3atbNUlHzFcdMGVDrd4+Ul8tBcB09HL+zV9iwMWEbnCt2sHUcI\nkUOiYiKZHzGXH65+j1ExUsKtJCNfDqTXS/3kA5iwWRYrvvz9/alatSo9e/ZEpVIxZcoUwsPDcXNz\nIyAggMmTJ/P++++jKAoVK1akWbNmloqSr2hDV6PY2aHr0dvaUbIt8n4EhVwKU9ilCA2LN+ZU3yjc\nHT2sHUsIYWGKonDoz4PMOz2Hg3/sB6BqwWoE1hxHx/KdZVsvYfNUyj8nY+ViOXX/2ZbvddtHReLV\nvCFprduSuGqdteNkmVExsigymBm/TqFu0QZsbP+DyU8s2fL1E4/JNbR9Wb2GBqOBn679wPyIr4mM\niQDgtWKNCKw5nqYlmsuTizlE3oPmYZU5XyLnaUP+WtHehtf2ik2NZezeEey5uQtvJx9G1xgr/+AK\nkcelZqSy7kIIwb99Q3TiDVSoaF/uDQJrjKNmoVov7kAIGyPFV16Rmorjpg0YChUmvXmAtdNkyaE/\nDjJqz1DupdylcfGmzG+xmELOhawdSwhhIQ91caz4fSlLoxYSmxqLo50j/asMZlTNMZT1KGfteEJY\njBRfeYTjti2oE+JJGfAW2NveZU1MS2DQjr6kZCTzUb3pjK4xFrVKbe1YQggL+CPpFosiF7D63Hek\nZCTj4ejJeP+JvFl9BL7OvtaOJ4TF2d5vafGftKGrAdD17mvlJJmjKAoqlQp3Rw/mNV+Ir7MvtQq9\nYu1YQggLOP/gHPMj5vL9lY1kGDMo4lKU9179gH5VBuDqIIt6ivxDiq88QH39Gg6HDpJe/zUMZctb\nO47JtlzdzDen5xDecQtuDu60KSPLjQiR1yiKwq93jjDv9Bz23NwFQCWvyoyuOY7OFbrhYOdg5YRC\n5DwpvvIA7bo1AOh697NyEtOk6FP46PAkVp9bgbO9M2diImlQrKG1YwkhzMioGNl+fSvzI+Zy6t4J\nAOoUqceYmuNpUaqVTCsQ+ZoUX7bOYEC7LhSjmztpr3e0dpoXOvfgLMN3DeLiwwtULViNxS1XUMGr\norVjCSHMJM2QxtLTYXx2aBZX468A0LpMOwJrjOfVInWsnE6I3EGKLxvnsH8PdndukzpwCDg7WzvO\nc4Vf3sD4faPRGXS8WW04H9f7BK291tqxhBBmYFSMbLi4jk+PTeNu8h00ag29K/djdM1x8gFLWMS8\neXO4ePE8cXEP0Ol0FC1aDHd3D4KCvnhh223btuDi4krjxk1feOyJE8dYvHgBarUd9eo1YODAN7Od\nXYovG6dd8/faXv2tnOTFyriXxd3Rg0WNV8j8LiHykFP3TvDBoXc5ff8UTvZOTKw3kf4Vh1LYpYi1\no4k8bMyYCcDjQuratasEBo43uW3btu1NPvbrr79k9ux5+Pj4Ehg4jMaNm1GmTNlM5/0nKb5smOr+\nfRx2bSejajUyqtewdpz/9OudoxRyLkQZj7LULFSLk32jZLRLiDzibvIdPjk6hQ2XHu+o0al8Fz6q\nN52aZavICunCak6fPsm6dWtISUkhMHACERGnOHBgL0ajkXr1GjB48DCWLVuEp6cnZcqUIzx8PSqV\nmujo6zRp0pzBg4c96evPP//Azc2dQoUKA1CvXgNOnTouxVd+pt2wDlVGBql9+uW6TbQNRgNfn57N\n5yeCqOnrz7bOe1GpVFJ4CZEH6DJ0LIycz9xTs0nJSKaa98t8+tos6hatb+1owkpcpn6I45bNZu0z\nrf0bJE+dkaW2V69eYe3acBwcHIiIOEVw8FLUajXdu3ekx//sfXzu3FlCQzdhNBrp1q39U8VXXNwD\nPD29nrz28vLizz//zNo39A9SfNkqRUEb8h2KoyNpXbpbO81T7jy6zag9Qzl8+xBFXYoxpd4M2SJI\niDxAURS2XtvC1CMfcDMpGm8nH2a89hm9KvfFTm1n7XhCPFG+fAUcHB4vY6LVagkMHIadnR3x8fEk\nJiY+dWylSpXRak0bGDDXbthSfNko++PHsL9yGV3nriheBawd54ldN7Yzdt9I4nRxtCnzOnObzsdL\nm3vyCSGy5tyDs3z0y/sc+vMg9mp7Rr48hrdrv4u7o4e1o4lcIHnqjCyPUlmCRqMB4O7dO4SFhbB8\neQjOzs706/fvwQo7u2d/cPD29iEu7sGT1zEx9/H29s52Pim+bJQ29K+J9r1zz0T7R/pHjN8/mmR9\nMp81ms2gqm/KiJcQNu5B6gNmHZ/BqnMrMCpGAkq1Ylr9IMp7VbB2NCFeKD4+Hi8vL5ydnbl48QJ3\n795Fr9eb3L5IkaIkJydz585tfHx8OXLkFz7++JNs55LiywapkhLR/hCOoWRp9K81snYcMowZ2Kvt\ncdW4srjlSrwcC1DV28/asYQQ2aA36Fl5dimfn5hJQlo85T0r8EmDmTQv1dLa0YQwWYUKFXFycmbk\nyMFUq1aDjh07M3v2LKpXf9nkPiZOfJ+pUz8AoFmzAEqWLJXtXCpFMdcdTMvKqSdnfHzccv1TOtrV\nK3F7eyzJ739IylvvWi2HoiiEXQxl7qkv+anzbrydsj8Um122cP3E88k1tL4Dt/bx0S/vc/HhBdwd\nPHjnlfcZ7DcMjZ3GpPZyDW2bXD/z8PF59n6lMvJlg7Shq1DUanQ9+1gtQ1J6Iu8cnED45Q24Obhz\nKe4C3sVes1oeIUT2XUu4ytTDH7DjxjZUqOhfZTDv1/kwV3ywEiIvkeLLxtidP4fm1EnSmgdgLFrM\nKhki7p1i+O7B3Ei8Tq1CtVkYsJxS7qWtkkUIkX1J6YnMOfUliyIXoDfqqVe0ATNem0U17+rWjiZE\nniTFl415MtG+zwCrnH/9xbWM3z8ag9HA2Jpv8d6rH5h8K0IIkbsYFSNhF0KZ8etUYlLvU8KtJFPr\nz+D1sh3lYRkhLEiKL1uSloZ2wzqM3t6kt2xtlQg1fPwp5lqcLxt/TeMSL94TSwiROx2/c4wPfnmX\nyJgInO2def/VDxlZYwxO9k7WjiZEnifFlw1x2LkNdVwcKSPHwF+Lx+WEg7f24+3kQ1VvPyoWqMTR\n3qexV8uPjhC26PajP5l+9GPCL28AoHOFbnxcbzpFXa0zjUGI/Eh+g9oQp5Cc3URbb9Dz2fEZzI+Y\ny0sFq7Kv+y+oVWopvISwQakZqQT/9g3zTs8hJSOFl31qMuO1WdQpUtfa0YTId+S3qI1Q37qJ5sA+\n9K/UwVCxksXPF514gxG7B3Pq3klKu5dhbtP5qFVqi59XCGFeiqKw5epmph39iFtJN/Fx8mVmwy/p\nUbm3vKeFTZs3bw4XL54nLu4BOp2OokWL4e7uQVDQFya1v3PnNgkJ8VSuXIW7d+8wY8YUjEYjPj4+\nfPjh9Cer5FuCFF82QrsuBJWi5Mio1/eXNzLx4HiS0hPpUqE7nzf+CjcHd4ufVwhhXlGxZ/jol/c5\ncvsXNGoNgTXHM6HWRHk/izxhzJgJAGzbtoVr164SGDg+U+1PnjyOwZBB5cpVWLIkmG7detG4cVOC\ng79m+/af6NChkyViA1J82QajEe26EIwurugs+MMAkKJPYfrRjzEYDXzT7Ft6VOotTz0JYWNiU2OZ\neewTQs5/h1Ex0rp0W6bWn0FZz/LWjiaExQUHf8PZs1EYjQa6du1F8+YBHD16mOXLF+Hg4Ii3tzej\nR49n5cqlaDQO+PoW5rffIpg0aQoADRo0YtOm9VJ85Xeanw9gd+smqX36g6urRc6RmpGKk70Tzhpn\nlrVahYejB+U8Ze82IWyJ3qBn+e+L+eLEZySmJ1DRqxKfNPiMpiWbWzuayAcK1PrvbeVSRo1FN2QY\nAG6jhqI5dvRfx+hr1SZp8Urg8S4uznO/JO7U75nOcPr0SR4+jGPBgiWkpekYMqQ/DRs2ZtOmMMaN\nm4ifX3X279+DRqOhVau2+Pr6Ur/+a8ycmY69/eOSyMvLiwcPYjN97syQ4ssGaC040V5RFJb/voS5\np75ke5e9FHcrgX+h2mY/jxDCsvbd3M1Hv0zicvwlPBw9CXrtcwZUHSLr8Il8JSoqkqioSAIDHxd7\nRqOBuLgHNG3aglmzZtCyZVsCAlrh5VXgmX3kxKaLUnzlcqq4Bzhu/4mMSpXJqPWKWft+qItj3P7R\n7Li+lYLagvyRdIvibiXMeg4hhGVdjb/Mx4cnszt6J2qVmkF+b/LuKx9Q0KmgtaOJfMaUkaqk4CUv\nPEbXbyC6fgOzlEGj0dChQyd69356sKJduw7Uq9eAn38+wDvvjCMo6Munvu7o6Eh6ejoODg7ExNzH\n29uyW2rJoy65nHZjGKr0dHS9+4MZ5179evsITcMasOP6Vl4r1oj9PY5Qt2h9s/UvhLCsxLQEphz+\ngIbr6rA7eievFWvEvu6HmdXoKym8RL5VpYofhw8fwmg0otPpmDv3cZG1YsUSHBwceeONLjRp0pzo\n6Ouo1WoMBgMA/v61+fnn/QAcOLCPOnUs+/vQpJEvRVFk0rU1KArakFUoGg26bj3N1m3YhVDG7R+F\nChWTXv2Isf5vYae2M1v/QgjLMRgNrL2whqBj04hNjaWkWymm1v+UdmXby7/TIt+rUcMfP7/qDB8+\nCFDo0qUHAD4+vowdOwI3N3c8PDzo23cA9vYaZs6cjoeHJ0OHjmTGjKls2rSeYsWK07JlG4vmVCnK\ni+9uNmnShI4dO9K1a1dKlLDObamYmKQcOY+Pj1uOnetF7E+fxKt1M9Lav0HislVm6/dW0k36bevJ\nrEZf5bkFFnPT9RNZI9fw2X69fYQPfnmPqNhInO1dGF/rbUa8HIjWXmvtaE+Ra2jb5PqZh4+P2zO/\nZtLI14YNG9i5cyeTJ0/G3t6ezp0706pVKxxycIub/EgbshqA1D79st1XuiGddGM6rhpXSriVZH/3\nw/IpWQgb8UfSLaYf/YjNV8IB6FaxJx/WnUoR16JWTiaEyAqT5nz5+PjQt29fVq9ezdSpU1m7di0N\nGzZkzpw5pKWlWTpj/pScjOP3GzEUK46+cbNsd7fp0nr8V1Vhb/QuACm8hLABKfoUPj8eRIO1tdl8\nJRx/31ps67yHBS0WS+ElhA0zecL9iRMnmDRpEkOHDsXf35/Q0FDc3d0ZN26cJfPlW45bNqN+lISu\nZx+wy958LEVRCP7tGx7pH1G5QBUzJRRCWIqiKHx/eSMN1tbmy5Of4ebgzrxmC9nWZS+1C79q7XhC\niGwy6bZjQEAAxYoVo3v37kyf/v/7HZUrV449e/ZYNGB+5RSyCkWlQterb7b72ndzNxcfXqBrxR4U\ncytuhnRCCEs5E/MbH/zyHsfuHMVB7cA4/7cZ5/8Wrg7Pnj8ihLAtJhVfS5cuRVEUSpcuDcC5c+eo\nUuXxCEpoaKjFwuVXdlcuozl2lPRGTTGWLJXt/oIj5wMwssaYbPclhLCM+yn3+ezYJ4ScX4WCQtsy\n7ZlafwalPcpYO5oQwsxMKr7Cw8O5f/8+M2fOBGDx4sUUL16ciRMnytwhC/j/Fe2zP9E+KiaSQ38c\noFHxplTzrp7t/oQQ5pVuSGdp1CJmn5xFUnoiLxWowievfUaj4k2sHU0IYSEmFV/Hjh1j3bp1T17P\nnTuXXr16WSxUvqbXow0LxejlRVqb17Pd3bbrPwEwqkZgtvsSQpiPoijsid7JR4cncS3hKl6OXnzW\naDb9qwzCXi2bjwjxIvPmzeHixfPExT1Ap9NRtGgx3N09CAr64oVtt23bgouLK40bN33hsWlpaXzx\nRRDXr19j2bLV5ohuWvGl1+ufLLsPkJycTEZGhlkCiKc57N6JOjaGlKEjQJv9tXvefWUyAaVaUdO3\nlhnSCSHM4VLcRT4+Mol9N/dgp7JjSLVhvPvKZLy0z95vTgjxtDFjJgCPC6lr164SGDje5LZt27Y3\n+djg4K+pUKEi169fy3TGZzGp+OrZsydt27bFz88Po9FIVFQUgYEykmIJ2tC/bjn2Ns8m2iqVSjbK\nFiKXSEpP5PPjQSz7fTEZxgwaFm/CjAaf8VJBeQpZCHM5ffok69atISUlhcDACUREnOLAgb0YjUbq\n1WvA4MHDWLZsEZ6enpQpU47w8PWoVGqio6/TpElzBg8e9lR/w4ePJiEhgV27dpgto0nFV7du3WjQ\noAFRUVGoVComTZqEq6ur2UKIx9R3buOwZxf6mv4Yqvplq6/EtAQ+PTaNN6uNoIJXRTMlFEJk1bE7\nvzJ6z1BuJkVTyr000xvMpHXptjJvVuQJU498yJarm83aZ/tybzC1/owstb169Qpr14bj4OBARMQp\ngoOXolar6d69Iz169H7q2HPnzhIaugmj0Ui3bu3/VXw5O7uQkJCQ5e/jv5g8sSAlJYUCBR4PiV+7\ndo0ZM2awffv257YJCgoiMjISlUrF5MmTqV79/yd8N2vWjMKFC2P31xpWX375JYUKFcrK95BnaMNC\nURmNZhn1Wn3uO1b8vpSiLsUYV+ttM6QTQmRFhjGD2SdnMefU43koE2pN5K3a7+Fo52jlZELkXeXL\nV3gyVUqr1RIYOAw7Ozvi4+NJTEx86thKlSqjNcM0n8wwqfiaMWMGhw8fJjY2lpIlS3Lr1i0GDx78\n3DbHjx8nOjqasLAwrl69yuTJkwkLC3vqmCVLluDi4pL19HmJ0Yg2dDWKkxNpnbpkqyu9Qc+SM9/i\nbO9C/6qDzBRQCJFZNxKuM3LPm5y6d4LiriUIbrGEukXrWzuWEGY3tf6MLI9SWcLf65HevXuHsLAQ\nli8PwdnZmX79uv/rWLtsLmSeFSatcB8VFcX27dupXLkymzZtYvny5aSmpj63zdGjR2nRogXweDHW\nhIQEHj16lP3EeZTm6GHsblwnrf0bKO4e2errh6vh3E7+kz4v9ZMJvEJYgaIohF0Ipen6Bpy6d4LO\nFbqyv8dhKbyEyGHx8fF4eXnh7OzMxYsXuHv3Lnq93tqxTCu+/h660+v1KIqCn58fp0+ffm6b2NhY\nvLy8nrwuUKAAMTExTx0zZcoUevXqxZdffomiKJnNnqdo13wHgK7vgGz183groXmoVWqGvTzKHNGE\nEJkQr3vI8N2DGLNvBCpUBLdYwsKA5Xg4elo7mhD5ToUKFXFycmbkyMHs3buLjh07M3v2rEz18eGH\n7zFlymRu3owmMHCYWSbeqxQTqp6PP/6YSpUqcefOHX7//XfKlClDREQEmzc/e3LdRx99ROPGjZ+M\nfvXq1YugoCDKlHm8WvPmzZtp2LAhHh4ejB49mk6dOtG6detn9peRYcDePueHBnNEfDwUKQIlS8KF\nC5CNCbh7r+2lxeoWdKvSjfXd1psxpBDiRQ7eOEi/7/txK/EW9UvUZ02nNZTxkhXqhRBPM2nO17Rp\n00hISMDd3Z2tW7fy4MEDhg8f/tw2vr6+xMbGPnl9//59fHx8nrx+4403nvy5UaNGXLp06bnF18OH\nKaZEzTYfHzdiYpJy5Fx/0y5fjptOx6PufUiNzd6tWXejD/2qDKLPS/1y/PvIDaxx/YR52eI1TDek\n88WJmXxz+ivUKjXvvfoB4/zfxj7D3ua+F3OwxWso/p9cP/Pw8Xn2fqwm3XYMCgrC09MTtVpN+/bt\nGThwIIULF35umwYNGrBz504Azp49i6+v75PlKZKSkhgyZAjp6ekAnDhxggoVKpj0zeRF2pBVKHZ2\n6P7n8desKO1RhtlNvpa1vYTIIVfjL/N6eABfn55NSfdSbOm0k7drvyer1Ashnsmkfx3s7Ow4evQo\n/v7+T54gAFCrn127+fv7U7VqVXr27IlKpWLKlCmEh4fj5uZGQEAAjRo1okePHjg6OlKlSpXnjnrl\nZfZRkWiiIklr3Q4lm0ttXE+4Rmn3MrJukBA5QFEUQs6v4sNf3iMlI4UelXozs+EXuDo8+9OuEEKA\niXO+atWqRUpKylOT4lUqFefPn7douH/KqSHQnB5udX3/bZyWLyFhdRjprdpkuZ97yXfxX12VDuU6\n8W3AUjMmtC0yXG77bOEaxuke8Nb+sWy7vgUPR0++aDSHNypkb4mYvMQWrqF4Nrl+5vG8244mjXyd\nOnXKbGHEP6Sm4rhpA4ZChUlvHpCtrpZFLUZv1Muj7EJY2MFb+xmzbwR3k+9Qv+hrzG++iOJuJawd\nSwhhQ0wqvr7++uv//Ptx48aZNUx+47j1R9QJ8aQMfBvssz4/5JH+ESvPLqWgtiDdK/UyY0IhxN/S\nDGkE/TqdbyPnYa+258O6UxldYxx26jz6FLYQwmJMnvP1N71ez4kTJ6hSRTaCzS5t6GoAUnv1zVY/\n686vIT4tnndemYSTvZM5ogkh/uFi3AVG7B7C2QdRlPUox8KAZdTw9bd2LCHytXnz5nDx4nni4h6g\n0+koWrQY7u4eBAV9YVL7O3duk5AQT+XKj+uZsLAQgoO/Ydeun3F0tOz2XyYVX4GBgU+9NhgMjBkz\nxiKB8gv19Ws4/PIz6fVfw1i2XJb7yTBmsPBMMFo7LYP8hpoxoRBCURRWnF3K1MMfoDPo6FdlINMb\nzMRFI9uiCWFtDPL6mgAAIABJREFUY8ZMAGDbti1cu3aVwMDxmWp/8uRxDIYMKleuwk8//UBSUhJe\nXjmzK0yW7nVlZGRw8+ZNc2fJV7Tr1gCg690vW/1cib9MYlo8PSr3wdvJ2xzRhBBATEoM4/ePYnf0\nTrwcvfg2YBntyra3diwhxAsEB3/D2bNRGI0GunbtRfPmARw9epjlyxfh4OCIt7c3o0ePZ+XKpWg0\nDvj6FqZZsxY4O7uwdeuPOZLRpOKrcePGTy1fkJCQQKdOnSwWKs/LyEC7NgSjuwdpr3fMVleVC7xE\nRP/z6DJ0ZgonhNgbvYsx+0YSmxpDo+JNmd98IYVdilg7lhC5Wq3Vfv/596NqjGVItWGP/7xnKMfu\nHP1320K1WdxyJQCrz61k7qkvOdXv90xnOH36JA8fxrFgwRLS0nQMGdKfhg0bs2lTGOPGTcTPrzr7\n9+9Bo9HQqlVbfH19qV//tUyfJ7tMKr5CQ0Of/FmlUuHq6oq7u7vFQuV1Dvv3YHf3DqkDh4Czc7b7\nc9G4yG0QIcwgNSOVT45+zNKoRTioHZhWP4jhL49CrTJpPWohhJVFRUUSFRVJYODjYs9oNBAX94Cm\nTVswa9YMWrZsS0BAqxy7vfgsJhVfqamp/PDDD7z99tsATJo0icGDB+frVemzQxvyeKK9rk//bPXz\nwaF3KedVgQFVBssTV0Jk07kHZxm5ewjn485R0asS3wYso5p3dWvHEsJmmDJSFdxiyQuP6VdlIP2q\nDMxSBo1GQ4cOnejd++nfr+3adaBevQb8/PMB3nlnHEFBX2apf3Mx6ePctGnTaNy48ZPXXbp0Yfr0\n6RYLlZep7t/HYdd2MqpWI6N6jSz3c+XhZZZGLWLDxbXyqVyIbDAqRhZHBtNqYxPOx51jsN9QdnU9\nKIWXEDaoShU/Dh8+hNFoRKfTMXfu4yJrxYolODg48sYbXWjSpDnR0ddRq9UYDAar5DRp5MtgMFC7\n9v/vFVi7dm1MWBhf/Aft+rWoMjJI7dsfsrEN0MLIBSgojKoxVrYTEiKL7iXfZey+key/tRdvJ2+W\nNV1Fy9JZ32lCCGFdNWr44+dXneHDBwEKXbr0AMDHx5exY0fg5uaOh4cHffsOwN5ew8yZ0/Hw8OTW\nrZucOnWC+PiHvPVWINWqvcyIEYHPP1k2mLS90PDhw2ncuDF16tTBaDRy6NAhjh07xqJFiywW7H/l\nie2FFAWvBrWxu3WTB1GXUDy9stRNbGos/quq4OtSmGO9I+SW4z/Ithi2L6eu4Y7r25iwfzQPdA9o\nXjKAr5t9i6+zr8XPmx/I+9C2yfUzj2xvLzRz5kxmz57N2rVrgcebZs+cOdM86fIR++PHsL9yGV3n\nrlkuvABW/L4EnUHHyJdHS+ElRCal6FOYcuQDvju7DEc7R2Y2/ILBfsNkBFkIkWNMKr4KFCjA0KFD\nKV26NADnzp2jQAHrPilgi5xCvgNA12dAlvtIzUhledRiPB096Vk5eyvjC5HfRMVEMmL3EC7HX+Kl\nAlVZGLCMlwrKbh1CiJxlUvE1Z84c7t+//2S0a/HixRQvXpyJEydaNFxeokpKxPHH7zGULI2+QcMs\n96NRa5jZ8EuS9EmyvIQQJjIqRr79bT5Bx6ahN+oZ/vJoPqgzBa291trRhBD5kEnF17Fjx1i3bt2T\n13PnzqVXL9nAOTMcN4ejSklB17svqLP+dKK92p43KnQxYzIh8rY7j24TuHc4h/48iK9zIb5p9i3N\nSrawdiwhRD5mUvGl1+tJT0/HwcEBgOTkZDIyMiwaLK/RhnyHolaj69kny31cfniJAtqCFHQqaMZk\nQuRdW67+wNsHxhCfFk/r0m35qul82YZLCGF1JhVfPXv2pG3btvj5+WE0GomKimLAgKzPW8pv7M6f\nQ3P6FGktWmIsWizL/bx9YCyRMRGc7Ps7Ps4+ZkwoRN7ySP+Ij355n5Dzq3Cyd+KLxnPpX2WQTKoX\nQuQKJhVf3bp1o3Tp0jx8+BCVSkWzZs1YtGgRAwcOtHC8vEEbugoAXe+sr2h/+t5Jfr1zhOYlA6Tw\nEuI5Iu6dYsSeIVxPuEY175dZGLCMCl4VrR1LCGFm8+bN4eLF88TFPUCn01G0aDHc3T0ICvrihW23\nbduCi4srjRs3feGxp0+fZOHC+djZqSlRohTvv/8R6mxMHwITi69PP/2UX375hdjYWEqWLMmtW7cY\nPHhwtk6cb6Slod2wDqO3N+ktW2e5m29/mw883qBUCPFvBqOBeRFz+PxEEAajgcCa43n/1Q9xsHOw\ndjQhhAWMGTMBeFxIXbt2lcDA8Sa3bdu2vcnHfv75p3zzzUJ8fQvx4YfvcezYEerVy95m3CYVX2fO\nnGH79u3069eP1atX8/vvv7N79+5snTi/cNyxFXVcHCkjx4BD1n4JRCfeYMu1zVTzfpnXijUyc0Ih\nbN+tpJuM3jOMX+8coYhLUeY3X0TD4o1f3FAIkeecPn2SdevWkJKSQmDgBCIiTnHgwF6MRiP16jVg\n8OBhLFu2CE9PT8qUKUd4+HpUKjXR0ddp0qQ5gwcPe6q/ZctW4+LiCoCnpxcJCQnZzmhS8fX3RHu9\nXo+iKPj5+TFr1qxsnzw/0Ib8dcsxG5toL44MxqgYGVkjUOasCPE/vr+8kXcOTiAxPYHXy3ZkdpOv\n8dLKOoRC5KSpUx3ZssWkksJk7dtnMHVqWpbaXr16hbVrw3FwcCAi4hTBwUtRq9V0796RHj16P3Xs\nuXNnCQ3dhNFopFu39v8qvv4uvGJjYzlx4leGDh2RtW/oH0z6P1WmTBlCQkKoXbs2gwYNokyZMiQl\nydYDL6K+dRPNwf3oX6mDoWKlLPWhKAr3Uu5RzLU4Hct1NnNCIWxXUnoi7/88kQ2X1uFs78Lcpgvo\nVbmvfEARQlC+fIUnA0darZbAwGHY2dkRHx9PYmLiU8dWqlQZrfb5a/49fBjHe+9N4O2338fDwzPb\n+UwqvqZNm0ZCQgLu7u5s3bqVBw8eMHz48GyfPK/TrgtBpSjZGvVSqVQsbfUdiWkJaOw0ZkwnhO06\nfucYo/YO5WbiDWr6+vNti6WU9Sxv7VhC5FtTp6ZleZTKEjSax78v7969Q1hYCMuXh+Ds7Ey/ft3/\ndayd3fO36UtOfsTbb49l2LBRvPpqXbPkM6n4UqlUeHo+rvTatzd9klq+ZjCgXbsGo4srug6dst2d\nu6OHGUIJYdsyjBl8dfJzvjr1OYqiMKHWRCbWniQfTIQQ/yk+Ph4vLy+cnZ25ePECd+/eRa/XZ6qP\n+fPn0qNHb+rWrW+2XOa9QSue0Px8ALs/bpHadwC4umapj7ALoeyK3sGHdadSxqOsmRMKYVtuJFxn\n1J6hnLx3nOKuJVjQYjH1ijawdiwhRC5WoUJFnJycGTlyMNWq1aBjx87Mnj2L6tVfNqm9Tqdjx46t\n3Lp1ky1bNgMQENCajh2zNw1IpSiKkq0eckhMTM7MMfPxcTPLudyGDkT7QzgPt+0ho/armW6vKAqN\nw+pyJf4yJ/qcoZhb8Wxnyg/Mdf2E9fzvNVQUhfUX1zLp0Ds80ifRqXwXPm88Bw/H7M+7EJYh70Pb\nJtfPPHx83J75NRn5sgDVgwc4bttCRqXKZNR6JUt97L+1hwtx5+lasYcUXiLfitc95N2fJ7D5Sjiu\nGjcWNF9M14o9ZFK9EMKmSfFlAdqN61Dp9Y8n2mfxl8SC3+YBMLLGGHNGE8JmHPnzF0bvHcafj/7g\nlcJ1CG6xhFLupa0dSwghsk2KL3NTFLShq1E0GnTdemWpi6iYSA79cYCGxZtQzbu6mQMKkbvpDXqC\nfp3O16dno1apefeVyYyvNRF7tfxzJYTIG+RfMzOzjziF/flzpLV/A6VgwSz1sTByAQCjZdRL5DPX\n4q8QuHkYJ2+fpKR7ab5tsYRXCtexdiwhhDArKb7M7O8V7VP79MtyHx/WncpLBavStEQLc8USItfb\nd3MPQ3cNJCk9kR6VehPU8HPcHNytHUsIIcxOii9zSk7G8ftNGIoVR9+4WZa7KeJalMCa48wYTIjc\nbVnUIj745T00ag2rO62mVZGO1o4khBAWI8WXGTlu2Yz6URLJw0fBC1bM/S9J6YkcuX2YgFKtUKvU\nFkgoRO6iN+j58PB7rPh9Kd5OPqxqs5Y21ZrLY+5CiBeaN28OFy+eJy7uATqdjqJFi+Hu7kFQ0Bcm\ntb9z5zYJCfFUrlyFu3fvMHPmdAwGAxqNho8+mk6BAlmbOmQKKb7MyGnNdygqFbpefbPUfs25VUw5\nMpmZDb9gSDXZvknkbQlp8QzZOYCf/9jPSwWqsqZdGCXcSlo7lhDCRowZMwGAbdu2cO3aVQIDx2eq\n/cmTxzEYMqhcuQqLFi2gc+duNG7cjPXr17JhwzqGDx9tidiAFF9mY3f5Eprjv5LeqCnGkqUy3V5v\n0LP4TDDO9i50rtDNAgmFyD2uJVyl79buXIm/TMtSrVkYsAxXh2cvSCiEEKYKDv6Gs2ejMBoNdO3a\ni+bNAzh69DDLly/CwcERb29vRo8ez8qVS9FoHPD1Lcy7737wZCNuT08vbty4ZtGMUnyZiTZ0NQC6\nvlnbRPvHq9/z56M/eLPacLy0BcwZTYhc5cifvzBoRx8epj1kVI2xfFR3GnbqzN+mF0LkLrVqufzn\n348alc6QIfq//qzl2LF/v99r1TKweLEOgNWrNcyd68CpU8mZznD69EkePoxjwYIlpKXpGDKkPw0b\nNmbTpjDGjZuIn1919u/fg0ajoVWrtvj6+lK//mtP2mdkZPD99xsYOnRkps+dGVJ8mYNejzYsFKOX\nF2ltXs90c0VRCP5tHmqVmmHVR1kgoBC5Q+j51bxzcDwKCnOazKdPlax9WBFCiP8SFRVJVFQkgYHD\nADAaDcTFPaBp0xbMmjWDli3bEhDQCi+vfw9yZGRkMH36R9StWx9//9oWzSnFlxk47NqBOjaGlKEj\nwNEx0+0P3z5EVGwkHcp1orRHGQskFMK6DEYDn/w6heDfvsHL0YsVrUOoX+y1FzcUQtgMU0aqgoN1\nLzymXz89/frps5RBo9HQoUMnevd++oNdu3YdqFevAT//fIB33hlHUNCX/2r76adTKVu2HAMGDMnS\nuTNDHqkzA23o47W9dL2z9ik+MS2Roi7FGFkj0JyxhMgVHqUnMXBHb4J/+4YKnhXZ3nWfFF5CCIuo\nUsWPw4cPYTQa0el0zJ37uMhasWIJDg6OvPFGF5o0aU509HXUajUGgwGA7dt/wtnZmYED38yRnDLy\nlU3qO7dx2LsbfU1/DFX9stRH27Kv07J0a9k+ReQ5t5Ju0m9bT849+J3GxZuytNV3eDh6WjuWECKP\nqlHDHz+/6gwfPghQ6NKlBwA+Pr6MHTsCNzd3PDw86Nt3APb2GmbOnI6Hhyfh4esxGIxPbleWK1ee\nCRPetVhOlaIoisV6N6OcWvfHx8ctU+dynvslLkHTSfpiLroBgzN9PqNilDW9zCiz109Yzsm7x+m/\nvRexqTEM8nuTGQ1mobHTvLCdXEPbJ9fQtsn1Mw8fn2c/wS2/9bPDaEQbsgrFyYm0Tl0y3fxe8l1e\nWVOdkHOrLBBOCOsJv7yBTj+0I073gJkNv2BWo69MKryEECI/sGjxFRQURI8ePejZsydnzpz5z2Nm\nz55Nv35Z3wfRmjRHfsEu+gZpHTqhuHtkuv2yqMXcSrpJhpJhgXRC5DyjYmTW8U8ZsXsIDnaOhLbb\nKAsGCyHE/7DYJKPjx48THR1NWFgYV69eZfLkyYSFhT11zJUrVzhx4gQajW1+Iv57E21dn8xPtH+k\nf8TKs0spqC1I90q9zB1NiByXok9h3L5R/HA1nFLupVnTdj2VClS2diwhhMh1LDbydfToUVq0aAFA\nuXLlSEhI4NGjR08d89lnnzFhwgRLRbAoVfxDHH/6gYxy5dHXqZfp9uvOryE+LZ7B1YbhZO9kgYRC\n5Jx7yXfp9ENbfrgaTt0i9dnRZb8UXkII8QwWK75iY2Px8vJ68rpAgQLExMQ8eR0eHs6rr75KsWLF\nLBXBohw3bUCVloauVz9QqTLV1mA0sPBMMFo7LYP8hloooRA5IyomkpYbmxBx/zQ9K/dhQ4cfKOhk\nuQ1phRDC1uXY2gb/fKgyPj6e8PBwVqxYwb1790xq7+XljL19zmxB8rwnFJ5YHwJ2driOHoarKcf/\nw9ZLW7mZeIPhtYbzUklZVNXcTLp+wiy+P/89fTf3JVWfyqwWs3in/juoMvlh5L/INbR9cg1tm1w/\ny7JY8eXr60tsbOyT1/fv38fHxweAX3/9lbi4OPr06UN6ejo3b94kKCiIyZMnP7O/hw9TLBX1KaY8\nYmt/5je8IiJIa92ORDsXyOQjua94NiTs9e8p41FWHuc1M3lEOmcoisK8iLnM+HUKzvbOrGgdQtuy\nrxMb++jFjV9ArqHtk2to2+T6mcfzCliLFV8NGjRg3rx59OzZk7Nnz+Lr64urqysArVu3pnXr1gD8\n8ccfTJo06bmFV26TnYn2ACqViqYlm5szkhA5Js2QxsQD4wi7GEpRl2KsbhdGNe/q1o4lhBA2w2LF\nl7+/P1WrVqVnz56oVCqmTJlCeHg4bm5uBAQEWOq0lpeaiuOmDRgKFSa9eea/j5Bzq2hYvDEl3UtZ\nIJwQlhWbGsugHX04duco/r61+K7NWgq5FLZ2LCGEsCkWnfM1ceLEp15Xrvzvp5+KFy/O6tWrLRnD\nrBy3/og6MYGUQW+Cfeb+912Nv8xbB8ZQq9ArbOuyx0IJhbCMC3Hn6butBzcTb/BG+c583exbeVJX\nCCGyQFa4zyRt6ONCMbVX30y3XRgZjILCiJdHmzuWEBa17+Zu2oUHcDPxBhNrv8+igBVSeAkhRBbJ\nTs6ZoL5+DYdffia9/msYy5bLVNvY1FjCLoRQ0r00bcu2t1BCIcxLURSWRi3ko8OT0Kg1LApYTqcK\nXa0dSwghbJoUX5mgXbsGyNpE+5W/L0Vn0DG8+kjs1fK/XeR+eoOeyb+8y3dnl+Hj5MuqtmupVegV\na8cSQgibJ1WAqTIy0K4LwejuQdrrHTPVNDUjleW/L8bD0ZNeL9nmPpYif4nXPeTNXQP5+Y/9VC1Y\njdVt11HcrYS1YwkhRJ4gxZeJHPbtxu7uHVIHDgGnzM11SUpPolHxppT2KIOrxtVCCYUwj2vxV+i7\nrQdX4i/TunRbggOWys+tEEKYkRRfJtKGPJ5on5Vbjr7OviwMWPbUKv9C5EaH/zzEoB19iE+LZ3SN\ncXxYdyp26pzZWUIIIfILKb5MoLp/H4fdO9D7VSejeo1MtU3Rp+CscX7cjxm2XRHCUtac+453f56A\nChVfNw2m10uZf6JXCCHEi0nxZQLt+rWoMjLQ9cn8Jtq9tnbBXq0htN0GHO0cLZRQiKwzGA1MP/ox\n30bOw8vRi5VtQqlXtIG1YwkhRJ4l63y9iKKgDfkOxdGRtC7dM9X09L2THL19GAe1RgovkSs9Sk9i\nwPZefBs5jwqeFdnRdb8UXkIIYWEy8vUC9sd+xf7qFXSdu6F4emWq7be/zQdgZI0xlogmRLbcSrpJ\n3609OB93liYlmrGk5Uo8HD2tHUsIIfI8Gfl6AafQrG2iHZ14gy3XNuPnXZ2GxRpbIpoQWXbi7jFa\nbWzK+bizDPYbSmi7jVJ4CSFEDpGRr+dQJSXi+OP3GEqWRt+gYabaLo4MxqgYGVVjjEy0F7nKxkth\nTNgfSIYxg5kNv2RItWHWjiSEEPmKFF/P4fj9JlQpKeh69wW16YOE6YZ0Nl8Jp6hLMTqW62zBhEKY\nzqgY+fz4p3x16gvcHTxY1WYlTUs2t3YsIYTId6T4eg5t6CoUtRpdzz6Zaudg58DhXie4mnAFjZ3G\nQumEMF2KPoUx+0aw5epmSrmXJqTtBioWqGTtWEIIkS9J8fUMdufOojl9irQWLTEWLZbp9p5aL2pp\nZR88YX13k+/Qf1tPfouJoF7RBixvtYaCTgWtHUsIIfItmXD/DNq/J9r3ztxE+103thN2IZR0Q7ol\nYgmRKWdifqPVxqb8FhNBr8p92dD+Bym8hBDCymTk67+kpaHdsA6jtzfpLVub3ExRFD79dRqXHl6k\nQbGGshGxsKqfrv5I4N5hpGak8nG9TxhdY6w8/CGEELmAjHz9B8cdW1E/fIiue29wcDC53f5bezkf\nd46O5TtL4SWsRlEUvj41m8E7+wIqvmuzlsCa46TwEkKIXEJGvv6DNiRra3sF/zYPgFGyqKqwkjRD\nGm8fGMv6i2sp5lqc1W3D8POuZu1YQggh/kGKr/8VHY3m4H70r9TBUKGiyc2iYs/w8x/7aVisMdV9\nMrf5thDmEJsay8DtvTl+91f8fWvxXdt1FHIuZO1YQggh/ocUX/9rxQpUipLpUa9vZdRLWNGFuPP0\n3dqdm0nRdCrfhbnNgnGyd7J2LCGEEP9Biq9/MhhgxQqMLq7oOnTKVNNGxZuQmpFKs5IBFgonxH/b\nG72LobsG8UifxDuvTGJi7fdlfpcQQuRiUnz9g+bgfrh5k7S+A8DVNVNte1buQ8/KmVuMVYjsUBSF\nJWe+5eMjk3FQO7A4YAVvVOhi7VhCCCFeQIqvf9CGrgZA17ufyW2S9ckYFQNuDu6WiiXEv+gNeiYd\neodV55bj61yIVW3W4l+otrVjCSGEMIEsNfEX1YMHOG7/CapWJaOW6SvTrzq7ghqrqvDzHwcsF06I\nf4jXPaTn1i6sOrccP+/q7OyyXwovIYSwITLy9Re7W9Go9HoYPRpMnC+jN+hZfCYYgzGDat7VLZxQ\nCLgWf4U+27pzNf4Kbcq8zoIWi3HVZO4WuRBCCOuS4usvGTX8eXDiDAVr+UHsI5Pa/Hj1e/589Adv\nVhuOl7aAhROK/O7nPw7w5s7+xKfFM6bmBD6oOwW1SgavhRDC1kjx9Q/GUqVNHvVSFIVvI+ejVqkZ\nVn2UZYOJfE1RFJZGLeTjw5NRq9R80+xbebhDCCFsmBRfWXT49iHOxPxGh3KdKO1RxtpxRB6VZkjj\nvYNvEXphNT5OvqxoHcKrRepYO5YQQohskOIri/bf3AvAyBqBVk4i8qp7KfcYvKMvJ+4e42WfmnzX\nJpSirsWsHUsIIUQ2SfGVRR/Vm0bXij14qWAVa0cReVDk/QgGbO/N7eQ/6VyhK3OaLpAV64UQIo+Q\n4isbpPASlhB+eQPj940mzZDGh3WnMabmeFmxXggh8hB5VCqT7iXfZdy+UVyIO2/tKCKPMRgNzDg6\nlRG7h6Cxc2BN2zDG+k+QwksIIfIYGfnKpGVRi1l7YQ01fWtRucBL1o4j8oik9ERG7B7C7uidlPEo\ny+o2YVQsUMnasYQQQliAFF+ZkKxPZuXZpRTUFqR7pV7WjiPyiGvxV+i/vReXHl6kSYlmLA5YgafW\ny9qxhBBCWIjcdsyEdRfWEJ8WzyC/oThrnK0dR+QB+2/updWmZlx6eJERLwcS2m6jFF5CCJHHyciX\niQxGA99GLkBrp2WQ31BrxxE2TlEUFp1ZwNQjH2Kvsmdes4X0qNzb2rGEEELkACm+TLTt+hZuJt6g\nf5XB+Dj7WDuOsGG6DB3vHBxP2MVQfJ0LsbJ1CLULv2rtWEIIIXKIFF8mqu5Tg8F+Q3mz2ghrRxE2\n7F7yXQbu6M2peyep6evPytahFHEtau1YQgghcpAUXyYq5V6azxrNtnYMYcMi7p1iwI7e3E2+Q9eK\nPZjd5BtZOFUIIfIhmXBvgnMPzqIoirVjCBu28VIYHTa35n7KPabUm8GC5oul8BJCiHxKiq8XuBZ/\nhaZh9Rm/f7S1owgbZDAamHbkI0btGYqjnZaQtusZXXOsLJwqhBD5mEVvOwYFBREZGYlKpWLy5MlU\nr179ydfWr1/Pxo0bUavVVK5cmSlTpuTKX0gLIxegoNCsZAtrRxE2JiEtnhG7h7D35m7KeZZndZsw\nyntVsHYsIYQQVmaxka/jx48THR1NWFgYn376KZ9++umTr6WmprJ161ZCQkJYt24d165dIyIiwlJR\nsiw2NZZ1F0Io6VaKdmU7WDuOsCFX4y/TZlNz9t7cTbOSLdjRZZ8UXkIIIQALFl9Hjx6lRYvHo0Xl\nypUjISGBR48eAeDk5MR3332HRqMhNTWVR48e4eOT+5ZvWPn7UnQGHcNfHoW9Wp5NEKbZd3M3rTY2\n40r8ZUbXGEdI2w14OHpaO5YQOUJRYNQoOHLEztpRhMi1LFZRxMbGUrVq1SevCxQoQExMDK6urk/+\nbvHixaxatYr+/ftTokSJ5/bn5eWMvX3OvJl9fNxI1aey4uwSPLWejG04ClcH1xc3FLmCj4+bVc6r\nKAqzj87mvT3voVFrWN1pNX2r97VKFltnrWsosi4hATw84PRpWLIEFi925osvYPx4yIUzSsQLyHvQ\nsnJsOOe/nhYcNmwY/fv3Z+jQodSqVYtatWo9s/3DhymWjPeEj48bMTFJnIn5DUVRGFBlCKkJCqkk\n5cj5Rfb8ff1ymi5Dx1sHxrDxUhiFXYqwsnUI/oVqWyWLrbPWNRRZ98cfKlq3dmbYMD1jx6azb58b\nXbsaeestNQcP6pkzR4erfH61GfIeNI/nFbAWu+3o6+tLbGzsk9f3799/cmsxPj6eEydOAKDVamnU\nqBGnT5+2VJQsqe5Tg1P9zjLWf4K1o4hc7m7yHd7Y3IaNl8KoVag2u7oewL9QbWvHEiJHJCdD//5O\n3L+vxsXl8Yfshg1h794U6tTJ4IcfNLRp48yVKzL8JcTfLFZ8NWjQgJ07dwJw9uxZfH19n9xyzMjI\n4P333yc5ORmAqKgoypQpY6koWeZk74Sbg7u1Y4hc7NS9EwRsaMzp+6foUak333fcRmGXItaOJUSO\nUBQYN07L77/b0a9fOoMH6598rVAhhfDwVIYPT+fiRTsOHpR5s0L8zWLvBn9/f6pWrUrPnj1RqVRM\nmTKF8PBw3NzcCAgIYPTo0fTv3x97e3sqVapE8+bNLRUl00bvGUYN35q8WW1Erlz+QuQOYRdCmXhw\nHHqjnuli6Cs7AAAgAElEQVQNghhefbT8vIh85auvHPjxRw1162Ywc2bav+Z2aTTwySdpvP56Bq++\nagAgPR3UarCXWkzkYyrFRpZuz6n7z9fTz1NnaR2alWzButfDc+ScwnxyYq5ChjGD6Uc/ZmHkfDwc\nPVkUsFzWgTMjmW9iG37+2Y6uXZ0pUcLIzp0peHv//6+S513Dd9915OpVNYsW6Z5qI3IPeQ+ah1Xm\nfNmq2Ucf7984qsZYKycRuVG87iG9t3ZlYeR8KnhWZEeXvVJ4iXypTh0Dgwals2pVqslFlF4Pd++q\nOHTInhYtnDl9Wn4FifxJfvL/4WZiNBvPbcTPuzoNizW2dhyRy1yKu0jrTc04cGsfAaVasb3LXsp5\nysKpIn8xGh//19ERZs1Ko2pVo8ltNRpYuVLHBx+kcfeuig4dnPnuOw22cf9FCPOR4usfFp8JxqgY\nGVVjjMzdEU/ZE72TNuHNuZZwlTE1J7CqzTrcHT2sHUuIHJWeDt26ObFypSbLfajVMG5cOuvWpeLq\nqvDOO1rGj9dKASbyFSm+/hKve8iac6so7l6cjuU6WzuOyCUUReGb03Pos7U7ekM637ZYykf1pmGn\nltW7Rf6iKDBpkiOHDtlz6JBdtoulJk0M7N6dQo0aBooUMcpCrCJfkedN/uLm4M785otwdrVHY5f1\nT3Ui70jNSGXC/kDCL2+giEtRvmsTSg1ff2vHEsIqVqzQsHq1A35+Br75RmeWYqlECYUff0xB89c/\nuUYjRESoqVXL9FuZQtgiGfn6i53ajtfLdaCHXw9rRxG5wO1Hf9Lh+9aEX95A7UKvsqvbQSm8RL51\n6JAdH3zgiLe3kVWrUnFxMV/fWi3Y/TWQPHu2A23bOjN7tsOTuWVC5EVSfAnxP07cPUbAhsZExkTQ\nq3Jfvn9jK4WcC1k7lhBWER2t4s03nVCrYflyHcWLW25yVkBABsWKKcya5Uj//k4kJFjsVEJYlRRf\nQvzD2vNr6LS5HXG6B8xo8Blzmy7A0c7R2rGEsJqCBRXq1s3g88/TqFvXYNFz1fi/9u48vKkq/+P4\n+2Zrki600A0oCCKbrDIqsogbDCgMKoxQQMCFAioiuPxURHAGYQSFcURkL4KgIFBRHJBFFgEBZwQp\ngiA7VMYuQEvbJM12f39culF226Rpv6/n6dObm9vm29w2+fScc89p6WXdOhv33ONm7VoDnToF8/PP\n8jYlKh75rRYCbeLU0Vtf5YWNz2I1WlncLYnBLZ6Vq15FpRcSok0P0a+f6+oHl4Jq1VQWL7YzcmQe\nx4/r6NrVyvHj8ncoKhYZcC8qvXOOsySsfZLvUjbSMKIR8x/6jJur1PN3WUL41Xvvmahf38vDD7t9\nfiWiXg+vv+7ktts87NhhoE4dmYdCVCwSvkSldvDsAfqv6s3x88foXOdBPuo4WxZTF5VeUpKBSZOC\nuPlmL126uAnyU897ly4eunTRujpVFT74wESvXi6qV5cwJgp5PNrqCS4XOJ3Khc8QFqYSHq4d8+uv\nOs6e1e4zmbQVGvxJwpeotNYcX80z6waR48pmRKuXea31aHSK9MSLyu2nn3SMGGEmNFRlwQK734LX\nxTZu1DN+fBAzZxqZM8dB27b+ffOsyFwuyMkBt1sLM9Wqqej12u2DB3UFQcflUnA6te3Gjb0FF2P8\n+98G0tMLQ5DbrR1Xv76XRx5xA7BypYENG/S4XMWPMxpVEhMdAPz4o45XXjEXhCqtHu3xli6106yZ\nF1WF6tUvvYbi66/nMXKkE4A33wxi40Yt8jRs6GHLFltZP41XJOFLVDqqqvKvXZP5x85xmA1mZnWa\nxyP1e/q7LCH8LjVVYeBAC3l5kJhop0GD8jPfw333eRg/3sHYsUH07GnhzTfzeOYZl0zOWkpUFXbu\n1DNzppFvvgGPpzDQ7NqVQ1ycSmamwn33XXqekcmTHfTvr40LnDLFxN69JSei7tbNVRC+9uzRsWiR\nqcQxVmthq6bTqXDihA6jUcVo1FqsrFYwmQqPURS49143Op22fJXRqGIyaduNGhX+/j76qIuWLT0Y\njRAV5f+WU0VVA2NRB1+tsC6ruQe2q50/m8vGiI3PsuJwEjVD4pj/4Kc0j2rpwwrF1cjfoH84HPDo\no1Z+/FHPmDEOhg278QH2ZXkOd+zQM2iQmbQ0Hd27u3j/fQchIWXyUJXKhg164uOtADRtCrGx7oIg\nM358HtHRKjYbvP12UEHIyQ9ERqPKvfd6aNpUCzvr1+vJzlYwGLSglH9cVJRKw4baMenpCtnZFNyX\nf6zBABaL356GUhUVdekWOZDwVYK88Ae2K52/lOxTDFzdl70Ze7gz9i4Suywk2hrt4wrF1cjfoH9k\nZsKTT1qoXl1l2rQ/NoN9WZ/D1FSFhAQzO3YYeO89BwMG+OZKzIrkzBmFBQuM9OvnIjpaxe2GV18N\n4rHH3HTrZiUjQ/4G/6grhS/pdhSVwo7/beepbx4nw57O440H8o8O78n8XUIUER4On39ux+Oh3Hfl\nxcSoLF9uZ9kyA/HxWjeWqpb/usuDAwd0zJ5tZOlSIw6HgtcLL73kxGCAyZPzAHkefUHCl6jwFu6f\nz6vfvYhX9fKPu9/lqaaDZf4uIS7YsEGPomhjqrTuJH9XdG2MRujTx11we8yYIIxGlVGjtCAhituw\nQc/06SY2b9aenJtu8pKQkEefPtJq6A/yKyoqLJfHxdjvRzFn70wigiKY03kBd8fd4++yhCg3Dh3S\nkZBgweOBH3/MpVq1gBiFUkJODqxbZ+DoUR0//aRn5kxHuRhUXZ4kJmrBq21bN4MHu+jc2V2wpqbw\nPbmuXlRIZx1niP+6B3P2zqRR1cas+esmCV5CFJGZCf37W8jOVpg82RGwwQu0WfjXrs2lSxcXW7ca\n6NTJyo8/Vt63t9OnFd5+28SIEYVDK0aNyuPbb3NZscLOQw9J8PK3yvvbKSqsX87s58/L7mPLb5vp\nUrcrq3qsp06Vuv4uS4hyw+2GhAQLR4/qGD48j5493Vf/onIuLExbBmn06Dx+/12he3crH38cIH2o\npWTXLh1Dh5q5/fZgPvggiHXrDOTkaPfdequXZs3Kz9QhlZ2EL1GhfHngSx5K6sjJ88d58fb/4+Mu\niwgxXf6KEyEqo7feCmLzZgOdO7sZNcrp73JKjU4Hw4c7WbLETmioyokTleMtbv9+bQ3MLl2CSUoy\nUr++l3/+08F//5sr03CUUzLmS1QITo+Td//zD/61azJWg5U5f55P91se9XdZQpQ7Nps2V1ajRh4+\n+siOrgLmk3vu8bBxo61g3JfXC2lpCrGxgdu1erGsLK27Va+HqlVV9uzR0amTm8GDnXTo4JErFss5\nCV8i4P1yZj/PfTuYnzOSqRtelzl//oRmkc39XZYQ5ZLVCl99ZSMzUyG0AjcKF13/cepUE9OmmZg+\n3c4DDwT2skRHjyrMnm3is8+MTJ/u4MEH3cTGquzenSsXGQSQCvg/j6gsvKqXj36aSqelHfg5I5l+\njQewZ+geCV5CXEJKilIwCN1qhRo1Ks8bdVSUF7sd+va18N57JrwBNvRJVWHLFj39+1to0yaYuXNN\nhIer5OUVHiPBK7BIy5cISCfPn2D4hmf4/vRWIi1RTLl3Kl3qPkRoUCgOZGZmIYrKzYUBAywcOqRj\n48Zcbrmlcr1R9+3rpkkTG089ZWHSpCB279YzbZqd8HB/V3ZtBg4088032sUDf/qThyFDnHTt6g6Y\nOdlESRK+REBRVZXFBxbxxtZXyXFl82Ddbky+9wMiLZH+Lk2IcklVYfhwMz//rGfAACf16lWu4JWv\nRQsv69blMnSohXXrDHTqFMyaNblUrervykpKS1M4dEhHu3ZaF2n79h7MZhg82MnttwdYs524JAlf\nImCk29J5afNwvjn2b0KMoXxw/3R6N+wrs9ULcQVTpphYudJImzZuJkzIq9QDsatWhc8+s/Puuyb+\n9z8dERH+rqi4n3/WMWuWiaQkA2FhKrt25V4IXS4GD5aZ6CsSCV8iIKw+9m9e2vQ8GfYM2tW4mw8e\nmE6t0Nr+LkuIcu3rrw1MnBhErVpe5s51YDL5uyL/0+vhtdecxdaCXL7cwF/+4vbL8+P1wtq1embN\nMrF1q/aWXK+el4SEijMFiChJwpco17Kd5xm99TU+O7CQIH0Qf283gcHNn0WnyLUiQlyJ1wv//KcJ\nq1VlwQI7kZGVs7vxcvKD14oVBp55xsKcOR4SE+3FrpL0hR079AwYYAWgQwc3Q4Y4eeABT4WcAkQU\nkvAlyq3vf9vK8xuGcir7JM0iWzCt4ywaVW3s77KECAg6HSxfbuOXX/Q0aSLjhC6nUyc3PXq4SEoy\n8sADVmbPdhSMtSoLp04pzJlj4oknnNStq9KmjYcXX8yje3c3t94q56mykGwtyh2H28HYbW/w6Jdd\n+S0nhZF/epnVPb+V4CXENXA6tbmgAMLDoU2bwJ7XqqwFB8P06Q4mTHCQmanw179amDbNiFqKDWCq\nCj/8oOPpp83ccUcw06ebWLRIu1RRUbRuUAlelYu0fIlyZW9GMsPWD+aXs/upW+Vmpj0wi9tj7/R3\nWUIEBFWF118P4osvjCxbZqNVK3lDvxaKAoMGuWjWzMugQWb+9jcztWqpdO/+x9e8/OorA9Ommdi9\nW1vJumlTbaqIRx4J/PU0xY2T8CXKBbfXzYe73+fd//wDl9fFE02eZmzbtwk2Bvu7NCECRmKikU8+\nMdG0qYeGDSV4Xa/WrT2sX29j3jwj3brdeDgqOph/zRoDP/2ko0sXF0OHumjTRpb+EaCoamk2rpad\n9HTfTJwZFRXqs8cSmqNZRxi2fgj/Tf2BGGss/7r/I+6v3fGGvpecv8An5/DGfPednt69LUREqKxd\nayMuzn8v7RXpHE6ebKJBAy9/+cvVw9ivv+qYNcvIb7/p+OwzOwAnTih4vVC3bkC81QIV6/z5U1TU\n5dfvkpYv4TeqqrJg/zzGbhuFzW3jkVt6MLHDFCLM5XDWQyHKsWPHFAYNsqDTwbx5Dr8Gr4okNVXh\nww9N5OYqPPeckzfeyMNw0bumqsKmTXpmzjSxYYN2Z+3aXjIztTF3N90k50KUJOFL+EVq7u+M2Pgc\n355cR5WgcGbcN5Ue9R/zd1lCBKRXXzWTmanw/vt2WreWAfalJSZGZfVqG08+aWHaNBM//aRj1ixH\nwTqK+/frGDLEzMGD2niu1q3dDBni4sEH3ej1/qxclHcSvoTPfXX4C17ZPIJzeee4t9b9/Ou+j6ge\nUsPfZQkRsKZOdbBypYG+fWUQd2lr1MjLmjW5PP+8mdWrjdx7r5WkJDsNG3qJi/OSlqajZ08XQ4Y4\nadlSxtmJayPhS/hMpuMcr295heWHPsdisPCPu9/jqaYJsjyQEDfo/HkIC9NaaAYNkuVnykpYGHz8\nsYOpU71MmGBi924dDRt6CQuDXbtyCJbrgsR1knm+hE9sPrWRe5a0Yfmhz2kV/Sc29NrK080GS/C6\nDmfOyHMlCi1fbuCuu4L5z3/kZdwXFAWGD3fy5Zf2gm5HQIKXuCHyVyvKlM1lY9SWV3hs5cOk29N4\n9c43+LrHOuqF1/d3aQFl714dbdsGM326NjFjXh64pKGj0tq9W8fIkWby8hSqVPF3NZVL69YeHnhA\nxtWJP0a6HUWZ2Z36I899O5jDmYeoH96AjzrOpkX0bf4uK+Ds3aujZ08rWVkQEaGiqjBypJm0NIW5\nc+3y5lvJpKYqDBxoIS8PEhPtNGgg44yECDRl2vI1YcIEevfuTXx8PMnJycXu27FjB7169SI+Pp7X\nX38dr1deQCoKl8fFpB8m8FBSRw5nHmJI82dZ32uLBK8bkJxcGLz+9S8H8fFu8vIgO1vhu+8MdO1q\n5cQJ6Y6sLBwOGDjQwu+/6xgzJo+OHaUFRohAVGbh64cffuDEiRMsWbKE8ePHM378+GL3jxkzhg8+\n+IDFixeTm5vLli1byqoU4UOHzv1K16SOvPffd4gNrs7y7isZ1/4dLAaLv0sLOHv2lAxeAGYzfPyx\nnSFDnPz6q54HH7TKuJ9K4q23gti1S89jj7l49lnpdxYiUJXZK/b27dvp2FGbpbxevXpkZWWRk5NT\ncH9SUhKxsbEAVK1alXPnzpVVKcIHvKqX2cnTeeDz9vyUvpteDfuwqff33B13j79LC1izZ5s4f16b\nRiA/eOXT62HcuDwmTnRw7pxCjx5WvvhCRhFUdEOGOOnd28XkyQ5ZokaIAFZm4SsjI4OIiIiC21Wr\nViU9Pb3gdkhICABpaWls27aNe+6RN+lA9Vt2Co+tfIQ3tr6K1WhlbudP+PCBmVQJCvd3aQFtyhQH\nS5fa6dXr8nM3Pfmki0WL7JhMkJIirV8VVf6ojLp1VaZOdWA2+7ceIcQf47N/lS+1hOSZM2cYOnQo\nY8eOLRbULiUiworB4Jspg6+0HpMopKoqi/YuYtiqYWTlZdGtQTdm/2U2sSGxfq0rkM/fDz/AsWPQ\nu7d2u2fPq39N797Qrh3UrBmEogTh8YDbDUFBZVtrWQrkc1jafvkF4uNh/nxo2dLf1Vw7OYeBTc5f\n2Sqz8BUdHU1GRkbB7bS0NKKiogpu5+TkkJCQwIgRI2jfvv1Vv9+5c7YyqfNisqDotTnrOMMrm0ey\n8sgKrIZgptw7lX6NB6DYFdLt/nv+Avn8/fijjl69rOTlQcOGudSsee1rwgUFQf6f2+jRQSQn65g3\nz0G1aoG3rlwgn8PSlpkJXbsGc+yYjp077dSsGRgz2Ms5DGxy/krHlQJsmfVTtGvXjjVr1gCwb98+\noqOjC7oaAd555x0GDhxIhw4dyqoEUUbWn1hDh8V3sfLICu6MvYtNvb/n8VsHyoSpf8B//6sFr9xc\nbYzX9QSvotxubSqCHTsMPPiglcOH5ZwEKrcbBg2ycOyYjhdeyKNHj8AIXkKIqyuzlq9WrVrRpEkT\n4uPjURSFsWPHkpSURGhoKO3bt2fFihWcOHGCZcuWAdCtWzd65/e1iHIpx5XD2G1v8Mn+eRh1Rkbf\n9TeeazkcvU5WkP0j/vMfHb17W7HbYcYMB488cuNvsgYDzJzpoF49L1OmBPHgg8HMm2enfXuZkiDQ\nvPVWEN99Z6BzZzevv+70dzlCiFKkqJcajFUO+aoJVJpbL+2H/+1k2LeDOX7+GI2rNuGjjrNpEtnU\n32WVEGjnLzlZxyOPFAavhx8uvdaNxYsNvPSSGVWFyZMd9OkTGC0ngXYOy8KnnxoYMcJCw4YeVq2y\nERpgw2/kHAY2OX+lwy/djqJicHqcvL39Lbqv6MyJ88d5/raRrH1sU7kMXoGobl0vTZt6mDmzdIMX\nQHy8m6VL7YSGwqFD8qceSJo399K8uYcFC+wBF7yEEFcnEwOJy/rlzH6eXZ/AvjN7qR1Whw8fmMld\n1dv4u6wKwWYDqxVCQ2HFCju6MspGbdt62LAhl+rVtQZuVdXWhZSpCsq3pk29rFtnk7m8hKig5N9h\nUYLH62Ha7g/otLQD+87s5fHGA9nUa5sEr1KyY4ee228PZutWbaxcWQWvfDVrqgWPMXmyiYcftpKa\nKu/q5U1uLgwZYuboUe3cSPASouKS8CWKOXH+OD2+6sbfto8mLKgKnzy0hCn3TSXEJH0fpWHHDj3x\n8RYyMxWysnz77qqqcPKkjt27tSWJ9u+XP//ywuuF558388UXRubNM/m7HCFEGZNXXwFoE6Z++ssn\n3LukLdtPb6Przd35Ln4nnes86O/SKozt27Xg5XTCnDkOunb17QB4RdHWiBw1Ko+UFB3dulnZsEGu\nVC0Ppkwx8fXXRtq0cfPmm3n+LkcIUcYkfAnSbGkMXN2HERufQ6fomHr/DBI7f0KkJdLfpVUY33+v\np08fCy4XzJ3r4KGH/HPloaLAiBFOZs+243JB374W5s41+qUWoVm50sCkSUHUquVl7lwHJmn4EqLC\nkwH3ldyqo1/z8ubhZNgzaF+zAx/cP5240Fr+LqtC8XphzJigC8HLTpcu/p9z6+GH3dSsaWPAAAs/\n/6xDVWWMkT/8/LOO5583Y7WqLFhgJzIyIGb+EUL8QRK+Kqls53ne2Poqiw8sIkgfxLh2/yCh+TPo\nFGkMLW06HSxcaOeXX3Tcd5//g1e+22/3sn69jagotSB45eUF9pqQgcZuh+BglUmT8mjSxOvvcoQQ\nPiLhqxLa9tsWhm94hlPZJ2ke1ZJpD8yiYdVG/i6rwtm6VU9EhEqTJl5iY1ViY8tP8MpXo0ZhS8vc\nuUYWLjSyaJG92H5Rdu64w8vOnbkUWXlNCFEJSDNHJeJwOxizbRQ9vuzG6ZzfePH2/2NVj/USvMrA\n5s16+va10K+fBYfD39Vcm8OHdezbp6dzZyt79shLQ1lRVfjwQ2PBdB8SvISofOQVthLIdp5nTvIM\nOixuzYw9H1K3ys183WMtr905GpNeRveWtk2b9PTvb8HrhffecwTMhKYTJuQxbpyDtDSFhx+2smqV\nNIyXhcREI3//u5mXXgqQXwwhRKmTV9cK7GjWEeYmz+SzA4vIcWVj0plIaDaUUXeNJdgY7O/yKqSN\nG/UMHGhBVWHBAjv331/+uhovR1FgyBAXN93kZehQC08+aWbMmDyefdYlg/FLwfnzsGCBkfHjg4iM\n9PLOOwHSJCqEKHUSvioYVVXZnLKROckzWHdiDSoqMdZYht32Av1vfZIoa5S/S6ywNm/WM2CABYD5\n8wMreBXVpYuHlSttPP64hR9/1KOqEr7+CJsNxo8P4tNPjeTmKoSEqMyb5yAuTsbVCVFZSfiqIHJd\nuSw9uJi5e2dy8NwBAP4UcwcJzYfS7eaHpXvRB6pXV4mJUZk0yRGwwStfs2Ze1qyxERZWuDSR04nM\nQXWNVFV7voKCwGLRgnlYmMrIkU7693cSEeHvCoUQ/iThK8Cdyj5J4t7ZLPxlPll5mRh1RnrW70VC\n86G0irnd3+VVCm43GAzQoIGX77/PrTABJTa2sGVm2TID779vYuFCO3XqSIvN5TidsGKFgZkzTbRv\n7+Fvf8tDUeCTT+zExakYZT5bIQQSvgKSqqpsP72N2XtnsPrY13hVL5GWKF66/VWeaPI0McGx/i6x\n0li/Xs9bbwWxeLH25lpRgtfFDh7U8euv2pqQ8+fbufNOmZOqqDNnFBYsMJKYaCQ1VYdOp9KsWWHr\nZ926EliFEIUkfAUQh9tB0qGlzE6ewb4zewFoHtWShGZDeaR+T4L0MjumL61bp+fJJy3o9dqC1XFx\ngd3VeCVvvOEkLk7ltdeC6NnTyr/+5aBHD/8skVTefPqpgddeM+NwaOO5hgxxMmiQk5tuksAlRHmg\nqpCernDqlMKpUzpOn1a4/34PjRr5759ICV8B4H85p5n38xw+2T+PM44z6BU93es9SkLzZ7gztjWK\njIb2ubVr9Tz1lBa8Fi6007ZtxQ1e+QYO1K6EfPppC0OHWjh6NI+XXnJWusH4qgq7d+to1Up74W7U\nyEt0tEpCQh59+7oIDfVzgUJUMqoKaWmF4Ur7UAo+p6TosNuLv1AdPuxkyhT/LWIv4aucUlWV/6b+\nwOzk6Xx99CvcXjcRQREMv+1Fnmw6iJqhcf4usdJas0YLXgYDLFpkp337ih+88t17r4dVq2z062dh\n+3Y9bjeVZhyT3Q7LlhmZNcvIwYN6Nm3K5dZbvbRqpc1Sr9f7u0IhKiavV2u5OnmyMFzlb6ekaOHK\n4bj0f4FVq3pp0MBLrVpeatVSL3z2+v11W8JXOeP0OPnycBJz9s5gd9ouABpXvZWE5s/Qs0EvLAaL\nnyus3HJy4IUXzBiNWvBq167yBK98DRt6Wb3ahtFYOIDc5aq4ISw1VWHePCPz5xs5c0aHwaDSs6cL\ns7mwW1GClxA3zuvV/s4ubrk6eVLb/u03hby8S4eratW8NGpUPFzVru0lLk7bLq8rSEj4KifSbGnM\n3zeX+fsSSbOloqDQpW5XBjd/hnY17pauxXIiJAQ+/tiB10ul6Gq8nKiowuCxfr2eN980s2CBnfr1\nK9ZAfIcD7r47mMxMhYgIlRdeyOOpp1xUry7juYS4Vh6PFq60MKW1VF0crpzOS7/HRUZ6ufXWkuGq\nVi2VuDgvwQE6X7iELz/bk7abWcnT+fJwEk6vkzBTFYa2GMZTTROoU6Wuv8sTF2zerKdFCw/h4XDX\nXZU3dF3Kzz/rOXJEx0MPWUlMtHP33YH7/Hg82oUUFgvcc48HsxmGDXMSFqbSq5cLq9XfFQpR/ng8\n8PvvSonuwKLhyuW6dLiKivLSrJmXuLjCgJUfrmrWDNxwdTUSvvzA5XGx6thKZiVP5z+/7wTglvD6\nDGo+lF4N+xBiLKftpJXUv/9tICHBTOvWHpKS7JVugPnVjBjhpHp1Ly++aKZ3bwvvvptHv34uf5d1\nXXJyYPFiI7NmmTh+XEeLFh7uuccGwPDhTj9XJ4R/ud0lw1XRgPXbbwpu96VfGKOjvTRvnt8VWDJc\nVdZ/aCR8+dAZ+xkW7v+YeT/P4XTubwA8ULsTCc2f4d5a96NTZJ3z8mblSgNDhpgJCoJXX618V/Zd\nq9693dSubeeJJyyMHGnmyBGF0aOdBbPjl1cpKQpz5phYuNDI+fMKQUEq/fo5GTw4sMKjENfD6YTz\n5xXOn4fsbOXCtkJ2trbf6YRffzUXm5rhcuEqJsZLy5b5XYGF3YG1a3upWVPFIsOUL0nClw/sy/iZ\nOXtnsPzXz3F4HAQbQ3i62WAGNRtCvfD6/i5PXMbKlQYGDzZjNsPixXZatw7c7jRfaNPGw+rVufTr\nZ2XbNgN5ec5y/8K7YYOBjz4yERXl5f/+z8nAga5i49mEKE9UVRuHWDQoadslb+eHq6K3s7O1sHW5\nKwOLM6Io2pJpt93mLTbWKv+KwZo1VczmMv+xKyQJX2XE4/Ww5vhqZidPZ9vpLQDcFFaHQc2G0KfR\n44QFVfFzheJKvvpKa/GyWGDxYpvM6H6Nbr5ZZdWqXFwupSB45S+/5G9ut9aFvGiRkcREOyEh8Nhj\nLuczNl0AABRWSURBVIKCVB55xE2QzFEsypCqaousXy4YXaoV6lKtUpcbO3UlZrNKaKhKWBjExXkv\nbGsfoaEU2dZu16ljITg4h5o1Vfm7KCPl4CWxYsl0nOPTAwtJ3DuLk9knAOgQdx8JzYfSsfaf0evk\nmvRAoNdDWBgsXGjjjjskeF0PbdForfVo5049L7xgZu5cO02a+Od5zMqChQuNzJ1rIiVFh6KobN2q\np0sXDxaL1mUqxNWoqjY2MC1NISNDVxCGirYqFW95Knm/x3P9wclq1YJRtWoqdeqoVwxOYWElg1RY\n2PUvexYVBenp0gJcliR8lZJfzx5kzt4ZfH7wM2xuGxaDhQG3PsWg5kNoVLWxv8sT10hVQVGga1c3\nHTrkyGzlf1Byso6jR3V062Zl9mw7HTv6ruvW5YKxY4P47DMjubkKVqvKU085GTzYyc03yxuL0Hi9\nkJGhkJqqkJ6ufU5N1ZGWlr+tkJam3bbZri88hYRoQSg21kv9+hcHpcJwVBioKBGuykOrsSh9clr/\nAK/q5dsTa5m9dwabTm0AIC6kFi83e51+jfsTYa7q5wrF9fjiCwPLlhmZO9eO2YwEr1KQkOAiJkZl\n2DAzjz9uYfz4PJ5+uuwGs6uqNhO91apN+rpnj54qVVRefNFJ//5OwsPL7KFFOeNwUBCg0tJ0Fz4X\nv52aqpCRoVyxRUqnU4mKUqlXz0tMjEp0tJfIyEsHpaK3Q0Jk8l1xeRK+bkC28zyLDyxizt6ZHMs6\nCkCbGu1IaPYMXeo+hEEnT2ugWb7cwHPPmQkOhmPHdDRuLF2NpaV7dzc1a9oYMMDC66+bOXJEx9//\nnleq/9E7nVp4njXLRLNmHt5/X1uzbfZsO1FRaoWdfb+yUVWtG7loeNICla5Ey1VW1pVbqSwWleho\nlVatvMTE5Acrtdh2dLRKZKQqIUqUOkkJ1+Fo1hHmJs/kswOLyHFlE6QPok+jxxnUfCjNIpv7uzxx\ng5YtMzBsmJmQEPj8c5sErzLwpz95+eYbbU3IzZv12GzamLo/6swZhfnzjSQmGklL06HTqTRs6C3o\nPq5RQ7oXA4HbrXX9FXb1Fe/2S03VkZ6u3X+1K/UiIlSqV/fSokV+mNIC1cXboaHI1DHCbyR8XYWq\nqmxO2cic5BmsO7EGFZXY4Oo8f9sI+jd5kkhLpL9LFH/A0qUGnn9eC15Ll9q47TYJXmWlVi2Vf//b\nRlaWUhC8PJ4b75pZvtzAyJFmHA6F0FCVoUOdDBrkpHZtCVzlhc1GsfBUdAxV0ZarjAwFVb18EjIY\ntCDVqFFh119hmNJux8Ro3YNydZ4IBBK+LiPXlcvSg4uZu3cmB88dAOBPMXcwuPkzdLv5YYx66ccI\ndEePKjz/vJnQUC14tWwpwaus5Y+LAdi3T8egQRamT7df03OvqrBjh5677vKgKNCihYfYWJVBg/Lo\n29dVbhfQLU/cbsjLy/9QLvp85X0Ohzb55uW3FRwObV9mJpw+HUJOzpWbloKDtfB0yy2egjCldfd5\niwQrlapV1XI/Ya8Q10PC10VOZJ7g3e//ycJf5pOVl4lRZ6Rn/V4kNB9Kq5jb/V2eKEU336wyaVIe\nLVp4aNFCgpev7dmj4+hRhYcftjJtmoNu3S495YPdDkuXGpk1y8ivv+r56isbd93l4ZZbVHbuzA2Y\nrqP8eZ5sNi3MOJ1acLmeAHQjoanovhuZ6uB66XQq1apB7dqXHkdVtOVKArOorCR8XZDjzGbExmF8\nffRLvKqXSEsUL93+Kk80eZqY4Fh/lydK0Y4deu64w4NeDwMGyDIy/tK3r5tq1ewMGWLhqacsvPlm\nHsOGFa6jmJqqkJhoZP58I2fP6jAYVP76VxfVqhV2K5ZF8FJVLRjZbJCbq1z4oOCzzXZt+3JzlQv7\n87e5YtdaaTAatTmdzGat+81shvBwL0FBFNtvMmkzkxff1u7TPtSLPl9tX+G2wQDR0aGkp9vK9GcV\nIpBJ+LrgZPZJvj76JS1jW/Jk48E8Ur8nQXoZPFDRfPaZgREjzCQkuHj77Tx/l1Ppde7sYeVKG/37\nWxg3LoijRxXmzdPGgnXqZOX333VERKiMGJHHU0+5iI0tPp7L7S5sTSoMPkUDUckAdalQdfG+y61j\nd610OpXgYG2CzJAQbf274GBtn8VyvWFH2zabtaCUH6qKhiaTSTtOrsoTIjAoqqoGxOjU9PTsMn+M\nHFcOdarHkpGRU+aPJcpGVFToZX9XPv1UG6AdHg7Lltlo1ky6Gn3N5dJmCdfWotM+cnLg1CmFqVOD\nyM5WGDRIITfXye7dOpxOhchILw5HYStS0VB1bWvUXZnVqmK1Foal4GAuBKUb32c2V+4r6a70dyjK\nPzl/pSMq6vKTRUrLVxHO7BCO2BQMBggO9nc1ojQtWmRk5EgzERGqBK/rlL+Yb35QKhqc8tefy8kp\n3L74uPz7cnIU7ParJ5LJkwGKroeiNeeYTIXhJjJS5aab1BIhyGql2Of8YHS5fRaLtBYJIXxPwlcR\nSUlGRo0CCCUkpPicMO+/78Bq1f5r//FHfcF94eGV+z/cQLBwoZEXXzRTtaqXZcvsNG1aOYKX1wu5\nuVw1KJUMS0WP04690W44q1VbOqVKFZW4OJWQkMI157TPWrdc/nZoqErNmlZcrtwSoUomShVCVBQS\nvoqoV8/LE0/AiRPugvlnjhwxYDCozJihHXP4sI7HHrMWfI3JVHgFz4QJjoJ5opYvNxAWVnhfZKQq\na3T9QflLx2Rna91O+eEgJ6dw22CAnJzi79Lr1hmwWlX69HGxbZuebduKN3VcKTxf7r7r3X8l1/O9\n8q+YK/zZr9T6dGOBSacrDEexsV5uuaV4OCoalopvlwxVN9KqpC3qWzkCshCicpI4UMR993no1QvS\n0+0F+1wuOHtWKZhjJjJS5ZVX8kqsEZacXDgJjdcLw4ebcbkK3/y0y69VRoxwkpCgXWH3xRcGzp5V\nCpaxyL8c22Lxzc/rC/mtLzk5xbufim7n5hZvbcnfvtR+r/daAoX5knunTavYF1AEBRWGnshIb0EL\nU3CwWiQ8ccmglH9fSIjWyiStuUIIUXYkfF2F0QgxMYXXJMTFqbzyirPEcV5v8e3Jkx2kpZVcIsNU\nZCjLvHlGduwoeQo6dnTz6adaAPz2Wz2bNxsKglnReXOqVCmbN0m3m4LWpIsD07XsLxqYcnNvvECj\nsTBMxMV5CQkpbGnJ384PFiEhWnCIjbVw/rydb7/Vk5mp0KOHG0XRWowu5UqXm9zI1/jiMbSuPIp1\n4YWEyMzeQggRKMr0ascJEyawZ88eFEVh1KhRNG9euP5hXl4eY8aM4dChQyQlJV31e5X1lRc5OfDe\ne0E4nSYcDuclQ03+vqL3XbzvSvddvC8tTesestnAblcKLpmPjFQLZvHevl3PTz+V7LvR67XlVBRF\na5nbuVN/yauvqlXTujvzH9fh0MJRbm7JLrv8/dcyKPpyLBbt8S8OSaGhl98fEqLVmx8m8oPUjYSJ\nqKhQJk508NprZiIjvWzebCMqKiAu6BUXyJVWgU/OYWCT81c6/HK14w8//MCJEydYsmQJR44cYdSo\nUSxZsqTg/kmTJtG4cWMOHTpUViVcl+PHdUyfbrzQ4mC62uFlKiWFSwauojwepdS60YKCVMLDtQ+j\nEcLC1IL5hLT5g1Rq1FBp29ZDSIjK//6nIyVFwWIpfnVZaKhKnz7aLOXnzsH27QaMRhW9Xpt40WDQ\nxgA1buwpWNvv0CFtMeSix3i92jxPhT8r6HTX1so3bRq89pqZqCgvSUl2CV5CCCHKnTILX9u3b6dj\nx44A1KtXj6ysLHJycgi5sJ7EyJEjyczM5KuvviqrEq5L06Ze9u7NxWQK4cyZwnm+8tsF82emLtpO\nWHjf5fdd7fgb+bqL7/N6ISsLzp7VcfaswtmzCufOaZ/z17zLyoKnn7bgdJZMMG+9lcfTT2vj0Lp0\nsbJrV8ngFxPjKhirNnGiiYULSwbUoCCVPn205+7XX/U88cSlB6+tWGGjbVstXXXqZMVmK1nTiBF5\njBqlde8+/bSZVauM6HRaOMwPai1aeFi+XOueXb7cwMSJQRw/DlFRXr74wk6DBjJoWwghRPlTZuEr\nIyODJk2aFNyuWrUq6enpBeErJCSEzMzMsnr4GxIdrRIVBeHhl2otCYQWlCuHjZSUnIJWJbe78MNc\nZHx6YqIdu12bWsDt1o51uShoqQL4619d3HabB7dbKfheLlfxUFi7tpe//91x4XsoxR4vLq6wzr59\nXeTlFX88txsaNSo8plEjL5mZ7hLfKzKy8AHzFwxu1QqmTrVTv74ELyGEEOWTzwbc/9GhZRERVgwG\n38yGeKV+2oouKurajrnrrqsfU2SI30UKu0tnz77cMYXTRWiTbl6KvuC4YcO0D43MkBvoKvPfYEUh\n5zCwyfkrW2UWvqKjo8nIyCi4nZaWRtS1vLNfxrlzvlmkVQYaBjY5f4FPzmHgk3MY2OT8lY4rBVjd\nZe/5g9q1a8eaNWsA2LdvH9HR0QVdjkIIIYQQlVWZtXy1atWKJk2aEB8fj6IojB07lqSkJEJDQ+nU\nqRPDhw/n999/59ixY/Tv359evXrxl7/8pazKEUIIIYQoF8p0nq/S5KsmUGluDWxy/gKfnMPAJ+cw\nsMn5Kx1+6XYUQgghhBAlSfgSQgghhPAhCV9CCCGEED4k4UsIIYQQwockfAkhhBBC+JCELyGEEEII\nH5LwJYQQQgjhQxK+hBBCCCF8SMKXEEIIIYQPSfgSQgghhPAhCV9CCCGEED4k4UsIIYQQwockfAkh\nhBBC+JCELyGEEEIIH1JUVVX9XYQQQgghRGUhLV9CCCGEED4k4UsIIYQQwockfAkhhBBC+JCELyGE\nEEIIH5LwJYQQQgjhQxK+hBBCCCF8SMLXBRMmTKB3797Ex8eTnJzs73LEDZg0aRK9e/emZ8+erF27\n1t/liBvgcDjo2LEjSUlJ/i5F3ICvvvqK7t2706NHDzZt2uTvcsR1ys3NZdiwYfTv35/4+Hi2bNni\n75IqLIO/CygPfvjhB06cOMGSJUs4cuQIo0aNYsmSJf4uS1yHHTt2cOjQIZYsWcK5c+d49NFH+fOf\n/+zvssR1mj59OlWqVPF3GeIGnDt3jmnTprF8+XJsNhtTp07l3nvv9XdZ4jp88cUX1K1bl5deeonU\n1FQGDhzIN9984++yKiQJX8D27dvp2LEjAPXq1SMrK4ucnBxCQkL8XJm4VnfccQfNmzcHICwsDLvd\njsfjQa/X+7kyca2OHDnC4cOH5Q07QG3fvp02bdoQEhJCSEgI48aN83dJ4jpFRERw8OBBAM6fP09E\nRISfK6q4pNsRyMjIKPZLVrVqVdLT0/1Ykbheer0eq9UKwLJly+jQoYMErwAzceJEXnvtNX+XIW5Q\nSkoKDoeDoUOH0rdvX7Zv3+7vksR16tq1K6dPn6ZTp048/vjjvPrqq/4uqcKSlq9LkBWXAtf69etZ\ntmwZiYmJ/i5FXIcVK1bQsmVLatWq5e9SxB+QmZnJhx9+yOnTpxkwYAAbN25EURR/lyWu0ZdffkmN\nGjWYO3cuBw4cYNSoUTL+soxI+AKio6PJyMgouJ2WlkZUVJQfKxI3YsuWLcyYMYM5c+YQGhrq73LE\nddi0aROnTp1i06ZN/P7775hMJmJjY2nbtq2/SxPXqFq1atx2220YDAZq165NcHAwZ8+epVq1av4u\nTVyjXbt20b59ewAaNWpEWlqaDN8oI9LtCLRr1441a9YAsG/fPqKjo2W8V4DJzs5m0qRJzJw5k/Dw\ncH+XI67T+++/z/Lly/n888957LHHePbZZyV4BZj27duzY8cOvF4v586dw2azyZihAHPTTTexZ88e\nAH777TeCg4MleJURafkCWrVqRZMmTYiPj0dRFMaOHevvksR1WrVqFefOnWPEiBEF+yZOnEiNGjX8\nWJUQlUdMTAydO3emV69eAIwePRqdTv6/DyS9e/dm1KhRPP7447jdbt566y1/l1RhKaoMcBJCCCGE\n8Bn5t0QIIYQQwockfAkhhBBC+JCELyGEEEIIH5LwJYQQQgjhQxK+hBBCCCF8SMKXEEJcRVJSEi+/\n/LK/yxBCVBASvoQQQgghfEgmWRVCVBiffPIJq1evxuPxcPPNNzNo0CCGDBlChw4dOHDgAAD//Oc/\niYmJYdOmTUybNg2z2YzFYmHcuHHExMSwZ88eJkyYgNFopEqVKkycOBGAnJwcXn75ZY4cOUKNGjX4\n8MMPZd1CIcQNkZYvIUSFkJyczLp161i0aBFLliwhNDSU77//nlOnTtGjRw8+/fRT7rzzThITE7Hb\n7YwePZqpU6fyySef0KFDB95//30AXnnlFcaNG8fChQu544472Lx5MwCHDx9m3LhxJCUlcejQIfbt\n2+fPH1cIEcCk5UsIUSHs3LmTkydPMmDAAABsNhupqamEh4fTtGlTQFtKbP78+Rw/fpxq1aoRGxsL\nwJ133snixYs5e/Ys58+fp0GDBgA88cQTgDbmq1mzZlgsFkBbSic7O9vHP6EQoqKQ8CWEqBBMJhP3\n338/Y8aMKdiXkpJCjx49Cm6rqoqiKCW6C4vuv9yKaxcvMCwrswkhbpR0OwohKoRWrVrx3XffkZub\nC8CiRYtIT08nKyuL/fv3A7Br1y4aNmxInTp1OHPmDKdPnwZg+/bttGjRgoiICMLDw0lOTgYgMTGR\nRYsW+ecHEkJUWNLyJYSoEJo1a0a/fv3o378/QUFBREdH07p1a2JiYkhKSuKdd95BVVWmTJmC2Wxm\n/PjxjBw5EpPJhNVqZfz48QC8++67TJgwAYPBQGhoKO+++y5r1671808nhKhIFFXazoUQFVRKSgp9\n+/blu+++83cpQghRQLodhRBCCCF8SFq+hBBCCCF8SFq+hBBCCCF8SMKXEEIIIYQPSfgSQgghhPAh\nCV9CCCGEED4k4UsIIYQQwockfAkhhBBC+ND/A0cHR0daqTk8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0523bf9e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yyJVLeEQ2d0a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see from the plot above, the more layers we add the worse the models perform. One of the  reasons is the fact that we use sigmoid for the hiden layer as well.  With MNIST, we are trying to predict based on probabilities.\n",
        "The sigmoid function \"squishes\" the weights between 0 and 1. Moreover sigmoid  tends to create the \"vanishing gradient problem\", which is common with sigmoid as \n",
        "an activation funstion especially for multiple layers, which is the reason of the decreasing accuracy. Using softmax as the activation function for the output layer seems logical, since it is the norm for classification problems with multiple classes, so this will not be modified\n",
        "\n",
        "On the other hand the ReLU function which we use later does not squish the values. If the value is less than 0, then the output is 0. If its more than 0, the answer is the value itself. This leaves for more space for the parameters to \"train\" and find the best possible changes for w's. Also, having multiple layers (aka a deep network) makes our network more eager to recognize certain aspects of input data. For example, if we want to find the details of the number \"5\" having more layers than needed can lead to overfiting.\n",
        "Specifically we get:\n",
        "\n",
        "-For 1 hidden layer:  88%\n",
        "-For 2 hidden layers: 79%\n",
        "-For 3 hidden layers: 26%\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2Gxa5WoF19gE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "   In the next cell we train the modified models. We increased the dropout to 0.4 to reduce overfitting and generalize in a more efficient way. The idea is that in each step each neuron has a probabilty of 'p' of drop rate, meaning that it will be ignored for the current step but it can be use for the next one. A typical values is 50%, in our case 40% seemed to provide slightly better results.\n",
        "   \n",
        "   To determine which activation function to use for the extra hidden layer first we tried a number of different functions like 'linear' 'relu' etc. Out of all possible activation functions relu was one of the best performance in terms of loss, meaning that it was among the lowests. Additionaly, the selection of relu is justified by the fact that the actual function takes in account only positive \"probabilities\" of the neurons since it serves as a thresholded at zero. This also led in a  better performance in time, especially compared to other functions. Finally since we also used SGD as our optimizer picking relu makes even more sence since it has been found to accelerate the convergence of stochastic gradient descent compared to the sigmoid/tanh functions. It is argued that this is due to its linear, non-saturating form in 'ImageNet Classification with Deep Convolutional Neural Networks' paper.\n",
        "(http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)\n",
        "\n",
        "Running for multiple number of neurons, we observed that it does affect the model performance. When a neural network has too few hidden neurons (< 64), it does not have the capacity to learn enough of the underlying patterns to distinguish between 0 â 9 effectively. When the neural network has >= 64 neurons, the neural network start to do better. At increasing number of hidden neurons (>= 256), the number of hidden neurons does not help too much for this problem.\n"
      ]
    },
    {
      "metadata": {
        "id": "f3MNSwvAeKW6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2950
        },
        "outputId": "76ee241d-d90b-4a48-8309-f54f0782faa9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523461576568,
          "user_tz": -120,
          "elapsed": 98844,
          "user": {
            "displayName": "metalrules211",
            "photoUrl": "//lh5.googleusercontent.com/-eXRoLTRTB4M/AAAAAAAAAAI/AAAAAAAAABY/a8zMwRWnaDU/s50-c-k-no/photo.jpg",
            "userId": "110111763941813844581"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#------------------------ Modified Models-----------------------\n",
        "myColors = ['r', 'g', 'b', 'y']\n",
        "plt.figure(figsize = (10, 8))\n",
        "for i in range(3):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, input_shape=(784,), activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  neurons = 256\n",
        "  number_hidden_layers=i\n",
        "  while number_hidden_layers >= 1:\n",
        "      neurons = int(neurons/2)\n",
        "      model.add(Dense(neurons))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      number_hidden_layers -= 1\n",
        "  number_hidden_layers = number_hidden_layers+1\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(),\n",
        "                metrics=['accuracy'])\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
        "                    verbose=1, validation_data=(X_test, Y_test))\n",
        "  score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  # list all data in history\n",
        "  print(history.history.keys())\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'], c = myColors[i], label = \"Train \" + str(i))\n",
        "  plt.plot(history.history['val_acc'], c = myColors[i], label = \"Test\" + str(i), linestyle = \"--\")\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  #plt.legend([trainlegend[i], testlegend[i]], loc='upper left')\n",
        "plt.legend()\n",
        "# plt.gca().set_color_cycle(['red', 'green', 'blue', 'yellow'])\n",
        "plt.show()\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f61e6e85780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_37 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 1.1532 - acc: 0.7177 - val_loss: 0.6272 - val_acc: 0.8587\n",
            "Epoch 2/10\n",
            "51328/60000 [========================>.....] - ETA: 0s - loss: 0.5719 - acc: 0.8574"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.5597 - acc: 0.8592 - val_loss: 0.4481 - val_acc: 0.8879\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.4500 - acc: 0.8786 - val_loss: 0.3840 - val_acc: 0.9012\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4013 - acc: 0.8894 - val_loss: 0.3504 - val_acc: 0.9065\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3723 - acc: 0.8958 - val_loss: 0.3269 - val_acc: 0.9128\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3508 - acc: 0.9020 - val_loss: 0.3100 - val_acc: 0.9171\n",
            "Epoch 7/10\n",
            "17280/60000 [=======>......................] - ETA: 1s - loss: 0.3421 - acc: 0.9036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3324 - acc: 0.9065 - val_loss: 0.2966 - val_acc: 0.9188\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3184 - acc: 0.9098 - val_loss: 0.2850 - val_acc: 0.9213\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3062 - acc: 0.9136 - val_loss: 0.2754 - val_acc: 0.9232\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.2955 - acc: 0.9172 - val_loss: 0.2668 - val_acc: 0.9260\n",
            "Test score: 0.26684256731271744\n",
            "Test accuracy: 0.926\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61db189ef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61db18f4a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'model accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,0,'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_39 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 1.2379 - acc: 0.6728 - val_loss: 0.5616 - val_acc: 0.8682\n",
            "Epoch 2/10\n",
            "12160/60000 [=====>........................] - ETA: 2s - loss: 0.6230 - acc: 0.8312"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.5374 - acc: 0.8514 - val_loss: 0.3893 - val_acc: 0.8968\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.4280 - acc: 0.8767 - val_loss: 0.3314 - val_acc: 0.9080\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.3766 - acc: 0.8908 - val_loss: 0.3001 - val_acc: 0.9150\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.3451 - acc: 0.9017 - val_loss: 0.2789 - val_acc: 0.9201\n",
            "Epoch 6/10\n",
            "59008/60000 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.9081"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.3192 - acc: 0.9083 - val_loss: 0.2603 - val_acc: 0.9256\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.3009 - acc: 0.9134 - val_loss: 0.2456 - val_acc: 0.9299\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.2845 - acc: 0.9182 - val_loss: 0.2342 - val_acc: 0.9310\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.2687 - acc: 0.9225 - val_loss: 0.2228 - val_acc: 0.9351\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.2573 - acc: 0.9257 - val_loss: 0.2129 - val_acc: 0.9377\n",
            "Test score: 0.21294747185260057\n",
            "Test accuracy: 0.9377\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61dad13908>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61daca4c18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'model accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,0,'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 242,762\n",
            "Trainable params: 242,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "51200/60000 [========================>.....] - ETA: 0s - loss: 1.5863 - acc: 0.5208"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 65us/step - loss: 1.4765 - acc: 0.5547 - val_loss: 0.6384 - val_acc: 0.8354\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.6419 - acc: 0.8079 - val_loss: 0.4024 - val_acc: 0.8939\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.4800 - acc: 0.8600 - val_loss: 0.3268 - val_acc: 0.9108\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.4049 - acc: 0.8814 - val_loss: 0.2855 - val_acc: 0.9196\n",
            "Epoch 5/10\n",
            "49536/60000 [=======================>......] - ETA: 0s - loss: 0.3568 - acc: 0.8954"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.3547 - acc: 0.8959 - val_loss: 0.2581 - val_acc: 0.9268\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.3268 - acc: 0.9046 - val_loss: 0.2377 - val_acc: 0.9331\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.3011 - acc: 0.9121 - val_loss: 0.2202 - val_acc: 0.9368\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.2769 - acc: 0.9187 - val_loss: 0.2076 - val_acc: 0.9410\n",
            "Epoch 9/10\n",
            "47872/60000 [======================>.......] - ETA: 0s - loss: 0.2624 - acc: 0.9231"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.2610 - acc: 0.9240 - val_loss: 0.1941 - val_acc: 0.9438\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.2470 - acc: 0.9262 - val_loss: 0.1832 - val_acc: 0.9462\n",
            "Test score: 0.1832090472713113\n",
            "Test accuracy: 0.9462\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61dabba208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61da816160>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'model accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,0,'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f61dd9c0a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAHvCAYAAAAVTKgEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1BhZ2VzIDIgMCBSIC9UeXBlIC9DYXRhbG9nID4+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\nMTU1MDUKJSVFT0YK\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f61e6e85780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mzLueZ0M7E8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see now by changing the parameters the performance of the new architecture is significantly better. We also get an increasing accuracy in contrast with before, which can be attributed to the change of the \n",
        "activation function.\n",
        "\n",
        "Specifically we get:\n",
        "\n",
        "-For 1 hidden layer: 92.6% \n",
        "-For 2 hidden layers: 93.7% \n",
        "-For 3 hidden layers: 94.6%\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wqeUW-15KEAL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST Calculator (6 points)\n",
        "\n",
        "During the lectures you have seen a CNN model that can be successfully trained to classify the MNIST images. You have also seen how a RNN model that can be trained to implement addition of two numbers. You now need to build a model that is a combination of convolutional layers and recurrent cells. \n",
        "\n",
        "Using the KERAS library, design and train a model that produces a sum of a sequence of MNIST images. More specifically, the model should input a sequence of 10 images and compute the cumulative sum of the digits represented by the images.\n",
        "\n",
        "For example:\n",
        "\n",
        "Input 1: ![294](images/a3ex1.png)\n",
        "\n",
        "Output 1: 15\n",
        "\n",
        "Input 2: ![61](images/a3ex2.png)\n",
        "\n",
        "Output 2: 7\n",
        "\n",
        "Your solutions should include:\n",
        "- Python code that formats the MNIST dataset such that it can be used for traning and testing your model\n",
        "- Implementation in keras of your model (for training and testing)\n",
        "- Performance on the model on test data\n",
        "- Justification (in text) of your decisions for the model architecture (type of layers, activation functions, loss function, regularization and training hyperparameters)\n",
        "\n",
        "Note: Use the 60000/10000 train/test split of the MNIST dataset\n"
      ]
    },
    {
      "metadata": {
        "id": "sN_6KFFHOojH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers import Input, RepeatVector, ConvLSTM2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvZ6_1CaP0hW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Python code that formats the MNIST dataset "
      ]
    },
    {
      "metadata": {
        "id": "hBd5XRGkKEAN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b92e366a-c3f5-4d8a-e3f5-b60bb0e401f2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523201452004,
          "user_tz": -120,
          "elapsed": 1092,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "######################### Obtain the dataset, as usual #########################\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 10\n",
        "\n",
        "# Load dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 784) # 784 = 28*28\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "# Normalize\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-kq1KWsPUEIh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "class colors:\n",
        "    ok = '\\033[92m'\n",
        "    fail = '\\033[91m'\n",
        "    close = '\\033[0m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11dgZwuISxwx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70b70ac8-48ac-41c4-8b95-a377a6d8d7fe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523201908010,
          "user_tz": -120,
          "elapsed": 524,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "DIGITS = 1 \n",
        "SUM_LENGTH = 2 # Sum is a.m 2 digits: 90 (9 + 9 + 9 + 9 + 9 + 9 + 9 + 9 + 9 + 9)\n",
        "\n",
        "chars = '0123456789' # The accepted characters\n",
        "ctable = CharacterTable(chars) # Create the table\n",
        "\n",
        "print(\"Dictionary of characters is: \")\n",
        "print(ctable.char_indices)\n",
        "\n",
        "def transform_X_y(X, y):\n",
        "  # Now we want to obtain sequences of 10 numbers, and sum up its values\n",
        "  y_aux = y.copy()\n",
        "  X_input = X.copy()\n",
        "\n",
        "  # arrays of 10 digits\n",
        "  X_input = X_input.reshape((-1,10, 28, 28, 1)) #28x28 ; 1 channel\n",
        "  y_aux = y_aux.reshape((-1,10))\n",
        "\n",
        "  # Get the true target (sum of the 10 digits)\n",
        "  y_true = []\n",
        "  for values in y_aux:\n",
        "    y_true.append(sum(values))\n",
        "\n",
        "  # Vectorize  data\n",
        "  y = np.zeros((len(y_true), SUM_LENGTH, len(chars)), dtype=np.bool)\n",
        "  \n",
        "  # Work with np arrays always... \n",
        "  y_true = np.asarray(y_true)\n",
        "  \n",
        "  # Get the encoded representation of the number (we could use categorical since\n",
        "  # the beginning btw, but following the tutorial approach)\n",
        "  for i, result in enumerate(y_true):\n",
        "      y[i] = ctable.encode(str(result), SUM_LENGTH)\n",
        "\n",
        "  return X_input, y_true, y"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary of characters is: \n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xfZMaauwZm1Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a30c45c8-a2af-40b7-8368-28c4a05d42e2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523202420199,
          "user_tz": -120,
          "elapsed": 553,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the data we will feed the network with. Our approach is to send 10 digits \n",
        "# as images (sequence), so our shapes are (n_obs, 10, width, height, channels)\n",
        "\n",
        "X_train_input, y_train_true, y_train_seq = transform_X_y(X_train, y_train)\n",
        "X_test_input, y_test_true, y_test_seq = transform_X_y(X_test, y_test)\n",
        "\n",
        "print(\"Train shapes...\")\n",
        "print(\"X_train_input : {}\".format(X_train_input.shape))\n",
        "print(\"y_train_true : {}\".format(y_train_true.shape))\n",
        "print(\"y_train_seq : {}\".format(y_train_seq.shape))\n",
        "print(\"\\nTest shapes...\")\n",
        "print(\"X_test_input : {}\".format(X_test_input.shape))\n",
        "print(\"y_test_true : {}\".format(y_test_true.shape))\n",
        "print(\"y_test_seq : {}\".format(y_test_seq.shape))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shapes...\n",
            "X_train_input : (6000, 10, 28, 28, 1)\n",
            "y_train_true : (6000,)\n",
            "y_train_seq : (6000, 2, 10)\n",
            "\n",
            "Test shapes...\n",
            "X_test_input : (1000, 10, 28, 28, 1)\n",
            "y_test_true : (1000,)\n",
            "y_test_seq : (1000, 2, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zza_pXbPP3m1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implementation in Keras of the model"
      ]
    },
    {
      "metadata": {
        "id": "4y5XzOihASLc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "bd3ac504-5610-4baf-8c43-8b1993843f01",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523207156962,
          "user_tz": -120,
          "elapsed": 3063,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "HIDDEN_SIZE = 128 # length of the h (hidden) vector\n",
        "input_shape = (10, 28, 28, 1)\n",
        "\n",
        "# Declare the model\n",
        "model = Sequential()\n",
        "\n",
        "# Receive the 10 mnist digits. The first layer is in charge of receiving 10\n",
        "# images as a convulutional layer. The rest of the layer is the architecture we\n",
        "# found to work the best in Question 2.\n",
        "model.add(ConvLSTM2D(32, (3, 3), input_shape = input_shape, \n",
        "                     activation = \"relu\" ))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# We indicate that we want two sequences as output\n",
        "model.add(RepeatVector(2*DIGITS)) # Repeat 2 times to obain 2 y_(t)...\n",
        "\n",
        "model.add(GRU(HIDDEN_SIZE, return_sequences = True))\n",
        "model.add(GRU(HIDDEN_SIZE, return_sequences = True))\n",
        "# We want to obtain the probability of the 10 classes (10 numbers/chars)\n",
        "model.add(TimeDistributed(Dense(10)))\n",
        "model.add(Activation('softmax'))\n",
        "# Usual loss function and optimizer\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_9 (ConvLSTM2D)  (None, 26, 26, 32)        38144     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_9 (RepeatVecto (None, 2, 1600)           0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 2, 128)            663936    \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 2, 128)            98688     \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 2, 10)             1290      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2, 10)             0         \n",
            "=================================================================\n",
            "Total params: 820,554\n",
            "Trainable params: 820,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bj3oneBRY4bF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 4607
        },
        "outputId": "c7beccaf-77b1-4302-cb63-840e131ad090",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523207468880,
          "user_tz": -120,
          "elapsed": 309354,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_test_aux = y_test.reshape(-1, 10)\n",
        "\n",
        "for iteration in range(1, 16):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(X_train_input, y_train_seq,\n",
        "              batch_size=128,\n",
        "              epochs=1,\n",
        "              validation_data=(X_test_input, y_test_seq))\n",
        "    \n",
        "    print(\"\\nQuestion             Prediction   Answer\")\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(X_test_input)) # One index\n",
        "        # Get the X input and the true label\n",
        "        digits = X_test_input[np.array([ind])] # A set of 10 digits\n",
        "        digits_labels = y_test_aux[np.array([ind])]\n",
        "        q = '+'.join(map(str, digits_labels[0])) \n",
        "        correct = y_test_true[ind]\n",
        "        pred = model.predict_classes(digits, verbose=0)[0]\n",
        "        prediction = int(\"{}{}\".format(pred[0], pred[1]))\n",
        "        print(q, \"  \", prediction, \"       \", correct, \"  \", colors.ok \n",
        "              if prediction == correct else colors.fail, \"â\" \n",
        "              if prediction == correct else \"â\", colors.close )\n",
        "        \n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 23s 4ms/step - loss: 2.0405 - acc: 0.2456 - val_loss: 1.8336 - val_acc: 0.2690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d4155f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "1+3+6+6+2+9+1+9+4+8    47         49    \u001b[91m â \u001b[0m\n",
            "5+4+7+6+7+9+0+5+8+5    47         56    \u001b[91m â \u001b[0m\n",
            "3+0+2+3+4+2+3+0+9+9    47         35    \u001b[91m â \u001b[0m\n",
            "2+3+3+5+7+0+6+8+6+3    47         43    \u001b[91m â \u001b[0m\n",
            "2+6+5+0+1+2+3+4+5+6    43         34    \u001b[91m â \u001b[0m\n",
            "6+6+2+0+0+0+5+8+7+1    47         35    \u001b[91m â \u001b[0m\n",
            "3+6+9+5+9+6+2+4+6+7    43         57    \u001b[91m â \u001b[0m\n",
            "9+0+1+2+3+4+5+6+7+8    42         45    \u001b[91m â \u001b[0m\n",
            "0+1+2+3+4+5+6+7+8+9    43         45    \u001b[91m â \u001b[0m\n",
            "9+3+4+4+6+4+2+1+8+2    47         43    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.8434 - acc: 0.2508 - val_loss: 1.7914 - val_acc: 0.2875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2878320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "0+9+4+4+8+3+2+5+9+7    56         51    \u001b[91m â \u001b[0m\n",
            "3+4+5+6+7+8+9+0+1+2    55         45    \u001b[91m â \u001b[0m\n",
            "2+6+4+7+5+5+5+2+9+2    46         47    \u001b[91m â \u001b[0m\n",
            "8+9+2+3+5+5+9+4+2+1    43         48    \u001b[91m â \u001b[0m\n",
            "7+5+1+3+4+9+4+1+8+5    56         47    \u001b[91m â \u001b[0m\n",
            "9+0+1+7+8+9+9+8+9+8    46         68    \u001b[91m â \u001b[0m\n",
            "9+0+1+2+3+4+5+6+7+8    43         45    \u001b[91m â \u001b[0m\n",
            "4+5+7+2+6+4+9+4+9+4    56         54    \u001b[91m â \u001b[0m\n",
            "4+6+0+4+5+4+1+3+8+6    46         41    \u001b[91m â \u001b[0m\n",
            "1+6+0+0+1+2+3+4+5+6    43         28    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.7968 - acc: 0.2655 - val_loss: 1.7364 - val_acc: 0.3285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2875da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "9+6+1+9+7+7+1+4+8+5    45         57    \u001b[91m â \u001b[0m\n",
            "5+4+3+4+2+8+1+5+1+0    35         33    \u001b[91m â \u001b[0m\n",
            "1+1+1+1+7+2+4+7+5+2    35         31    \u001b[91m â \u001b[0m\n",
            "7+4+2+7+4+9+1+0+6+8    55         48    \u001b[91m â \u001b[0m\n",
            "4+4+1+2+9+1+4+6+9+9    55         49    \u001b[91m â \u001b[0m\n",
            "7+2+0+0+9+1+7+8+7+8    35         49    \u001b[91m â \u001b[0m\n",
            "8+5+7+7+9+1+8+1+8+0    45         54    \u001b[91m â \u001b[0m\n",
            "9+9+5+5+1+5+6+0+3+4    45         47    \u001b[91m â \u001b[0m\n",
            "6+7+3+1+7+1+8+2+0+2    45         37    \u001b[91m â \u001b[0m\n",
            "4+9+9+7+1+1+9+0+7+8    45         55    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.7605 - acc: 0.2860 - val_loss: 1.7146 - val_acc: 0.3190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d287afd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "0+7+6+6+9+3+7+0+5+2    45         45    \u001b[92m â \u001b[0m\n",
            "7+8+1+1+2+9+7+8+4+0    46         47    \u001b[91m â \u001b[0m\n",
            "0+1+2+3+4+5+6+7+8+9    45         45    \u001b[92m â \u001b[0m\n",
            "8+7+9+4+8+8+7+9+7+1    56         68    \u001b[91m â \u001b[0m\n",
            "3+3+8+4+1+1+9+7+4+3    43         43    \u001b[92m â \u001b[0m\n",
            "0+7+3+5+4+2+4+1+8+3    45         37    \u001b[91m â \u001b[0m\n",
            "6+3+4+4+2+8+1+0+6+4    44         38    \u001b[91m â \u001b[0m\n",
            "6+9+8+4+3+7+1+6+4+5    56         53    \u001b[91m â \u001b[0m\n",
            "5+4+8+8+4+0+0+2+3+2    45         36    \u001b[91m â \u001b[0m\n",
            "4+7+3+9+8+8+4+7+1+2    46         53    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.7416 - acc: 0.2918 - val_loss: 1.7054 - val_acc: 0.2975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2866358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "3+6+9+6+0+2+7+4+4+4    40         45    \u001b[91m â \u001b[0m\n",
            "4+3+2+3+5+6+8+8+6+2    40         47    \u001b[91m â \u001b[0m\n",
            "3+4+5+6+7+8+9+0+1+2    50         45    \u001b[91m â \u001b[0m\n",
            "9+4+5+8+4+2+9+7+0+0    51         48    \u001b[91m â \u001b[0m\n",
            "7+2+3+4+0+2+1+8+3+5    39         35    \u001b[91m â \u001b[0m\n",
            "1+6+8+9+9+0+1+2+4+4    40         44    \u001b[91m â \u001b[0m\n",
            "7+1+3+4+5+8+0+9+1+3    40         41    \u001b[91m â \u001b[0m\n",
            "9+0+1+2+3+5+6+0+1+2    30         29    \u001b[91m â \u001b[0m\n",
            "4+9+0+0+5+2+5+0+7+1    40         33    \u001b[91m â \u001b[0m\n",
            "8+7+9+4+8+8+7+9+7+1    50         68    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.7189 - acc: 0.3018 - val_loss: 1.7303 - val_acc: 0.2790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2866128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "4+6+0+4+5+4+1+3+8+6    40         41    \u001b[91m â \u001b[0m\n",
            "5+8+8+0+9+3+2+7+8+4    52         54    \u001b[91m â \u001b[0m\n",
            "9+4+4+7+6+5+4+1+9+9    52         58    \u001b[91m â \u001b[0m\n",
            "2+3+7+8+1+0+0+2+1+6    32         30    \u001b[91m â \u001b[0m\n",
            "2+8+5+8+5+1+1+4+4+3    52         41    \u001b[91m â \u001b[0m\n",
            "2+0+9+7+6+7+4+1+6+2    52         44    \u001b[91m â \u001b[0m\n",
            "4+0+5+0+4+4+7+9+3+4    52         40    \u001b[91m â \u001b[0m\n",
            "1+7+7+4+8+0+7+3+1+3    32         41    \u001b[91m â \u001b[0m\n",
            "5+9+1+4+2+0+2+7+0+9    32         39    \u001b[91m â \u001b[0m\n",
            "3+6+9+3+1+4+1+7+6+9    52         49    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6963 - acc: 0.3101 - val_loss: 1.6644 - val_acc: 0.3125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2866160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "2+2+0+8+9+2+5+1+0+8    22         37    \u001b[91m â \u001b[0m\n",
            "6+9+8+4+3+7+1+6+4+5    52         53    \u001b[91m â \u001b[0m\n",
            "8+1+4+7+5+7+2+2+0+0    39         36    \u001b[91m â \u001b[0m\n",
            "0+8+9+8+9+4+2+5+7+9    52         61    \u001b[91m â \u001b[0m\n",
            "5+5+4+0+8+2+1+0+8+4    42         37    \u001b[91m â \u001b[0m\n",
            "7+4+7+0+0+6+6+6+3+7    48         46    \u001b[91m â \u001b[0m\n",
            "6+9+8+7+1+1+6+7+6+3    52         54    \u001b[91m â \u001b[0m\n",
            "3+4+5+6+7+8+9+0+1+2    42         45    \u001b[91m â \u001b[0m\n",
            "2+7+8+1+7+1+3+8+5+4    49         46    \u001b[91m â \u001b[0m\n",
            "6+8+8+0+1+2+3+4+7+8    52         47    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6757 - acc: 0.3201 - val_loss: 1.6663 - val_acc: 0.3175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d28da6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "8+7+3+9+7+4+4+4+9+2    53         57    \u001b[91m â \u001b[0m\n",
            "3+4+5+6+7+8+9+0+1+2    43         45    \u001b[91m â \u001b[0m\n",
            "1+7+9+1+9+2+6+7+6+6    53         54    \u001b[91m â \u001b[0m\n",
            "0+1+2+3+4+5+6+7+8+9    43         45    \u001b[91m â \u001b[0m\n",
            "4+5+6+7+8+9+0+1+2+3    46         45    \u001b[91m â \u001b[0m\n",
            "4+7+7+7+9+8+4+3+8+2    53         59    \u001b[91m â \u001b[0m\n",
            "5+2+0+9+1+8+6+2+3+9    36         45    \u001b[91m â \u001b[0m\n",
            "6+2+7+3+3+2+1+0+7+3    36         34    \u001b[91m â \u001b[0m\n",
            "8+9+6+1+8+4+1+2+5+9    53         53    \u001b[92m â \u001b[0m\n",
            "8+4+0+0+7+2+4+3+8+6    36         42    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6608 - acc: 0.3298 - val_loss: 1.6536 - val_acc: 0.3290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d28666a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "9+8+6+6+4+2+6+9+2+8    59         60    \u001b[91m â \u001b[0m\n",
            "7+1+3+5+4+3+3+5+5+6    49         42    \u001b[91m â \u001b[0m\n",
            "4+6+0+4+5+4+1+3+8+6    49         41    \u001b[91m â \u001b[0m\n",
            "6+7+3+1+7+1+8+2+0+2    49         37    \u001b[91m â \u001b[0m\n",
            "4+0+5+0+4+4+7+9+3+4    51         40    \u001b[91m â \u001b[0m\n",
            "5+7+6+9+1+4+1+6+4+2    59         45    \u001b[91m â \u001b[0m\n",
            "1+3+6+6+2+9+1+9+4+8    41         49    \u001b[91m â \u001b[0m\n",
            "0+0+8+3+4+3+1+5+0+0    31         24    \u001b[91m â \u001b[0m\n",
            "4+4+1+2+9+1+4+6+9+9    41         49    \u001b[91m â \u001b[0m\n",
            "4+7+2+8+4+7+0+6+2+8    39         48    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 10\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6476 - acc: 0.3313 - val_loss: 1.6503 - val_acc: 0.3170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2866320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "4+9+0+0+5+2+5+0+7+1    46         33    \u001b[91m â \u001b[0m\n",
            "6+0+5+4+9+9+2+1+9+4    46         49    \u001b[91m â \u001b[0m\n",
            "4+4+1+5+2+8+3+4+9+5    46         45    \u001b[91m â \u001b[0m\n",
            "6+2+5+4+1+9+2+1+5+8    46         43    \u001b[91m â \u001b[0m\n",
            "7+4+2+1+5+4+5+5+8+6    46         47    \u001b[91m â \u001b[0m\n",
            "5+0+2+7+4+6+6+8+6+6    56         50    \u001b[91m â \u001b[0m\n",
            "6+9+2+3+3+7+7+0+0+7    56         44    \u001b[91m â \u001b[0m\n",
            "0+8+4+6+2+6+7+9+3+2    46         47    \u001b[91m â \u001b[0m\n",
            "3+4+5+8+9+0+1+2+3+4    46         39    \u001b[91m â \u001b[0m\n",
            "5+6+7+8+9+0+1+2+3+4    46         45    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 11\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6391 - acc: 0.3359 - val_loss: 1.6309 - val_acc: 0.3335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2866438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "8+9+0+1+2+3+4+5+6+7    46         45    \u001b[91m â \u001b[0m\n",
            "9+9+0+0+1+8+8+4+3+4    46         46    \u001b[92m â \u001b[0m\n",
            "0+3+1+8+6+7+5+9+9+3    56         51    \u001b[91m â \u001b[0m\n",
            "9+4+7+0+2+3+4+0+0+8    46         37    \u001b[91m â \u001b[0m\n",
            "7+8+9+0+1+2+3+4+7+8    46         49    \u001b[91m â \u001b[0m\n",
            "0+6+1+6+8+7+0+1+5+0    36         34    \u001b[91m â \u001b[0m\n",
            "9+3+4+0+7+9+6+4+1+4    46         47    \u001b[91m â \u001b[0m\n",
            "5+6+7+8+9+0+1+2+3+5    46         46    \u001b[92m â \u001b[0m\n",
            "2+7+8+1+7+1+3+8+5+4    46         46    \u001b[92m â \u001b[0m\n",
            "8+7+8+9+0+8+4+4+5+8    56         61    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 12\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6311 - acc: 0.3407 - val_loss: 1.6237 - val_acc: 0.3490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d28da358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "5+6+2+3+9+2+6+0+0+6    33         39    \u001b[91m â \u001b[0m\n",
            "4+7+6+2+2+0+9+4+0+1    33         35    \u001b[91m â \u001b[0m\n",
            "7+2+6+9+3+1+4+6+2+5    43         45    \u001b[91m â \u001b[0m\n",
            "8+9+0+1+2+3+4+5+6+7    43         45    \u001b[91m â \u001b[0m\n",
            "5+8+2+6+2+2+5+6+5+0    43         41    \u001b[91m â \u001b[0m\n",
            "9+2+7+1+8+8+8+2+7+6    43         58    \u001b[91m â \u001b[0m\n",
            "1+6+0+0+1+2+3+4+5+6    30         28    \u001b[91m â \u001b[0m\n",
            "9+5+8+6+2+6+2+8+1+7    46         54    \u001b[91m â \u001b[0m\n",
            "3+6+9+8+7+1+0+5+7+1    43         47    \u001b[91m â \u001b[0m\n",
            "5+2+2+0+9+2+6+6+0+1    43         33    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 13\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6177 - acc: 0.3540 - val_loss: 1.6395 - val_acc: 0.3340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d286dcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "0+3+3+8+4+3+6+3+5+0    41         35    \u001b[91m â \u001b[0m\n",
            "7+7+4+7+7+3+7+4+5+4    51         55    \u001b[91m â \u001b[0m\n",
            "8+3+8+1+5+3+5+0+5+5    41         43    \u001b[91m â \u001b[0m\n",
            "9+3+9+2+2+9+2+1+8+3    46         48    \u001b[91m â \u001b[0m\n",
            "9+9+0+0+1+8+8+4+3+4    41         46    \u001b[91m â \u001b[0m\n",
            "6+9+9+9+2+1+6+1+3+5    41         51    \u001b[91m â \u001b[0m\n",
            "6+0+8+2+9+2+8+8+8+8    41         59    \u001b[91m â \u001b[0m\n",
            "0+0+3+0+2+6+6+4+9+3    41         33    \u001b[91m â \u001b[0m\n",
            "5+6+9+3+6+3+6+0+1+2    41         41    \u001b[92m â \u001b[0m\n",
            "5+5+9+1+7+5+4+9+1+2    41         48    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 14\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6173 - acc: 0.3511 - val_loss: 1.6107 - val_acc: 0.3520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d28da400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "4+9+8+3+7+4+0+4+7+8    46         54    \u001b[91m â \u001b[0m\n",
            "4+6+1+0+4+5+3+9+4+2    46         38    \u001b[91m â \u001b[0m\n",
            "8+1+0+0+7+7+8+7+5+0    41         43    \u001b[91m â \u001b[0m\n",
            "3+1+9+0+9+3+6+8+7+0    46         46    \u001b[92m â \u001b[0m\n",
            "1+3+5+0+7+8+1+5+1+4    36         35    \u001b[91m â \u001b[0m\n",
            "0+3+9+2+8+1+4+3+5+2    31         37    \u001b[91m â \u001b[0m\n",
            "7+5+8+8+3+8+9+2+6+2    56         58    \u001b[91m â \u001b[0m\n",
            "6+7+1+2+5+8+0+3+7+2    33         41    \u001b[91m â \u001b[0m\n",
            "7+6+2+7+8+4+7+3+6+1    56         51    \u001b[91m â \u001b[0m\n",
            "2+4+4+3+3+6+9+9+5+8    56         53    \u001b[91m â \u001b[0m\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 15\n",
            "Train on 6000 samples, validate on 1000 samples\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 1.6109 - acc: 0.3547 - val_loss: 1.6169 - val_acc: 0.3450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23d2875b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question             Prediction   Answer\n",
            "6+3+7+7+4+4+3+9+2+8    53         53    \u001b[92m â \u001b[0m\n",
            "8+6+5+9+0+0+0+3+7+1    36         39    \u001b[91m â \u001b[0m\n",
            "3+7+8+0+1+2+3+4+7+8    46         43    \u001b[91m â \u001b[0m\n",
            "0+4+4+4+4+6+1+2+3+3    36         31    \u001b[91m â \u001b[0m\n",
            "1+8+0+2+0+5+2+1+3+7    39         29    \u001b[91m â \u001b[0m\n",
            "2+3+4+7+8+9+0+8+3+9    53         53    \u001b[92m â \u001b[0m\n",
            "0+9+4+4+8+3+2+5+9+7    51         51    \u001b[92m â \u001b[0m\n",
            "2+9+7+2+1+1+3+7+5+3    36         40    \u001b[91m â \u001b[0m\n",
            "0+1+2+1+3+2+0+7+2+6    36         24    \u001b[91m â \u001b[0m\n",
            "8+6+1+0+2+1+4+0+1+2    26         25    \u001b[91m â \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rb9XHvj-P8h0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Performance in test data "
      ]
    },
    {
      "metadata": {
        "id": "gL9_-60XqCpY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cd93a2b5-a306-43f4-c7a2-14da415a1d4c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523207478123,
          "user_tz": -120,
          "elapsed": 2056,
          "user": {
            "displayName": "Jorge GÃ³mez",
            "photoUrl": "//lh5.googleusercontent.com/-OHXqZEKFiwY/AAAAAAAAAAI/AAAAAAAAG1Q/EYd5cagCTIo/s50-c-k-no/photo.jpg",
            "userId": "108155755194959101108"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_input, y_test_seq, verbose = 1)\n",
        "print('\\nTest loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "\n",
            "Test loss: 1.616915943145752\n",
            "Test accuracy: 0.345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fsFgLCGAKEAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Justification\n",
        "\n",
        "For this task, we were asked to train a Neural Network that is the combination of Convolutional Layers and Recurrent units to solve the problem of summing up a set of 10 images from the MNIST dataset. This is, we want to input a sequence of 10 digits images ($x_1 ... x_{10}$) and output the sum of these digits ($Y$).\n",
        "\n",
        "In order to achieve this, we create a delayed sequence-to-sequence model where the input sequence are the 10 digits (images) to sum up and the output sequence  is the decomposition of $Y$ into digits (e.g. if the result is 45, the sequence is \\[4, 5\\]). Note that at the most, we can have a result of two digits $(y_1, y_2)$, since the maximum value of each digit is 9 and `9x10=90`. The architecture of our model is then based on this approach and we can depict it as next:\n",
        "\n",
        "- Convolutional component\n",
        " - Receive 10 `28x28x1` images with the `ConvLSTM2D` layer\n",
        " - Then, apply a set of Conv2D, MaxPooling and Dropout layers to build the features of the images as we would to in a CNN\n",
        " - After the last convolution layer, we flatten the resulting vector and pass that to the RNN component to form a fully-connected layer\n",
        "- Recurrent component\n",
        " - Two GRU units that\n",
        " - A Dense layer to predict the sequence of two digits that represent the sum of the 10 images, by means of a softmax function.\n",
        "\n",
        "In the previous cells we showed this architecture in detail. \n",
        "\n",
        "For the Convolutional component we have just followed a typical CNN architecture where at each layer the size of the feature maps would increase (32 -> 64) and Dropout layers for regularization were applied. On the other hand, for the Recurrent unit, we have tested different units (GRU, LSTM and SimpleRNN) but GRU was the one with the best accuracy.\n",
        "\n",
        "We can observe that after 15 epochs, the model is not able to learn all the correct sums, indeed our accuracy is low (34%). This is somehow expected since we are learning from images and not the actual digits. More specifically, we are extracting the features of the images and based on them predicting $y$. One can say that the problem itself is complex since we only have 10 digits and very similar sums (expected value of the sum is 45), and even in that setting the model is learning to predict results that are not really far from the true answer, as observed in the output.\n",
        "\n",
        "It comes important to mention that while testing we have tried a different model, where based on the convolutional layers we would predict a real number (regression). However, with that approach the model learned to predict the expected value of the sums (45) for any input and we decided to drop it.\n"
      ]
    }
  ]
}